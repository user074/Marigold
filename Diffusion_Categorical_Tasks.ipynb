{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2778478f65af400793e8671c5d510ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00398a404dc84d7ba8518d58f7eaaa52",
              "IPY_MODEL_60eb6d6eb5ce4850ae8020e3c57e6db0",
              "IPY_MODEL_f0a1ce8b4af640898da9e3d9f7b5bb94"
            ],
            "layout": "IPY_MODEL_615804088a3e48ddb9e977d8ac39e27d"
          }
        },
        "00398a404dc84d7ba8518d58f7eaaa52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71575dba847f483d80b4c3afb31d44d1",
            "placeholder": "​",
            "style": "IPY_MODEL_b4568cb4de5149b8bd0b7c5eee41947c",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "60eb6d6eb5ce4850ae8020e3c57e6db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df9ee6ba2114f52b902163b21a6e498",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e79393d440a545068a891eb1d554f510",
            "value": 5
          }
        },
        "f0a1ce8b4af640898da9e3d9f7b5bb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_966d636006bc41e4aee68b90d9a32b8c",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d3bb46a6b24bb8913ada89ca41612c",
            "value": " 5/5 [00:03&lt;00:00,  1.21it/s]"
          }
        },
        "615804088a3e48ddb9e977d8ac39e27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71575dba847f483d80b4c3afb31d44d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4568cb4de5149b8bd0b7c5eee41947c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df9ee6ba2114f52b902163b21a6e498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79393d440a545068a891eb1d554f510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "966d636006bc41e4aee68b90d9a32b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d3bb46a6b24bb8913ada89ca41612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification"
      ],
      "metadata": {
        "id": "2GrphaPOSiA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "flkid5WMSiYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrYyVbEmScyq",
        "outputId": "61563577-a04e-4fd1-8b0b-705eade0bcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Marigold'...\n",
            "remote: Enumerating objects: 612, done.\u001b[K\n",
            "remote: Counting objects: 100% (334/334), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 612 (delta 238), reused 251 (delta 177), pack-reused 278\u001b[K\n",
            "Receiving objects: 100% (612/612), 5.70 MiB | 3.19 MiB/s, done.\n",
            "Resolving deltas: 100% (350/350), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# # @title 📦 i. Clone repository\n",
        "\n",
        "# %%shell\n",
        "# cd /content\n",
        "\n",
        "# if [ -d \"Marigold\" ]; then\n",
        "#     cd Marigold\n",
        "#     git pull\n",
        "# else\n",
        "#     git clone https://github.com/user074/Marigold.git\n",
        "#     cd Marigold\n",
        "# fi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔨 ii. Install dependencies (might take minutes)\n",
        "%%shell\n",
        "\n",
        "cd /content/Marigold\n",
        "\n",
        "# pip install -r requirements.txt --upgrade  --quiet\n",
        "pip install accelerate diffusers matplotlib scipy torch transformers --quiet\n",
        "\n",
        "# for progress bar\n",
        "pip install ipywidgets==7.7.1 --quiet\n",
        "\n",
        "#for training\n",
        "pip install -r requirements++.txt -r requirements+.txt -r requirements.txt --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeoDpvtDSz18",
        "outputId": "b27428ad-6143-4b67-9f33-c0dfea09e472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m307.2/309.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔧 iii. Setup directories\n",
        "\n",
        "import os\n",
        "\n",
        "# Directories\n",
        "repo_dir = \"/content/Marigold\"\n",
        "input_dir = os.path.join(repo_dir, \"input\")\n",
        "output_dir = os.path.join(repo_dir, \"output\")\n",
        "output_dir_color = os.path.join(output_dir, \"depth_colored\")\n",
        "output_dir_tif = os.path.join(output_dir, \"depth_bw\")\n",
        "output_dir_npy = os.path.join(output_dir, \"depth_npy\")\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "pIWidjdvTWzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Stable Diffusion Model\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/stabilityai/stable-diffusion-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDfrASNtU_Vb",
        "outputId": "5a22f3af-f1e7-484e-811b-d137fc1f3612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'stable-diffusion-2'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 174 (delta 72), reused 174 (delta 72), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 610.01 KiB | 1.29 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "Filtering content: 100% (14/14), 16.13 GiB | 48.57 MiB/s, done.\n",
            "Encountered 2 file(s) that may not have been copied correctly on Windows:\n",
            "\t768-v-ema.safetensors\n",
            "\t768-v-ema.ckpt\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jT31tIxF3knP",
        "outputId": "8f641d18-3168-4cc4-c9bd-424c8103e24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Marigold/output'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stable-diffusion = 'stable-diffusion-2'\n",
        "!export BASE_CKPT_DIR='.'  # directory of pretrained checkpoint\n",
        "!export BASE_DATA_DIR='output'  # directory of training data\n"
      ],
      "metadata": {
        "id": "yjAnRDaIbmSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"BASE_DATA_DIR\"] = \"output\"\n",
        "os.environ[\"BASE_CKPT_DIR\"] = \".\""
      ],
      "metadata": {
        "id": "gxkKofEn36lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config config/train_marigold.yaml --no_wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68H24VRW1Mqq",
        "outputId": "2502f99b-034d-45b1-9b8b-bb365a7ca7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-03 05:25:33.304733: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-03 05:25:33.362602: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-03 05:25:33.362651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-03 05:25:33.364896: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-03 05:25:33.373857: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-03 05:25:34.468723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "start at 2024-07-03 05:25:36.460906\n",
            " 2024-07-03 05:25:36,582 - INFO -train.py - <module> >> device = cuda\n",
            " 2024-07-03 05:25:36,589 - INFO -train.py - <module> >> Config saved to ./output/train_marigold/config.yaml\n",
            " 2024-07-03 05:25:36,589 - INFO -train.py - <module> >> Effective batch size: 32, accumulation steps: 16\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Loading pipeline components...: 100% 5/5 [00:00<00:00,  5.04it/s]\n",
            " 2024-07-03 05:25:39,338 - INFO -marigold_trainer.py - _replace_unet_conv_in >> Unet conv_in layer is replaced\n",
            " 2024-07-03 05:25:39,338 - INFO -marigold_trainer.py - _replace_unet_conv_in >> Unet config is updated\n",
            " 2024-07-03 05:25:40,776 - INFO -marigold_trainer.py - train >> Start training\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            " 2024-07-03 05:25:42,888 - INFO -marigold_trainer.py - _get_next_seed >> Global seed sequence is generated, length=480000\n",
            " 2024-07-03 05:25:48,751 - INFO -marigold_trainer.py - train >> iter     1 (epoch  1): loss=0.91901\n",
            " 2024-07-03 05:25:53,246 - INFO -marigold_trainer.py - train >> iter     2 (epoch  1): loss=0.86319\n",
            " 2024-07-03 05:25:57,488 - INFO -marigold_trainer.py - train >> iter     3 (epoch  1): loss=0.96631\n",
            " 2024-07-03 05:26:01,749 - INFO -marigold_trainer.py - train >> iter     4 (epoch  1): loss=0.99890\n",
            " 2024-07-03 05:26:06,006 - INFO -marigold_trainer.py - train >> iter     5 (epoch  1): loss=0.85773\n",
            " 2024-07-03 05:26:10,277 - INFO -marigold_trainer.py - train >> iter     6 (epoch  1): loss=0.89499\n",
            " 2024-07-03 05:26:14,549 - INFO -marigold_trainer.py - train >> iter     7 (epoch  1): loss=0.97090\n",
            " 2024-07-03 05:26:18,816 - INFO -marigold_trainer.py - train >> iter     8 (epoch  1): loss=0.88604\n",
            " 2024-07-03 05:26:23,083 - INFO -marigold_trainer.py - train >> iter     9 (epoch  1): loss=0.83148\n",
            " 2024-07-03 05:26:27,365 - INFO -marigold_trainer.py - train >> iter    10 (epoch  1): loss=1.01321\n",
            " 2024-07-03 05:26:31,638 - INFO -marigold_trainer.py - train >> iter    11 (epoch  1): loss=0.90683\n",
            " 2024-07-03 05:26:35,986 - INFO -marigold_trainer.py - train >> iter    12 (epoch  1): loss=0.90277\n",
            " 2024-07-03 05:26:40,282 - INFO -marigold_trainer.py - train >> iter    13 (epoch  1): loss=0.80748\n",
            " 2024-07-03 05:26:44,572 - INFO -marigold_trainer.py - train >> iter    14 (epoch  1): loss=0.81278\n",
            " 2024-07-03 05:26:48,863 - INFO -marigold_trainer.py - train >> iter    15 (epoch  1): loss=0.72245\n",
            " 2024-07-03 05:26:53,167 - INFO -marigold_trainer.py - train >> iter    16 (epoch  1): loss=0.73944\n",
            " 2024-07-03 05:26:57,565 - INFO -marigold_trainer.py - train >> iter    17 (epoch  1): loss=0.69710\n",
            " 2024-07-03 05:27:01,881 - INFO -marigold_trainer.py - train >> iter    18 (epoch  1): loss=0.63522\n",
            " 2024-07-03 05:27:06,208 - INFO -marigold_trainer.py - train >> iter    19 (epoch  1): loss=0.67628\n",
            " 2024-07-03 05:27:10,551 - INFO -marigold_trainer.py - train >> iter    20 (epoch  1): loss=0.64880\n",
            " 2024-07-03 05:27:14,880 - INFO -marigold_trainer.py - train >> iter    21 (epoch  1): loss=0.58802\n",
            " 2024-07-03 05:27:19,205 - INFO -marigold_trainer.py - train >> iter    22 (epoch  1): loss=0.56275\n",
            " 2024-07-03 05:27:23,521 - INFO -marigold_trainer.py - train >> iter    23 (epoch  1): loss=0.56217\n",
            " 2024-07-03 05:27:27,821 - INFO -marigold_trainer.py - train >> iter    24 (epoch  1): loss=0.56381\n",
            " 2024-07-03 05:27:32,114 - INFO -marigold_trainer.py - train >> iter    25 (epoch  1): loss=0.56011\n",
            " 2024-07-03 05:27:36,443 - INFO -marigold_trainer.py - train >> iter    26 (epoch  1): loss=0.52112\n",
            " 2024-07-03 05:27:40,741 - INFO -marigold_trainer.py - train >> iter    27 (epoch  1): loss=0.48895\n",
            " 2024-07-03 05:27:45,038 - INFO -marigold_trainer.py - train >> iter    28 (epoch  1): loss=0.43610\n",
            " 2024-07-03 05:27:49,366 - INFO -marigold_trainer.py - train >> iter    29 (epoch  1): loss=0.44696\n",
            " 2024-07-03 05:27:53,661 - INFO -marigold_trainer.py - train >> iter    30 (epoch  1): loss=0.43623\n",
            " 2024-07-03 05:27:57,999 - INFO -marigold_trainer.py - train >> iter    31 (epoch  1): loss=0.41521\n",
            " 2024-07-03 05:28:02,304 - INFO -marigold_trainer.py - train >> iter    32 (epoch  1): loss=0.38231\n",
            " 2024-07-03 05:28:06,591 - INFO -marigold_trainer.py - train >> iter    33 (epoch  1): loss=0.39643\n",
            " 2024-07-03 05:28:10,899 - INFO -marigold_trainer.py - train >> iter    34 (epoch  1): loss=0.32038\n",
            " 2024-07-03 05:28:15,226 - INFO -marigold_trainer.py - train >> iter    35 (epoch  1): loss=0.31724\n",
            " 2024-07-03 05:28:19,514 - INFO -marigold_trainer.py - train >> iter    36 (epoch  1): loss=0.47065\n",
            " 2024-07-03 05:28:23,814 - INFO -marigold_trainer.py - train >> iter    37 (epoch  1): loss=0.44357\n",
            " 2024-07-03 05:28:28,115 - INFO -marigold_trainer.py - train >> iter    38 (epoch  1): loss=0.43470\n",
            " 2024-07-03 05:28:32,416 - INFO -marigold_trainer.py - train >> iter    39 (epoch  1): loss=0.43782\n",
            " 2024-07-03 05:28:36,731 - INFO -marigold_trainer.py - train >> iter    40 (epoch  1): loss=0.32218\n",
            " 2024-07-03 05:28:41,046 - INFO -marigold_trainer.py - train >> iter    41 (epoch  1): loss=0.33690\n",
            " 2024-07-03 05:28:45,353 - INFO -marigold_trainer.py - train >> iter    42 (epoch  1): loss=0.34616\n",
            " 2024-07-03 05:28:49,664 - INFO -marigold_trainer.py - train >> iter    43 (epoch  1): loss=0.45295\n",
            " 2024-07-03 05:28:53,957 - INFO -marigold_trainer.py - train >> iter    44 (epoch  1): loss=0.38478\n",
            " 2024-07-03 05:28:58,369 - INFO -marigold_trainer.py - train >> iter    45 (epoch  1): loss=0.35223\n",
            " 2024-07-03 05:29:02,686 - INFO -marigold_trainer.py - train >> iter    46 (epoch  1): loss=0.32845\n",
            " 2024-07-03 05:29:06,981 - INFO -marigold_trainer.py - train >> iter    47 (epoch  1): loss=0.33245\n",
            " 2024-07-03 05:29:11,282 - INFO -marigold_trainer.py - train >> iter    48 (epoch  1): loss=0.38506\n",
            " 2024-07-03 05:29:15,603 - INFO -marigold_trainer.py - train >> iter    49 (epoch  1): loss=0.34405\n",
            " 2024-07-03 05:29:19,900 - INFO -marigold_trainer.py - train >> iter    50 (epoch  1): loss=0.36297\n",
            " 2024-07-03 05:29:19,901 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:29:32,424 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:29:50,726 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:29:54,770 - INFO -marigold_trainer.py - train >> iter    51 (epoch  1): loss=0.35241\n",
            " 2024-07-03 05:29:59,109 - INFO -marigold_trainer.py - train >> iter    52 (epoch  1): loss=0.34073\n",
            " 2024-07-03 05:30:03,428 - INFO -marigold_trainer.py - train >> iter    53 (epoch  1): loss=0.29291\n",
            " 2024-07-03 05:30:07,743 - INFO -marigold_trainer.py - train >> iter    54 (epoch  1): loss=0.32825\n",
            " 2024-07-03 05:30:12,073 - INFO -marigold_trainer.py - train >> iter    55 (epoch  1): loss=0.42837\n",
            " 2024-07-03 05:30:16,399 - INFO -marigold_trainer.py - train >> iter    56 (epoch  1): loss=0.35719\n",
            " 2024-07-03 05:30:20,711 - INFO -marigold_trainer.py - train >> iter    57 (epoch  1): loss=0.33419\n",
            " 2024-07-03 05:30:25,039 - INFO -marigold_trainer.py - train >> iter    58 (epoch  1): loss=0.33053\n",
            " 2024-07-03 05:30:29,385 - INFO -marigold_trainer.py - train >> iter    59 (epoch  1): loss=0.28439\n",
            " 2024-07-03 05:30:33,704 - INFO -marigold_trainer.py - train >> iter    60 (epoch  1): loss=0.35309\n",
            " 2024-07-03 05:30:38,033 - INFO -marigold_trainer.py - train >> iter    61 (epoch  1): loss=0.27523\n",
            " 2024-07-03 05:30:42,391 - INFO -marigold_trainer.py - train >> iter    62 (epoch  1): loss=0.41515\n",
            " 2024-07-03 05:30:46,716 - INFO -marigold_trainer.py - train >> iter    63 (epoch  1): loss=0.35228\n",
            " 2024-07-03 05:30:51,048 - INFO -marigold_trainer.py - train >> iter    64 (epoch  1): loss=0.28113\n",
            " 2024-07-03 05:30:55,368 - INFO -marigold_trainer.py - train >> iter    65 (epoch  1): loss=0.43399\n",
            " 2024-07-03 05:30:59,790 - INFO -marigold_trainer.py - train >> iter    66 (epoch  1): loss=0.40239\n",
            " 2024-07-03 05:31:04,108 - INFO -marigold_trainer.py - train >> iter    67 (epoch  1): loss=0.30027\n",
            " 2024-07-03 05:31:08,428 - INFO -marigold_trainer.py - train >> iter    68 (epoch  1): loss=0.31388\n",
            " 2024-07-03 05:31:12,748 - INFO -marigold_trainer.py - train >> iter    69 (epoch  1): loss=0.28030\n",
            " 2024-07-03 05:31:17,062 - INFO -marigold_trainer.py - train >> iter    70 (epoch  1): loss=0.25990\n",
            " 2024-07-03 05:31:21,366 - INFO -marigold_trainer.py - train >> iter    71 (epoch  1): loss=0.34761\n",
            " 2024-07-03 05:31:25,684 - INFO -marigold_trainer.py - train >> iter    72 (epoch  1): loss=0.31584\n",
            " 2024-07-03 05:31:30,011 - INFO -marigold_trainer.py - train >> iter    73 (epoch  1): loss=0.34586\n",
            " 2024-07-03 05:31:34,335 - INFO -marigold_trainer.py - train >> iter    74 (epoch  1): loss=0.33069\n",
            " 2024-07-03 05:31:38,680 - INFO -marigold_trainer.py - train >> iter    75 (epoch  1): loss=0.31040\n",
            " 2024-07-03 05:31:43,018 - INFO -marigold_trainer.py - train >> iter    76 (epoch  1): loss=0.29458\n",
            " 2024-07-03 05:31:47,350 - INFO -marigold_trainer.py - train >> iter    77 (epoch  1): loss=0.47040\n",
            " 2024-07-03 05:31:51,683 - INFO -marigold_trainer.py - train >> iter    78 (epoch  1): loss=0.28137\n",
            " 2024-07-03 05:31:55,999 - INFO -marigold_trainer.py - train >> iter    79 (epoch  1): loss=0.30070\n",
            " 2024-07-03 05:32:00,329 - INFO -marigold_trainer.py - train >> iter    80 (epoch  1): loss=0.28308\n",
            " 2024-07-03 05:32:04,745 - INFO -marigold_trainer.py - train >> iter    81 (epoch  1): loss=0.35872\n",
            " 2024-07-03 05:32:09,049 - INFO -marigold_trainer.py - train >> iter    82 (epoch  1): loss=0.34594\n",
            " 2024-07-03 05:32:13,386 - INFO -marigold_trainer.py - train >> iter    83 (epoch  1): loss=0.29274\n",
            " 2024-07-03 05:32:18,026 - INFO -marigold_trainer.py - train >> iter    84 (epoch  1): loss=0.34223\n",
            " 2024-07-03 05:32:22,362 - INFO -marigold_trainer.py - train >> iter    85 (epoch  1): loss=0.28946\n",
            " 2024-07-03 05:32:26,700 - INFO -marigold_trainer.py - train >> iter    86 (epoch  1): loss=0.37582\n",
            " 2024-07-03 05:32:31,023 - INFO -marigold_trainer.py - train >> iter    87 (epoch  1): loss=0.33991\n",
            " 2024-07-03 05:32:35,330 - INFO -marigold_trainer.py - train >> iter    88 (epoch  1): loss=0.36437\n",
            " 2024-07-03 05:32:39,658 - INFO -marigold_trainer.py - train >> iter    89 (epoch  1): loss=0.31500\n",
            " 2024-07-03 05:32:43,976 - INFO -marigold_trainer.py - train >> iter    90 (epoch  1): loss=0.28860\n",
            " 2024-07-03 05:32:48,291 - INFO -marigold_trainer.py - train >> iter    91 (epoch  1): loss=0.32212\n",
            " 2024-07-03 05:32:52,617 - INFO -marigold_trainer.py - train >> iter    92 (epoch  1): loss=0.42516\n",
            " 2024-07-03 05:32:56,929 - INFO -marigold_trainer.py - train >> iter    93 (epoch  1): loss=0.28523\n",
            " 2024-07-03 05:33:01,240 - INFO -marigold_trainer.py - train >> iter    94 (epoch  1): loss=0.30584\n",
            " 2024-07-03 05:33:05,631 - INFO -marigold_trainer.py - train >> iter    95 (epoch  1): loss=0.37524\n",
            " 2024-07-03 05:33:09,969 - INFO -marigold_trainer.py - train >> iter    96 (epoch  1): loss=0.31789\n",
            " 2024-07-03 05:33:14,307 - INFO -marigold_trainer.py - train >> iter    97 (epoch  1): loss=0.38298\n",
            " 2024-07-03 05:33:18,626 - INFO -marigold_trainer.py - train >> iter    98 (epoch  1): loss=0.32411\n",
            " 2024-07-03 05:33:22,944 - INFO -marigold_trainer.py - train >> iter    99 (epoch  1): loss=0.24267\n",
            " 2024-07-03 05:33:27,259 - INFO -marigold_trainer.py - train >> iter   100 (epoch  1): loss=0.34091\n",
            " 2024-07-03 05:33:27,259 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:33:35,625 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:33:54,143 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:33:59,926 - INFO -marigold_trainer.py - train >> iter   101 (epoch  1): loss=0.21423\n",
            " 2024-07-03 05:34:04,323 - INFO -marigold_trainer.py - train >> iter   102 (epoch  1): loss=0.29752\n",
            " 2024-07-03 05:34:08,631 - INFO -marigold_trainer.py - train >> iter   103 (epoch  1): loss=0.32641\n",
            " 2024-07-03 05:34:12,972 - INFO -marigold_trainer.py - train >> iter   104 (epoch  1): loss=0.28543\n",
            " 2024-07-03 05:34:17,309 - INFO -marigold_trainer.py - train >> iter   105 (epoch  1): loss=0.34354\n",
            " 2024-07-03 05:34:21,625 - INFO -marigold_trainer.py - train >> iter   106 (epoch  1): loss=0.38568\n",
            " 2024-07-03 05:34:25,957 - INFO -marigold_trainer.py - train >> iter   107 (epoch  1): loss=0.35648\n",
            " 2024-07-03 05:34:30,290 - INFO -marigold_trainer.py - train >> iter   108 (epoch  1): loss=0.28263\n",
            " 2024-07-03 05:34:34,601 - INFO -marigold_trainer.py - train >> iter   109 (epoch  1): loss=0.34345\n",
            " 2024-07-03 05:34:38,921 - INFO -marigold_trainer.py - train >> iter   110 (epoch  1): loss=0.27248\n",
            " 2024-07-03 05:34:43,238 - INFO -marigold_trainer.py - train >> iter   111 (epoch  1): loss=0.22660\n",
            " 2024-07-03 05:34:47,553 - INFO -marigold_trainer.py - train >> iter   112 (epoch  1): loss=0.37044\n",
            " 2024-07-03 05:34:51,875 - INFO -marigold_trainer.py - train >> iter   113 (epoch  1): loss=0.25396\n",
            " 2024-07-03 05:34:56,189 - INFO -marigold_trainer.py - train >> iter   114 (epoch  1): loss=0.31122\n",
            " 2024-07-03 05:35:00,489 - INFO -marigold_trainer.py - train >> iter   115 (epoch  1): loss=0.33781\n",
            " 2024-07-03 05:35:04,808 - INFO -marigold_trainer.py - train >> iter   116 (epoch  1): loss=0.35547\n",
            " 2024-07-03 05:35:09,164 - INFO -marigold_trainer.py - train >> iter   117 (epoch  1): loss=0.31161\n",
            " 2024-07-03 05:35:13,471 - INFO -marigold_trainer.py - train >> iter   118 (epoch  1): loss=0.27133\n",
            " 2024-07-03 05:35:17,777 - INFO -marigold_trainer.py - train >> iter   119 (epoch  1): loss=0.32575\n",
            " 2024-07-03 05:35:22,098 - INFO -marigold_trainer.py - train >> iter   120 (epoch  1): loss=0.29791\n",
            " 2024-07-03 05:35:26,425 - INFO -marigold_trainer.py - train >> iter   121 (epoch  1): loss=0.31084\n",
            " 2024-07-03 05:35:30,717 - INFO -marigold_trainer.py - train >> iter   122 (epoch  1): loss=0.38630\n",
            " 2024-07-03 05:35:35,014 - INFO -marigold_trainer.py - train >> iter   123 (epoch  1): loss=0.33220\n",
            " 2024-07-03 05:35:39,341 - INFO -marigold_trainer.py - train >> iter   124 (epoch  1): loss=0.31730\n",
            " 2024-07-03 05:35:43,649 - INFO -marigold_trainer.py - train >> iter   125 (epoch  1): loss=0.34462\n",
            " 2024-07-03 05:35:47,948 - INFO -marigold_trainer.py - train >> iter   126 (epoch  1): loss=0.35426\n",
            " 2024-07-03 05:35:52,247 - INFO -marigold_trainer.py - train >> iter   127 (epoch  1): loss=0.28435\n",
            " 2024-07-03 05:35:56,544 - INFO -marigold_trainer.py - train >> iter   128 (epoch  1): loss=0.29948\n",
            " 2024-07-03 05:36:00,849 - INFO -marigold_trainer.py - train >> iter   129 (epoch  1): loss=0.31963\n",
            " 2024-07-03 05:36:05,171 - INFO -marigold_trainer.py - train >> iter   130 (epoch  1): loss=0.31085\n",
            " 2024-07-03 05:36:09,541 - INFO -marigold_trainer.py - train >> iter   131 (epoch  1): loss=0.32188\n",
            " 2024-07-03 05:36:13,865 - INFO -marigold_trainer.py - train >> iter   132 (epoch  1): loss=0.28380\n",
            " 2024-07-03 05:36:18,185 - INFO -marigold_trainer.py - train >> iter   133 (epoch  1): loss=0.36074\n",
            " 2024-07-03 05:36:22,482 - INFO -marigold_trainer.py - train >> iter   134 (epoch  1): loss=0.32159\n",
            " 2024-07-03 05:36:26,782 - INFO -marigold_trainer.py - train >> iter   135 (epoch  1): loss=0.34714\n",
            " 2024-07-03 05:36:31,074 - INFO -marigold_trainer.py - train >> iter   136 (epoch  1): loss=0.29166\n",
            " 2024-07-03 05:36:35,369 - INFO -marigold_trainer.py - train >> iter   137 (epoch  1): loss=0.33040\n",
            " 2024-07-03 05:36:39,681 - INFO -marigold_trainer.py - train >> iter   138 (epoch  1): loss=0.34943\n",
            " 2024-07-03 05:36:43,992 - INFO -marigold_trainer.py - train >> iter   139 (epoch  1): loss=0.30599\n",
            " 2024-07-03 05:36:48,298 - INFO -marigold_trainer.py - train >> iter   140 (epoch  1): loss=0.36935\n",
            " 2024-07-03 05:36:52,606 - INFO -marigold_trainer.py - train >> iter   141 (epoch  1): loss=0.36375\n",
            " 2024-07-03 05:36:56,909 - INFO -marigold_trainer.py - train >> iter   142 (epoch  1): loss=0.31990\n",
            " 2024-07-03 05:37:01,229 - INFO -marigold_trainer.py - train >> iter   143 (epoch  1): loss=0.26296\n",
            " 2024-07-03 05:37:05,530 - INFO -marigold_trainer.py - train >> iter   144 (epoch  1): loss=0.33829\n",
            " 2024-07-03 05:37:09,928 - INFO -marigold_trainer.py - train >> iter   145 (epoch  1): loss=0.42367\n",
            " 2024-07-03 05:37:14,244 - INFO -marigold_trainer.py - train >> iter   146 (epoch  1): loss=0.28024\n",
            " 2024-07-03 05:37:18,546 - INFO -marigold_trainer.py - train >> iter   147 (epoch  1): loss=0.31755\n",
            " 2024-07-03 05:37:22,855 - INFO -marigold_trainer.py - train >> iter   148 (epoch  1): loss=0.28762\n",
            " 2024-07-03 05:37:27,181 - INFO -marigold_trainer.py - train >> iter   149 (epoch  1): loss=0.28633\n",
            " 2024-07-03 05:37:31,484 - INFO -marigold_trainer.py - train >> iter   150 (epoch  1): loss=0.27166\n",
            " 2024-07-03 05:37:31,485 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:37:45,569 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:38:06,464 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:38:12,275 - INFO -marigold_trainer.py - train >> iter   151 (epoch  1): loss=0.25293\n",
            " 2024-07-03 05:38:16,585 - INFO -marigold_trainer.py - train >> iter   152 (epoch  1): loss=0.38475\n",
            " 2024-07-03 05:38:20,883 - INFO -marigold_trainer.py - train >> iter   153 (epoch  1): loss=0.37207\n",
            " 2024-07-03 05:38:25,229 - INFO -marigold_trainer.py - train >> iter   154 (epoch  1): loss=0.36621\n",
            " 2024-07-03 05:38:29,524 - INFO -marigold_trainer.py - train >> iter   155 (epoch  1): loss=0.27214\n",
            " 2024-07-03 05:38:33,840 - INFO -marigold_trainer.py - train >> iter   156 (epoch  1): loss=0.37050\n",
            " 2024-07-03 05:38:38,181 - INFO -marigold_trainer.py - train >> iter   157 (epoch  1): loss=0.31954\n",
            " 2024-07-03 05:38:42,507 - INFO -marigold_trainer.py - train >> iter   158 (epoch  1): loss=0.22746\n",
            " 2024-07-03 05:38:46,838 - INFO -marigold_trainer.py - train >> iter   159 (epoch  1): loss=0.25593\n",
            " 2024-07-03 05:38:51,171 - INFO -marigold_trainer.py - train >> iter   160 (epoch  1): loss=0.33940\n",
            " 2024-07-03 05:38:55,468 - INFO -marigold_trainer.py - train >> iter   161 (epoch  1): loss=0.29367\n",
            " 2024-07-03 05:38:59,761 - INFO -marigold_trainer.py - train >> iter   162 (epoch  1): loss=0.26782\n",
            " 2024-07-03 05:39:04,073 - INFO -marigold_trainer.py - train >> iter   163 (epoch  1): loss=0.30778\n",
            " 2024-07-03 05:39:08,361 - INFO -marigold_trainer.py - train >> iter   164 (epoch  1): loss=0.28047\n",
            " 2024-07-03 05:39:12,737 - INFO -marigold_trainer.py - train >> iter   165 (epoch  1): loss=0.37750\n",
            " 2024-07-03 05:39:17,031 - INFO -marigold_trainer.py - train >> iter   166 (epoch  1): loss=0.32817\n",
            " 2024-07-03 05:39:21,320 - INFO -marigold_trainer.py - train >> iter   167 (epoch  1): loss=0.28832\n",
            " 2024-07-03 05:39:25,616 - INFO -marigold_trainer.py - train >> iter   168 (epoch  1): loss=0.31050\n",
            " 2024-07-03 05:39:29,922 - INFO -marigold_trainer.py - train >> iter   169 (epoch  1): loss=0.29667\n",
            " 2024-07-03 05:39:34,209 - INFO -marigold_trainer.py - train >> iter   170 (epoch  1): loss=0.28219\n",
            " 2024-07-03 05:39:38,495 - INFO -marigold_trainer.py - train >> iter   171 (epoch  1): loss=0.30043\n",
            " 2024-07-03 05:39:42,806 - INFO -marigold_trainer.py - train >> iter   172 (epoch  1): loss=0.23506\n",
            " 2024-07-03 05:39:47,096 - INFO -marigold_trainer.py - train >> iter   173 (epoch  1): loss=0.37870\n",
            " 2024-07-03 05:39:51,404 - INFO -marigold_trainer.py - train >> iter   174 (epoch  1): loss=0.27406\n",
            " 2024-07-03 05:39:55,712 - INFO -marigold_trainer.py - train >> iter   175 (epoch  1): loss=0.26868\n",
            " 2024-07-03 05:40:00,197 - INFO -marigold_trainer.py - train >> iter   176 (epoch  1): loss=0.31193\n",
            " 2024-07-03 05:40:04,514 - INFO -marigold_trainer.py - train >> iter   177 (epoch  1): loss=0.30438\n",
            " 2024-07-03 05:40:08,827 - INFO -marigold_trainer.py - train >> iter   178 (epoch  1): loss=0.31760\n",
            " 2024-07-03 05:40:13,214 - INFO -marigold_trainer.py - train >> iter   179 (epoch  1): loss=0.31112\n",
            " 2024-07-03 05:40:17,547 - INFO -marigold_trainer.py - train >> iter   180 (epoch  1): loss=0.27384\n",
            " 2024-07-03 05:40:21,874 - INFO -marigold_trainer.py - train >> iter   181 (epoch  1): loss=0.35065\n",
            " 2024-07-03 05:40:26,199 - INFO -marigold_trainer.py - train >> iter   182 (epoch  1): loss=0.28515\n",
            " 2024-07-03 05:40:30,503 - INFO -marigold_trainer.py - train >> iter   183 (epoch  1): loss=0.28814\n",
            " 2024-07-03 05:40:34,798 - INFO -marigold_trainer.py - train >> iter   184 (epoch  1): loss=0.26246\n",
            " 2024-07-03 05:40:39,114 - INFO -marigold_trainer.py - train >> iter   185 (epoch  1): loss=0.24427\n",
            " 2024-07-03 05:40:43,404 - INFO -marigold_trainer.py - train >> iter   186 (epoch  1): loss=0.22556\n",
            " 2024-07-03 05:40:47,701 - INFO -marigold_trainer.py - train >> iter   187 (epoch  1): loss=0.29226\n",
            " 2024-07-03 05:40:52,006 - INFO -marigold_trainer.py - train >> iter   188 (epoch  1): loss=0.22913\n",
            " 2024-07-03 05:40:56,310 - INFO -marigold_trainer.py - train >> iter   189 (epoch  1): loss=0.42184\n",
            " 2024-07-03 05:41:00,616 - INFO -marigold_trainer.py - train >> iter   190 (epoch  1): loss=0.32043\n",
            " 2024-07-03 05:41:04,910 - INFO -marigold_trainer.py - train >> iter   191 (epoch  1): loss=0.30955\n",
            " 2024-07-03 05:41:09,220 - INFO -marigold_trainer.py - train >> iter   192 (epoch  1): loss=0.26930\n",
            " 2024-07-03 05:41:13,509 - INFO -marigold_trainer.py - train >> iter   193 (epoch  1): loss=0.35365\n",
            " 2024-07-03 05:41:17,903 - INFO -marigold_trainer.py - train >> iter   194 (epoch  1): loss=0.28606\n",
            " 2024-07-03 05:41:22,192 - INFO -marigold_trainer.py - train >> iter   195 (epoch  1): loss=0.21234\n",
            " 2024-07-03 05:41:26,499 - INFO -marigold_trainer.py - train >> iter   196 (epoch  1): loss=0.30120\n",
            " 2024-07-03 05:41:30,790 - INFO -marigold_trainer.py - train >> iter   197 (epoch  1): loss=0.29965\n",
            " 2024-07-03 05:41:35,094 - INFO -marigold_trainer.py - train >> iter   198 (epoch  1): loss=0.25740\n",
            " 2024-07-03 05:41:39,396 - INFO -marigold_trainer.py - train >> iter   199 (epoch  1): loss=0.31473\n",
            " 2024-07-03 05:41:43,690 - INFO -marigold_trainer.py - train >> iter   200 (epoch  1): loss=0.28524\n",
            " 2024-07-03 05:41:43,691 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:42:01,125 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:42:19,307 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:42:25,088 - INFO -marigold_trainer.py - train >> iter   201 (epoch  1): loss=0.26657\n",
            " 2024-07-03 05:42:29,400 - INFO -marigold_trainer.py - train >> iter   202 (epoch  1): loss=0.34136\n",
            " 2024-07-03 05:42:33,699 - INFO -marigold_trainer.py - train >> iter   203 (epoch  1): loss=0.21417\n",
            " 2024-07-03 05:42:38,028 - INFO -marigold_trainer.py - train >> iter   204 (epoch  1): loss=0.28616\n",
            " 2024-07-03 05:42:42,378 - INFO -marigold_trainer.py - train >> iter   205 (epoch  1): loss=0.30275\n",
            " 2024-07-03 05:42:46,699 - INFO -marigold_trainer.py - train >> iter   206 (epoch  1): loss=0.26893\n",
            " 2024-07-03 05:42:51,041 - INFO -marigold_trainer.py - train >> iter   207 (epoch  1): loss=0.27713\n",
            " 2024-07-03 05:42:55,346 - INFO -marigold_trainer.py - train >> iter   208 (epoch  1): loss=0.32559\n",
            " 2024-07-03 05:42:59,675 - INFO -marigold_trainer.py - train >> iter   209 (epoch  1): loss=0.35231\n",
            " 2024-07-03 05:43:03,973 - INFO -marigold_trainer.py - train >> iter   210 (epoch  1): loss=0.30394\n",
            " 2024-07-03 05:43:08,272 - INFO -marigold_trainer.py - train >> iter   211 (epoch  1): loss=0.33636\n",
            " 2024-07-03 05:43:12,566 - INFO -marigold_trainer.py - train >> iter   212 (epoch  1): loss=0.27084\n",
            " 2024-07-03 05:43:16,976 - INFO -marigold_trainer.py - train >> iter   213 (epoch  1): loss=0.26800\n",
            " 2024-07-03 05:43:21,191 - INFO -marigold_trainer.py - train >> iter   214 (epoch  1): loss=0.28234\n",
            " 2024-07-03 05:43:25,481 - INFO -marigold_trainer.py - train >> iter   215 (epoch  1): loss=0.29939\n",
            " 2024-07-03 05:43:29,803 - INFO -marigold_trainer.py - train >> iter   216 (epoch  1): loss=0.35091\n",
            " 2024-07-03 05:43:34,088 - INFO -marigold_trainer.py - train >> iter   217 (epoch  1): loss=0.26043\n",
            " 2024-07-03 05:43:38,378 - INFO -marigold_trainer.py - train >> iter   218 (epoch  1): loss=0.32536\n",
            " 2024-07-03 05:43:42,692 - INFO -marigold_trainer.py - train >> iter   219 (epoch  1): loss=0.31685\n",
            " 2024-07-03 05:43:46,978 - INFO -marigold_trainer.py - train >> iter   220 (epoch  1): loss=0.28977\n",
            " 2024-07-03 05:43:51,277 - INFO -marigold_trainer.py - train >> iter   221 (epoch  1): loss=0.36179\n",
            " 2024-07-03 05:43:55,567 - INFO -marigold_trainer.py - train >> iter   222 (epoch  1): loss=0.34285\n",
            " 2024-07-03 05:43:59,855 - INFO -marigold_trainer.py - train >> iter   223 (epoch  1): loss=0.25792\n",
            " 2024-07-03 05:44:04,189 - INFO -marigold_trainer.py - train >> iter   224 (epoch  1): loss=0.28971\n",
            " 2024-07-03 05:44:08,504 - INFO -marigold_trainer.py - train >> iter   225 (epoch  1): loss=0.28591\n",
            " 2024-07-03 05:44:12,790 - INFO -marigold_trainer.py - train >> iter   226 (epoch  1): loss=0.27908\n",
            " 2024-07-03 05:44:17,116 - INFO -marigold_trainer.py - train >> iter   227 (epoch  1): loss=0.30355\n",
            " 2024-07-03 05:44:21,506 - INFO -marigold_trainer.py - train >> iter   228 (epoch  1): loss=0.21506\n",
            " 2024-07-03 05:44:25,803 - INFO -marigold_trainer.py - train >> iter   229 (epoch  1): loss=0.26090\n",
            " 2024-07-03 05:44:30,142 - INFO -marigold_trainer.py - train >> iter   230 (epoch  1): loss=0.30450\n",
            " 2024-07-03 05:44:34,463 - INFO -marigold_trainer.py - train >> iter   231 (epoch  1): loss=0.34065\n",
            " 2024-07-03 05:44:38,786 - INFO -marigold_trainer.py - train >> iter   232 (epoch  1): loss=0.27631\n",
            " 2024-07-03 05:44:43,084 - INFO -marigold_trainer.py - train >> iter   233 (epoch  1): loss=0.27102\n",
            " 2024-07-03 05:44:47,382 - INFO -marigold_trainer.py - train >> iter   234 (epoch  1): loss=0.36227\n",
            " 2024-07-03 05:44:51,703 - INFO -marigold_trainer.py - train >> iter   235 (epoch  1): loss=0.25557\n",
            " 2024-07-03 05:44:56,018 - INFO -marigold_trainer.py - train >> iter   236 (epoch  1): loss=0.31456\n",
            " 2024-07-03 05:45:00,312 - INFO -marigold_trainer.py - train >> iter   237 (epoch  1): loss=0.29621\n",
            " 2024-07-03 05:45:04,613 - INFO -marigold_trainer.py - train >> iter   238 (epoch  1): loss=0.33503\n",
            " 2024-07-03 05:45:08,902 - INFO -marigold_trainer.py - train >> iter   239 (epoch  1): loss=0.33111\n",
            " 2024-07-03 05:45:13,198 - INFO -marigold_trainer.py - train >> iter   240 (epoch  1): loss=0.26352\n",
            " 2024-07-03 05:45:17,511 - INFO -marigold_trainer.py - train >> iter   241 (epoch  1): loss=0.28298\n",
            " 2024-07-03 05:45:21,866 - INFO -marigold_trainer.py - train >> iter   242 (epoch  1): loss=0.23051\n",
            " 2024-07-03 05:45:26,159 - INFO -marigold_trainer.py - train >> iter   243 (epoch  1): loss=0.26741\n",
            " 2024-07-03 05:45:30,457 - INFO -marigold_trainer.py - train >> iter   244 (epoch  1): loss=0.31154\n",
            " 2024-07-03 05:45:34,742 - INFO -marigold_trainer.py - train >> iter   245 (epoch  1): loss=0.33047\n",
            " 2024-07-03 05:45:39,062 - INFO -marigold_trainer.py - train >> iter   246 (epoch  1): loss=0.27467\n",
            " 2024-07-03 05:45:43,346 - INFO -marigold_trainer.py - train >> iter   247 (epoch  1): loss=0.33866\n",
            " 2024-07-03 05:45:47,633 - INFO -marigold_trainer.py - train >> iter   248 (epoch  1): loss=0.33027\n",
            " 2024-07-03 05:45:51,937 - INFO -marigold_trainer.py - train >> iter   249 (epoch  1): loss=0.31573\n",
            " 2024-07-03 05:45:56,226 - INFO -marigold_trainer.py - train >> iter   250 (epoch  1): loss=0.27810\n",
            " 2024-07-03 05:45:56,227 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:46:05,995 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:46:24,595 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:46:30,364 - INFO -marigold_trainer.py - train >> iter   251 (epoch  1): loss=0.23806\n",
            " 2024-07-03 05:46:34,651 - INFO -marigold_trainer.py - train >> iter   252 (epoch  1): loss=0.31193\n",
            " 2024-07-03 05:46:38,947 - INFO -marigold_trainer.py - train >> iter   253 (epoch  1): loss=0.27659\n",
            " 2024-07-03 05:46:43,266 - INFO -marigold_trainer.py - train >> iter   254 (epoch  1): loss=0.28277\n",
            " 2024-07-03 05:46:47,585 - INFO -marigold_trainer.py - train >> iter   255 (epoch  1): loss=0.29453\n",
            " 2024-07-03 05:46:51,928 - INFO -marigold_trainer.py - train >> iter   256 (epoch  1): loss=0.27835\n",
            " 2024-07-03 05:46:56,244 - INFO -marigold_trainer.py - train >> iter   257 (epoch  1): loss=0.27939\n",
            " 2024-07-03 05:47:00,560 - INFO -marigold_trainer.py - train >> iter   258 (epoch  1): loss=0.22228\n",
            " 2024-07-03 05:47:04,889 - INFO -marigold_trainer.py - train >> iter   259 (epoch  1): loss=0.24634\n",
            " 2024-07-03 05:47:09,191 - INFO -marigold_trainer.py - train >> iter   260 (epoch  1): loss=0.28260\n",
            " 2024-07-03 05:47:13,509 - INFO -marigold_trainer.py - train >> iter   261 (epoch  1): loss=0.34166\n",
            " 2024-07-03 05:47:17,831 - INFO -marigold_trainer.py - train >> iter   262 (epoch  1): loss=0.32872\n",
            " 2024-07-03 05:47:22,131 - INFO -marigold_trainer.py - train >> iter   263 (epoch  1): loss=0.30213\n",
            " 2024-07-03 05:47:26,525 - INFO -marigold_trainer.py - train >> iter   264 (epoch  1): loss=0.25155\n",
            " 2024-07-03 05:47:30,812 - INFO -marigold_trainer.py - train >> iter   265 (epoch  1): loss=0.24539\n",
            " 2024-07-03 05:47:35,105 - INFO -marigold_trainer.py - train >> iter   266 (epoch  1): loss=0.30902\n",
            " 2024-07-03 05:47:39,396 - INFO -marigold_trainer.py - train >> iter   267 (epoch  1): loss=0.30652\n",
            " 2024-07-03 05:47:43,714 - INFO -marigold_trainer.py - train >> iter   268 (epoch  1): loss=0.29190\n",
            " 2024-07-03 05:47:48,011 - INFO -marigold_trainer.py - train >> iter   269 (epoch  1): loss=0.23288\n",
            " 2024-07-03 05:47:52,321 - INFO -marigold_trainer.py - train >> iter   270 (epoch  1): loss=0.26804\n",
            " 2024-07-03 05:47:56,618 - INFO -marigold_trainer.py - train >> iter   271 (epoch  1): loss=0.30965\n",
            " 2024-07-03 05:48:00,922 - INFO -marigold_trainer.py - train >> iter   272 (epoch  1): loss=0.26113\n",
            " 2024-07-03 05:48:05,246 - INFO -marigold_trainer.py - train >> iter   273 (epoch  1): loss=0.24788\n",
            " 2024-07-03 05:48:09,548 - INFO -marigold_trainer.py - train >> iter   274 (epoch  1): loss=0.32573\n",
            " 2024-07-03 05:48:13,843 - INFO -marigold_trainer.py - train >> iter   275 (epoch  1): loss=0.34319\n",
            " 2024-07-03 05:48:18,368 - INFO -marigold_trainer.py - train >> iter   276 (epoch  1): loss=0.30048\n",
            " 2024-07-03 05:48:22,673 - INFO -marigold_trainer.py - train >> iter   277 (epoch  1): loss=0.35586\n",
            " 2024-07-03 05:48:27,046 - INFO -marigold_trainer.py - train >> iter   278 (epoch  1): loss=0.30542\n",
            " 2024-07-03 05:48:31,362 - INFO -marigold_trainer.py - train >> iter   279 (epoch  1): loss=0.22172\n",
            " 2024-07-03 05:48:35,665 - INFO -marigold_trainer.py - train >> iter   280 (epoch  1): loss=0.26527\n",
            " 2024-07-03 05:48:39,977 - INFO -marigold_trainer.py - train >> iter   281 (epoch  1): loss=0.22312\n",
            " 2024-07-03 05:48:44,273 - INFO -marigold_trainer.py - train >> iter   282 (epoch  1): loss=0.31354\n",
            " 2024-07-03 05:48:48,575 - INFO -marigold_trainer.py - train >> iter   283 (epoch  1): loss=0.23865\n",
            " 2024-07-03 05:48:52,896 - INFO -marigold_trainer.py - train >> iter   284 (epoch  1): loss=0.45611\n",
            " 2024-07-03 05:48:57,196 - INFO -marigold_trainer.py - train >> iter   285 (epoch  1): loss=0.40713\n",
            " 2024-07-03 05:49:01,499 - INFO -marigold_trainer.py - train >> iter   286 (epoch  1): loss=0.27763\n",
            " 2024-07-03 05:49:05,828 - INFO -marigold_trainer.py - train >> iter   287 (epoch  1): loss=0.31893\n",
            " 2024-07-03 05:49:10,135 - INFO -marigold_trainer.py - train >> iter   288 (epoch  1): loss=0.22007\n",
            " 2024-07-03 05:49:14,431 - INFO -marigold_trainer.py - train >> iter   289 (epoch  1): loss=0.29631\n",
            " 2024-07-03 05:49:18,733 - INFO -marigold_trainer.py - train >> iter   290 (epoch  1): loss=0.29852\n",
            " 2024-07-03 05:49:23,029 - INFO -marigold_trainer.py - train >> iter   291 (epoch  1): loss=0.25024\n",
            " 2024-07-03 05:49:27,394 - INFO -marigold_trainer.py - train >> iter   292 (epoch  1): loss=0.31484\n",
            " 2024-07-03 05:49:31,690 - INFO -marigold_trainer.py - train >> iter   293 (epoch  1): loss=0.29764\n",
            " 2024-07-03 05:49:36,005 - INFO -marigold_trainer.py - train >> iter   294 (epoch  1): loss=0.28999\n",
            " 2024-07-03 05:49:40,309 - INFO -marigold_trainer.py - train >> iter   295 (epoch  1): loss=0.28014\n",
            " 2024-07-03 05:49:44,600 - INFO -marigold_trainer.py - train >> iter   296 (epoch  1): loss=0.27499\n",
            " 2024-07-03 05:49:48,903 - INFO -marigold_trainer.py - train >> iter   297 (epoch  1): loss=0.29304\n",
            " 2024-07-03 05:49:53,217 - INFO -marigold_trainer.py - train >> iter   298 (epoch  1): loss=0.30122\n",
            " 2024-07-03 05:49:57,509 - INFO -marigold_trainer.py - train >> iter   299 (epoch  1): loss=0.38638\n",
            " 2024-07-03 05:50:01,796 - INFO -marigold_trainer.py - train >> iter   300 (epoch  1): loss=0.29742\n",
            " 2024-07-03 05:50:01,797 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:50:15,512 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:50:34,500 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:50:40,239 - INFO -marigold_trainer.py - train >> iter   301 (epoch  1): loss=0.29870\n",
            " 2024-07-03 05:50:44,548 - INFO -marigold_trainer.py - train >> iter   302 (epoch  1): loss=0.28870\n",
            " 2024-07-03 05:50:48,859 - INFO -marigold_trainer.py - train >> iter   303 (epoch  1): loss=0.31504\n",
            " 2024-07-03 05:50:53,176 - INFO -marigold_trainer.py - train >> iter   304 (epoch  1): loss=0.31573\n",
            " 2024-07-03 05:50:57,483 - INFO -marigold_trainer.py - train >> iter   305 (epoch  1): loss=0.28961\n",
            " 2024-07-03 05:51:01,805 - INFO -marigold_trainer.py - train >> iter   306 (epoch  1): loss=0.35008\n",
            " 2024-07-03 05:51:06,143 - INFO -marigold_trainer.py - train >> iter   307 (epoch  1): loss=0.32081\n",
            " 2024-07-03 05:51:10,462 - INFO -marigold_trainer.py - train >> iter   308 (epoch  1): loss=0.31450\n",
            " 2024-07-03 05:51:14,795 - INFO -marigold_trainer.py - train >> iter   309 (epoch  1): loss=0.18596\n",
            " 2024-07-03 05:51:19,133 - INFO -marigold_trainer.py - train >> iter   310 (epoch  1): loss=0.25513\n",
            " 2024-07-03 05:51:23,450 - INFO -marigold_trainer.py - train >> iter   311 (epoch  1): loss=0.26457\n",
            " 2024-07-03 05:51:27,769 - INFO -marigold_trainer.py - train >> iter   312 (epoch  1): loss=0.26577\n",
            " 2024-07-03 05:51:32,171 - INFO -marigold_trainer.py - train >> iter   313 (epoch  1): loss=0.25122\n",
            " 2024-07-03 05:51:36,464 - INFO -marigold_trainer.py - train >> iter   314 (epoch  1): loss=0.29396\n",
            " 2024-07-03 05:51:40,776 - INFO -marigold_trainer.py - train >> iter   315 (epoch  1): loss=0.35586\n",
            " 2024-07-03 05:51:45,063 - INFO -marigold_trainer.py - train >> iter   316 (epoch  1): loss=0.29486\n",
            " 2024-07-03 05:51:49,357 - INFO -marigold_trainer.py - train >> iter   317 (epoch  1): loss=0.20837\n",
            " 2024-07-03 05:51:53,665 - INFO -marigold_trainer.py - train >> iter   318 (epoch  1): loss=0.34387\n",
            " 2024-07-03 05:51:57,983 - INFO -marigold_trainer.py - train >> iter   319 (epoch  1): loss=0.26649\n",
            " 2024-07-03 05:52:02,270 - INFO -marigold_trainer.py - train >> iter   320 (epoch  1): loss=0.29468\n",
            " 2024-07-03 05:52:06,580 - INFO -marigold_trainer.py - train >> iter   321 (epoch  1): loss=0.25312\n",
            " 2024-07-03 05:52:10,892 - INFO -marigold_trainer.py - train >> iter   322 (epoch  1): loss=0.26494\n",
            " 2024-07-03 05:52:15,191 - INFO -marigold_trainer.py - train >> iter   323 (epoch  1): loss=0.22087\n",
            " 2024-07-03 05:52:19,489 - INFO -marigold_trainer.py - train >> iter   324 (epoch  1): loss=0.29999\n",
            " 2024-07-03 05:52:23,789 - INFO -marigold_trainer.py - train >> iter   325 (epoch  1): loss=0.33061\n",
            " 2024-07-03 05:52:28,094 - INFO -marigold_trainer.py - train >> iter   326 (epoch  1): loss=0.33872\n",
            " 2024-07-03 05:52:32,448 - INFO -marigold_trainer.py - train >> iter   327 (epoch  1): loss=0.22411\n",
            " 2024-07-03 05:52:36,764 - INFO -marigold_trainer.py - train >> iter   328 (epoch  1): loss=0.33316\n",
            " 2024-07-03 05:52:41,096 - INFO -marigold_trainer.py - train >> iter   329 (epoch  1): loss=0.26970\n",
            " 2024-07-03 05:52:45,385 - INFO -marigold_trainer.py - train >> iter   330 (epoch  1): loss=0.28055\n",
            " 2024-07-03 05:52:49,701 - INFO -marigold_trainer.py - train >> iter   331 (epoch  1): loss=0.26396\n",
            " 2024-07-03 05:52:54,013 - INFO -marigold_trainer.py - train >> iter   332 (epoch  1): loss=0.32084\n",
            " 2024-07-03 05:52:58,314 - INFO -marigold_trainer.py - train >> iter   333 (epoch  1): loss=0.28392\n",
            " 2024-07-03 05:53:02,617 - INFO -marigold_trainer.py - train >> iter   334 (epoch  1): loss=0.21350\n",
            " 2024-07-03 05:53:06,917 - INFO -marigold_trainer.py - train >> iter   335 (epoch  1): loss=0.30215\n",
            " 2024-07-03 05:53:11,213 - INFO -marigold_trainer.py - train >> iter   336 (epoch  1): loss=0.31068\n",
            " 2024-07-03 05:53:15,510 - INFO -marigold_trainer.py - train >> iter   337 (epoch  1): loss=0.31594\n",
            " 2024-07-03 05:53:19,817 - INFO -marigold_trainer.py - train >> iter   338 (epoch  1): loss=0.33617\n",
            " 2024-07-03 05:53:24,111 - INFO -marigold_trainer.py - train >> iter   339 (epoch  1): loss=0.31736\n",
            " 2024-07-03 05:53:28,417 - INFO -marigold_trainer.py - train >> iter   340 (epoch  1): loss=0.31496\n",
            " 2024-07-03 05:53:32,801 - INFO -marigold_trainer.py - train >> iter   341 (epoch  1): loss=0.22989\n",
            " 2024-07-03 05:53:37,108 - INFO -marigold_trainer.py - train >> iter   342 (epoch  1): loss=0.28116\n",
            " 2024-07-03 05:53:41,424 - INFO -marigold_trainer.py - train >> iter   343 (epoch  1): loss=0.30872\n",
            " 2024-07-03 05:53:45,722 - INFO -marigold_trainer.py - train >> iter   344 (epoch  1): loss=0.26162\n",
            " 2024-07-03 05:53:50,024 - INFO -marigold_trainer.py - train >> iter   345 (epoch  1): loss=0.27854\n",
            " 2024-07-03 05:53:54,333 - INFO -marigold_trainer.py - train >> iter   346 (epoch  1): loss=0.25951\n",
            " 2024-07-03 05:53:58,641 - INFO -marigold_trainer.py - train >> iter   347 (epoch  1): loss=0.36951\n",
            " 2024-07-03 05:54:02,945 - INFO -marigold_trainer.py - train >> iter   348 (epoch  1): loss=0.24971\n",
            " 2024-07-03 05:54:07,255 - INFO -marigold_trainer.py - train >> iter   349 (epoch  1): loss=0.33185\n",
            " 2024-07-03 05:54:11,555 - INFO -marigold_trainer.py - train >> iter   350 (epoch  1): loss=0.29094\n",
            " 2024-07-03 05:54:11,556 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:54:26,532 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:54:44,925 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:54:50,733 - INFO -marigold_trainer.py - train >> iter   351 (epoch  1): loss=0.26513\n",
            " 2024-07-03 05:54:55,037 - INFO -marigold_trainer.py - train >> iter   352 (epoch  1): loss=0.26904\n",
            " 2024-07-03 05:54:59,346 - INFO -marigold_trainer.py - train >> iter   353 (epoch  1): loss=0.28939\n",
            " 2024-07-03 05:55:03,657 - INFO -marigold_trainer.py - train >> iter   354 (epoch  1): loss=0.29283\n",
            " 2024-07-03 05:55:07,993 - INFO -marigold_trainer.py - train >> iter   355 (epoch  1): loss=0.24933\n",
            " 2024-07-03 05:55:12,341 - INFO -marigold_trainer.py - train >> iter   356 (epoch  1): loss=0.24847\n",
            " 2024-07-03 05:55:16,660 - INFO -marigold_trainer.py - train >> iter   357 (epoch  1): loss=0.29834\n",
            " 2024-07-03 05:55:20,996 - INFO -marigold_trainer.py - train >> iter   358 (epoch  1): loss=0.24862\n",
            " 2024-07-03 05:55:25,321 - INFO -marigold_trainer.py - train >> iter   359 (epoch  1): loss=0.20896\n",
            " 2024-07-03 05:55:29,651 - INFO -marigold_trainer.py - train >> iter   360 (epoch  1): loss=0.36557\n",
            " 2024-07-03 05:55:33,963 - INFO -marigold_trainer.py - train >> iter   361 (epoch  1): loss=0.39692\n",
            " 2024-07-03 05:55:38,281 - INFO -marigold_trainer.py - train >> iter   362 (epoch  1): loss=0.26185\n",
            " 2024-07-03 05:55:42,579 - INFO -marigold_trainer.py - train >> iter   363 (epoch  1): loss=0.25605\n",
            " 2024-07-03 05:55:46,896 - INFO -marigold_trainer.py - train >> iter   364 (epoch  1): loss=0.21938\n",
            " 2024-07-03 05:55:51,188 - INFO -marigold_trainer.py - train >> iter   365 (epoch  1): loss=0.24489\n",
            " 2024-07-03 05:55:55,477 - INFO -marigold_trainer.py - train >> iter   366 (epoch  1): loss=0.26422\n",
            " 2024-07-03 05:55:59,783 - INFO -marigold_trainer.py - train >> iter   367 (epoch  1): loss=0.29456\n",
            " 2024-07-03 05:56:04,077 - INFO -marigold_trainer.py - train >> iter   368 (epoch  1): loss=0.25984\n",
            " 2024-07-03 05:56:08,371 - INFO -marigold_trainer.py - train >> iter   369 (epoch  1): loss=0.29416\n",
            " 2024-07-03 05:56:12,652 - INFO -marigold_trainer.py - train >> iter   370 (epoch  1): loss=0.35153\n",
            " 2024-07-03 05:56:16,980 - INFO -marigold_trainer.py - train >> iter   371 (epoch  1): loss=0.29122\n",
            " 2024-07-03 05:56:21,459 - INFO -marigold_trainer.py - train >> iter   372 (epoch  1): loss=0.27048\n",
            " 2024-07-03 05:56:25,748 - INFO -marigold_trainer.py - train >> iter   373 (epoch  1): loss=0.24530\n",
            " 2024-07-03 05:56:30,061 - INFO -marigold_trainer.py - train >> iter   374 (epoch  1): loss=0.39903\n",
            " 2024-07-03 05:56:34,375 - INFO -marigold_trainer.py - train >> iter   375 (epoch  1): loss=0.19553\n",
            " 2024-07-03 05:56:38,739 - INFO -marigold_trainer.py - train >> iter   376 (epoch  1): loss=0.29387\n",
            " 2024-07-03 05:56:43,051 - INFO -marigold_trainer.py - train >> iter   377 (epoch  1): loss=0.31282\n",
            " 2024-07-03 05:56:47,344 - INFO -marigold_trainer.py - train >> iter   378 (epoch  1): loss=0.27694\n",
            " 2024-07-03 05:56:51,639 - INFO -marigold_trainer.py - train >> iter   379 (epoch  1): loss=0.29169\n",
            " 2024-07-03 05:56:55,948 - INFO -marigold_trainer.py - train >> iter   380 (epoch  1): loss=0.25113\n",
            " 2024-07-03 05:57:00,259 - INFO -marigold_trainer.py - train >> iter   381 (epoch  1): loss=0.27697\n",
            " 2024-07-03 05:57:04,570 - INFO -marigold_trainer.py - train >> iter   382 (epoch  1): loss=0.27370\n",
            " 2024-07-03 05:57:08,889 - INFO -marigold_trainer.py - train >> iter   383 (epoch  1): loss=0.29659\n",
            " 2024-07-03 05:57:13,191 - INFO -marigold_trainer.py - train >> iter   384 (epoch  1): loss=0.24305\n",
            " 2024-07-03 05:57:17,520 - INFO -marigold_trainer.py - train >> iter   385 (epoch  1): loss=0.27944\n",
            " 2024-07-03 05:57:21,830 - INFO -marigold_trainer.py - train >> iter   386 (epoch  1): loss=0.26780\n",
            " 2024-07-03 05:57:26,146 - INFO -marigold_trainer.py - train >> iter   387 (epoch  1): loss=0.27232\n",
            " 2024-07-03 05:57:30,466 - INFO -marigold_trainer.py - train >> iter   388 (epoch  1): loss=0.24759\n",
            " 2024-07-03 05:57:34,768 - INFO -marigold_trainer.py - train >> iter   389 (epoch  1): loss=0.26480\n",
            " 2024-07-03 05:57:39,155 - INFO -marigold_trainer.py - train >> iter   390 (epoch  1): loss=0.31815\n",
            " 2024-07-03 05:57:43,445 - INFO -marigold_trainer.py - train >> iter   391 (epoch  1): loss=0.25550\n",
            " 2024-07-03 05:57:47,749 - INFO -marigold_trainer.py - train >> iter   392 (epoch  1): loss=0.28021\n",
            " 2024-07-03 05:57:52,047 - INFO -marigold_trainer.py - train >> iter   393 (epoch  1): loss=0.29813\n",
            " 2024-07-03 05:57:56,373 - INFO -marigold_trainer.py - train >> iter   394 (epoch  1): loss=0.25745\n",
            " 2024-07-03 05:58:00,659 - INFO -marigold_trainer.py - train >> iter   395 (epoch  1): loss=0.28060\n",
            " 2024-07-03 05:58:04,965 - INFO -marigold_trainer.py - train >> iter   396 (epoch  1): loss=0.28004\n",
            " 2024-07-03 05:58:09,287 - INFO -marigold_trainer.py - train >> iter   397 (epoch  1): loss=0.32428\n",
            " 2024-07-03 05:58:13,578 - INFO -marigold_trainer.py - train >> iter   398 (epoch  1): loss=0.29803\n",
            " 2024-07-03 05:58:17,893 - INFO -marigold_trainer.py - train >> iter   399 (epoch  1): loss=0.22990\n",
            " 2024-07-03 05:58:22,197 - INFO -marigold_trainer.py - train >> iter   400 (epoch  1): loss=0.28686\n",
            " 2024-07-03 05:58:22,197 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 05:58:34,112 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 05:58:51,992 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 05:58:57,773 - INFO -marigold_trainer.py - train >> iter   401 (epoch  1): loss=0.22648\n",
            " 2024-07-03 05:59:02,076 - INFO -marigold_trainer.py - train >> iter   402 (epoch  1): loss=0.27801\n",
            " 2024-07-03 05:59:06,389 - INFO -marigold_trainer.py - train >> iter   403 (epoch  1): loss=0.24454\n",
            " 2024-07-03 05:59:10,712 - INFO -marigold_trainer.py - train >> iter   404 (epoch  1): loss=0.19332\n",
            " 2024-07-03 05:59:15,043 - INFO -marigold_trainer.py - train >> iter   405 (epoch  1): loss=0.21875\n",
            " 2024-07-03 05:59:19,384 - INFO -marigold_trainer.py - train >> iter   406 (epoch  1): loss=0.26770\n",
            " 2024-07-03 05:59:23,701 - INFO -marigold_trainer.py - train >> iter   407 (epoch  1): loss=0.24410\n",
            " 2024-07-03 05:59:28,037 - INFO -marigold_trainer.py - train >> iter   408 (epoch  1): loss=0.32402\n",
            " 2024-07-03 05:59:32,380 - INFO -marigold_trainer.py - train >> iter   409 (epoch  1): loss=0.29790\n",
            " 2024-07-03 05:59:36,698 - INFO -marigold_trainer.py - train >> iter   410 (epoch  1): loss=0.35320\n",
            " 2024-07-03 05:59:41,095 - INFO -marigold_trainer.py - train >> iter   411 (epoch  1): loss=0.31232\n",
            " 2024-07-03 05:59:45,394 - INFO -marigold_trainer.py - train >> iter   412 (epoch  1): loss=0.26008\n",
            " 2024-07-03 05:59:49,725 - INFO -marigold_trainer.py - train >> iter   413 (epoch  1): loss=0.31728\n",
            " 2024-07-03 05:59:54,033 - INFO -marigold_trainer.py - train >> iter   414 (epoch  1): loss=0.29733\n",
            " 2024-07-03 05:59:58,324 - INFO -marigold_trainer.py - train >> iter   415 (epoch  1): loss=0.29511\n",
            " 2024-07-03 06:00:02,625 - INFO -marigold_trainer.py - train >> iter   416 (epoch  1): loss=0.21283\n",
            " 2024-07-03 06:00:06,926 - INFO -marigold_trainer.py - train >> iter   417 (epoch  1): loss=0.24424\n",
            " 2024-07-03 06:00:11,222 - INFO -marigold_trainer.py - train >> iter   418 (epoch  1): loss=0.29198\n",
            " 2024-07-03 06:00:15,529 - INFO -marigold_trainer.py - train >> iter   419 (epoch  1): loss=0.24697\n",
            " 2024-07-03 06:00:19,830 - INFO -marigold_trainer.py - train >> iter   420 (epoch  1): loss=0.26407\n",
            " 2024-07-03 06:00:24,131 - INFO -marigold_trainer.py - train >> iter   421 (epoch  1): loss=0.27469\n",
            " 2024-07-03 06:00:28,435 - INFO -marigold_trainer.py - train >> iter   422 (epoch  1): loss=0.39017\n",
            " 2024-07-03 06:00:32,758 - INFO -marigold_trainer.py - train >> iter   423 (epoch  1): loss=0.23328\n",
            " 2024-07-03 06:00:37,055 - INFO -marigold_trainer.py - train >> iter   424 (epoch  1): loss=0.28564\n",
            " 2024-07-03 06:00:41,445 - INFO -marigold_trainer.py - train >> iter   425 (epoch  1): loss=0.33694\n",
            " 2024-07-03 06:00:45,748 - INFO -marigold_trainer.py - train >> iter   426 (epoch  1): loss=0.23132\n",
            " 2024-07-03 06:00:50,049 - INFO -marigold_trainer.py - train >> iter   427 (epoch  1): loss=0.25327\n",
            " 2024-07-03 06:00:54,365 - INFO -marigold_trainer.py - train >> iter   428 (epoch  1): loss=0.30752\n",
            " 2024-07-03 06:00:58,660 - INFO -marigold_trainer.py - train >> iter   429 (epoch  1): loss=0.24863\n",
            " 2024-07-03 06:01:02,966 - INFO -marigold_trainer.py - train >> iter   430 (epoch  1): loss=0.25983\n",
            " 2024-07-03 06:01:07,292 - INFO -marigold_trainer.py - train >> iter   431 (epoch  1): loss=0.23580\n",
            " 2024-07-03 06:01:11,597 - INFO -marigold_trainer.py - train >> iter   432 (epoch  1): loss=0.25057\n",
            " 2024-07-03 06:01:15,905 - INFO -marigold_trainer.py - train >> iter   433 (epoch  1): loss=0.20489\n",
            " 2024-07-03 06:01:20,240 - INFO -marigold_trainer.py - train >> iter   434 (epoch  1): loss=0.24570\n",
            " 2024-07-03 06:01:24,531 - INFO -marigold_trainer.py - train >> iter   435 (epoch  1): loss=0.21677\n",
            " 2024-07-03 06:01:28,827 - INFO -marigold_trainer.py - train >> iter   436 (epoch  1): loss=0.32104\n",
            " 2024-07-03 06:01:33,175 - INFO -marigold_trainer.py - train >> iter   437 (epoch  1): loss=0.30270\n",
            " 2024-07-03 06:01:37,467 - INFO -marigold_trainer.py - train >> iter   438 (epoch  1): loss=0.28546\n",
            " 2024-07-03 06:01:41,796 - INFO -marigold_trainer.py - train >> iter   439 (epoch  1): loss=0.27170\n",
            " 2024-07-03 06:01:46,194 - INFO -marigold_trainer.py - train >> iter   440 (epoch  1): loss=0.26228\n",
            " 2024-07-03 06:01:50,506 - INFO -marigold_trainer.py - train >> iter   441 (epoch  1): loss=0.24137\n",
            " 2024-07-03 06:01:54,811 - INFO -marigold_trainer.py - train >> iter   442 (epoch  1): loss=0.26715\n",
            " 2024-07-03 06:01:59,110 - INFO -marigold_trainer.py - train >> iter   443 (epoch  1): loss=0.25117\n",
            " 2024-07-03 06:02:03,404 - INFO -marigold_trainer.py - train >> iter   444 (epoch  1): loss=0.20674\n",
            " 2024-07-03 06:02:07,717 - INFO -marigold_trainer.py - train >> iter   445 (epoch  1): loss=0.33870\n",
            " 2024-07-03 06:02:12,008 - INFO -marigold_trainer.py - train >> iter   446 (epoch  1): loss=0.27703\n",
            " 2024-07-03 06:02:16,327 - INFO -marigold_trainer.py - train >> iter   447 (epoch  1): loss=0.20999\n",
            " 2024-07-03 06:02:20,672 - INFO -marigold_trainer.py - train >> iter   448 (epoch  1): loss=0.32311\n",
            " 2024-07-03 06:02:24,989 - INFO -marigold_trainer.py - train >> iter   449 (epoch  1): loss=0.26173\n",
            " 2024-07-03 06:02:29,301 - INFO -marigold_trainer.py - train >> iter   450 (epoch  1): loss=0.32932\n",
            " 2024-07-03 06:02:29,302 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:02:41,487 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:03:04,505 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:03:10,359 - INFO -marigold_trainer.py - train >> iter   451 (epoch  1): loss=0.28474\n",
            " 2024-07-03 06:03:14,643 - INFO -marigold_trainer.py - train >> iter   452 (epoch  1): loss=0.24194\n",
            " 2024-07-03 06:03:18,955 - INFO -marigold_trainer.py - train >> iter   453 (epoch  1): loss=0.22844\n",
            " 2024-07-03 06:03:23,259 - INFO -marigold_trainer.py - train >> iter   454 (epoch  1): loss=0.16301\n",
            " 2024-07-03 06:03:27,582 - INFO -marigold_trainer.py - train >> iter   455 (epoch  1): loss=0.25179\n",
            " 2024-07-03 06:03:31,896 - INFO -marigold_trainer.py - train >> iter   456 (epoch  1): loss=0.28188\n",
            " 2024-07-03 06:03:36,218 - INFO -marigold_trainer.py - train >> iter   457 (epoch  1): loss=0.29916\n",
            " 2024-07-03 06:03:40,520 - INFO -marigold_trainer.py - train >> iter   458 (epoch  1): loss=0.18344\n",
            " 2024-07-03 06:03:44,835 - INFO -marigold_trainer.py - train >> iter   459 (epoch  1): loss=0.30660\n",
            " 2024-07-03 06:03:49,254 - INFO -marigold_trainer.py - train >> iter   460 (epoch  1): loss=0.37902\n",
            " 2024-07-03 06:03:53,582 - INFO -marigold_trainer.py - train >> iter   461 (epoch  1): loss=0.32142\n",
            " 2024-07-03 06:03:57,895 - INFO -marigold_trainer.py - train >> iter   462 (epoch  1): loss=0.19921\n",
            " 2024-07-03 06:04:02,185 - INFO -marigold_trainer.py - train >> iter   463 (epoch  1): loss=0.23881\n",
            " 2024-07-03 06:04:06,486 - INFO -marigold_trainer.py - train >> iter   464 (epoch  1): loss=0.25729\n",
            " 2024-07-03 06:04:10,780 - INFO -marigold_trainer.py - train >> iter   465 (epoch  1): loss=0.32919\n",
            " 2024-07-03 06:04:15,087 - INFO -marigold_trainer.py - train >> iter   466 (epoch  1): loss=0.24830\n",
            " 2024-07-03 06:04:19,402 - INFO -marigold_trainer.py - train >> iter   467 (epoch  1): loss=0.20327\n",
            " 2024-07-03 06:04:23,693 - INFO -marigold_trainer.py - train >> iter   468 (epoch  1): loss=0.29723\n",
            " 2024-07-03 06:04:27,995 - INFO -marigold_trainer.py - train >> iter   469 (epoch  1): loss=0.25079\n",
            " 2024-07-03 06:04:32,312 - INFO -marigold_trainer.py - train >> iter   470 (epoch  1): loss=0.26871\n",
            " 2024-07-03 06:04:36,599 - INFO -marigold_trainer.py - train >> iter   471 (epoch  1): loss=0.25261\n",
            " 2024-07-03 06:04:40,897 - INFO -marigold_trainer.py - train >> iter   472 (epoch  1): loss=0.24612\n",
            " 2024-07-03 06:04:45,212 - INFO -marigold_trainer.py - train >> iter   473 (epoch  1): loss=0.29303\n",
            " 2024-07-03 06:04:49,581 - INFO -marigold_trainer.py - train >> iter   474 (epoch  1): loss=0.29578\n",
            " 2024-07-03 06:04:53,880 - INFO -marigold_trainer.py - train >> iter   475 (epoch  1): loss=0.27294\n",
            " 2024-07-03 06:04:58,200 - INFO -marigold_trainer.py - train >> iter   476 (epoch  1): loss=0.25808\n",
            " 2024-07-03 06:05:02,491 - INFO -marigold_trainer.py - train >> iter   477 (epoch  1): loss=0.30167\n",
            " 2024-07-03 06:05:06,794 - INFO -marigold_trainer.py - train >> iter   478 (epoch  1): loss=0.24901\n",
            " 2024-07-03 06:05:11,103 - INFO -marigold_trainer.py - train >> iter   479 (epoch  1): loss=0.22615\n",
            " 2024-07-03 06:05:15,597 - INFO -marigold_trainer.py - train >> iter   480 (epoch  1): loss=0.28595\n",
            " 2024-07-03 06:05:19,920 - INFO -marigold_trainer.py - train >> iter   481 (epoch  1): loss=0.26708\n",
            " 2024-07-03 06:05:24,227 - INFO -marigold_trainer.py - train >> iter   482 (epoch  1): loss=0.28796\n",
            " 2024-07-03 06:05:28,536 - INFO -marigold_trainer.py - train >> iter   483 (epoch  1): loss=0.29960\n",
            " 2024-07-03 06:05:32,859 - INFO -marigold_trainer.py - train >> iter   484 (epoch  1): loss=0.30789\n",
            " 2024-07-03 06:05:37,152 - INFO -marigold_trainer.py - train >> iter   485 (epoch  1): loss=0.29439\n",
            " 2024-07-03 06:05:41,469 - INFO -marigold_trainer.py - train >> iter   486 (epoch  1): loss=0.25575\n",
            " 2024-07-03 06:05:45,790 - INFO -marigold_trainer.py - train >> iter   487 (epoch  1): loss=0.27579\n",
            " 2024-07-03 06:05:50,195 - INFO -marigold_trainer.py - train >> iter   488 (epoch  1): loss=0.20107\n",
            " 2024-07-03 06:05:54,504 - INFO -marigold_trainer.py - train >> iter   489 (epoch  1): loss=0.23136\n",
            " 2024-07-03 06:05:58,823 - INFO -marigold_trainer.py - train >> iter   490 (epoch  1): loss=0.22870\n",
            " 2024-07-03 06:06:03,118 - INFO -marigold_trainer.py - train >> iter   491 (epoch  1): loss=0.21420\n",
            " 2024-07-03 06:06:07,421 - INFO -marigold_trainer.py - train >> iter   492 (epoch  1): loss=0.29789\n",
            " 2024-07-03 06:06:11,714 - INFO -marigold_trainer.py - train >> iter   493 (epoch  1): loss=0.27134\n",
            " 2024-07-03 06:06:16,002 - INFO -marigold_trainer.py - train >> iter   494 (epoch  1): loss=0.23753\n",
            " 2024-07-03 06:06:20,298 - INFO -marigold_trainer.py - train >> iter   495 (epoch  1): loss=0.27978\n",
            " 2024-07-03 06:06:24,574 - INFO -marigold_trainer.py - train >> iter   496 (epoch  1): loss=0.32236\n",
            " 2024-07-03 06:06:28,875 - INFO -marigold_trainer.py - train >> iter   497 (epoch  1): loss=0.33132\n",
            " 2024-07-03 06:06:33,168 - INFO -marigold_trainer.py - train >> iter   498 (epoch  1): loss=0.23779\n",
            " 2024-07-03 06:06:37,451 - INFO -marigold_trainer.py - train >> iter   499 (epoch  1): loss=0.27493\n",
            " 2024-07-03 06:06:41,766 - INFO -marigold_trainer.py - train >> iter   500 (epoch  1): loss=0.35667\n",
            " 2024-07-03 06:06:41,767 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:06:55,073 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:07:14,115 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:07:19,912 - INFO -marigold_trainer.py - train >> iter   501 (epoch  1): loss=0.23803\n",
            " 2024-07-03 06:07:24,220 - INFO -marigold_trainer.py - train >> iter   502 (epoch  1): loss=0.22883\n",
            " 2024-07-03 06:07:28,539 - INFO -marigold_trainer.py - train >> iter   503 (epoch  1): loss=0.25640\n",
            " 2024-07-03 06:07:32,863 - INFO -marigold_trainer.py - train >> iter   504 (epoch  1): loss=0.18793\n",
            " 2024-07-03 06:07:37,195 - INFO -marigold_trainer.py - train >> iter   505 (epoch  1): loss=0.27002\n",
            " 2024-07-03 06:07:41,502 - INFO -marigold_trainer.py - train >> iter   506 (epoch  1): loss=0.19535\n",
            " 2024-07-03 06:07:45,863 - INFO -marigold_trainer.py - train >> iter   507 (epoch  1): loss=0.31965\n",
            " 2024-07-03 06:07:50,206 - INFO -marigold_trainer.py - train >> iter   508 (epoch  1): loss=0.24309\n",
            " 2024-07-03 06:07:54,664 - INFO -marigold_trainer.py - train >> iter   509 (epoch  1): loss=0.22262\n",
            " 2024-07-03 06:07:59,024 - INFO -marigold_trainer.py - train >> iter   510 (epoch  1): loss=0.23341\n",
            " 2024-07-03 06:08:03,356 - INFO -marigold_trainer.py - train >> iter   511 (epoch  1): loss=0.23602\n",
            " 2024-07-03 06:08:07,679 - INFO -marigold_trainer.py - train >> iter   512 (epoch  1): loss=0.26717\n",
            " 2024-07-03 06:08:11,997 - INFO -marigold_trainer.py - train >> iter   513 (epoch  1): loss=0.32755\n",
            " 2024-07-03 06:08:16,316 - INFO -marigold_trainer.py - train >> iter   514 (epoch  1): loss=0.31840\n",
            " 2024-07-03 06:08:20,637 - INFO -marigold_trainer.py - train >> iter   515 (epoch  1): loss=0.27703\n",
            " 2024-07-03 06:08:24,952 - INFO -marigold_trainer.py - train >> iter   516 (epoch  1): loss=0.21715\n",
            " 2024-07-03 06:08:29,268 - INFO -marigold_trainer.py - train >> iter   517 (epoch  1): loss=0.22840\n",
            " 2024-07-03 06:08:33,641 - INFO -marigold_trainer.py - train >> iter   518 (epoch  1): loss=0.26403\n",
            " 2024-07-03 06:08:37,961 - INFO -marigold_trainer.py - train >> iter   519 (epoch  1): loss=0.30352\n",
            " 2024-07-03 06:08:42,261 - INFO -marigold_trainer.py - train >> iter   520 (epoch  1): loss=0.21220\n",
            " 2024-07-03 06:08:46,602 - INFO -marigold_trainer.py - train >> iter   521 (epoch  1): loss=0.25194\n",
            " 2024-07-03 06:08:50,906 - INFO -marigold_trainer.py - train >> iter   522 (epoch  1): loss=0.22724\n",
            " 2024-07-03 06:08:55,264 - INFO -marigold_trainer.py - train >> iter   523 (epoch  1): loss=0.24379\n",
            " 2024-07-03 06:08:59,605 - INFO -marigold_trainer.py - train >> iter   524 (epoch  1): loss=0.25617\n",
            " 2024-07-03 06:09:03,955 - INFO -marigold_trainer.py - train >> iter   525 (epoch  1): loss=0.27968\n",
            " 2024-07-03 06:09:08,306 - INFO -marigold_trainer.py - train >> iter   526 (epoch  1): loss=0.21445\n",
            " 2024-07-03 06:09:12,614 - INFO -marigold_trainer.py - train >> iter   527 (epoch  1): loss=0.28067\n",
            " 2024-07-03 06:09:16,928 - INFO -marigold_trainer.py - train >> iter   528 (epoch  1): loss=0.30131\n",
            " 2024-07-03 06:09:21,269 - INFO -marigold_trainer.py - train >> iter   529 (epoch  1): loss=0.26456\n",
            " 2024-07-03 06:09:25,577 - INFO -marigold_trainer.py - train >> iter   530 (epoch  1): loss=0.29602\n",
            " 2024-07-03 06:09:29,894 - INFO -marigold_trainer.py - train >> iter   531 (epoch  1): loss=0.20772\n",
            " 2024-07-03 06:09:34,251 - INFO -marigold_trainer.py - train >> iter   532 (epoch  1): loss=0.22817\n",
            " 2024-07-03 06:09:38,571 - INFO -marigold_trainer.py - train >> iter   533 (epoch  1): loss=0.20799\n",
            " 2024-07-03 06:09:42,895 - INFO -marigold_trainer.py - train >> iter   534 (epoch  1): loss=0.26776\n",
            " 2024-07-03 06:09:47,224 - INFO -marigold_trainer.py - train >> iter   535 (epoch  1): loss=0.24866\n",
            " 2024-07-03 06:09:51,549 - INFO -marigold_trainer.py - train >> iter   536 (epoch  1): loss=0.26242\n",
            " 2024-07-03 06:09:55,962 - INFO -marigold_trainer.py - train >> iter   537 (epoch  1): loss=0.27111\n",
            " 2024-07-03 06:10:00,295 - INFO -marigold_trainer.py - train >> iter   538 (epoch  1): loss=0.26768\n",
            " 2024-07-03 06:10:04,628 - INFO -marigold_trainer.py - train >> iter   539 (epoch  1): loss=0.26369\n",
            " 2024-07-03 06:10:08,963 - INFO -marigold_trainer.py - train >> iter   540 (epoch  1): loss=0.20948\n",
            " 2024-07-03 06:10:13,271 - INFO -marigold_trainer.py - train >> iter   541 (epoch  1): loss=0.22044\n",
            " 2024-07-03 06:10:17,618 - INFO -marigold_trainer.py - train >> iter   542 (epoch  1): loss=0.30690\n",
            " 2024-07-03 06:10:21,940 - INFO -marigold_trainer.py - train >> iter   543 (epoch  1): loss=0.30665\n",
            " 2024-07-03 06:10:26,254 - INFO -marigold_trainer.py - train >> iter   544 (epoch  1): loss=0.37276\n",
            " 2024-07-03 06:10:30,568 - INFO -marigold_trainer.py - train >> iter   545 (epoch  1): loss=0.24460\n",
            " 2024-07-03 06:10:34,886 - INFO -marigold_trainer.py - train >> iter   546 (epoch  1): loss=0.24857\n",
            " 2024-07-03 06:10:39,186 - INFO -marigold_trainer.py - train >> iter   547 (epoch  1): loss=0.29043\n",
            " 2024-07-03 06:10:43,492 - INFO -marigold_trainer.py - train >> iter   548 (epoch  1): loss=0.23425\n",
            " 2024-07-03 06:10:47,831 - INFO -marigold_trainer.py - train >> iter   549 (epoch  1): loss=0.27063\n",
            " 2024-07-03 06:10:52,141 - INFO -marigold_trainer.py - train >> iter   550 (epoch  1): loss=0.26428\n",
            " 2024-07-03 06:10:52,142 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:11:03,892 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:11:21,828 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:11:27,647 - INFO -marigold_trainer.py - train >> iter   551 (epoch  1): loss=0.26478\n",
            " 2024-07-03 06:11:31,962 - INFO -marigold_trainer.py - train >> iter   552 (epoch  1): loss=0.23897\n",
            " 2024-07-03 06:11:36,284 - INFO -marigold_trainer.py - train >> iter   553 (epoch  1): loss=0.28621\n",
            " 2024-07-03 06:11:40,584 - INFO -marigold_trainer.py - train >> iter   554 (epoch  1): loss=0.19717\n",
            " 2024-07-03 06:11:44,907 - INFO -marigold_trainer.py - train >> iter   555 (epoch  1): loss=0.26793\n",
            " 2024-07-03 06:11:49,222 - INFO -marigold_trainer.py - train >> iter   556 (epoch  1): loss=0.25419\n",
            " 2024-07-03 06:11:53,541 - INFO -marigold_trainer.py - train >> iter   557 (epoch  1): loss=0.22690\n",
            " 2024-07-03 06:11:57,980 - INFO -marigold_trainer.py - train >> iter   558 (epoch  1): loss=0.25409\n",
            " 2024-07-03 06:12:02,290 - INFO -marigold_trainer.py - train >> iter   559 (epoch  1): loss=0.28875\n",
            " 2024-07-03 06:12:06,613 - INFO -marigold_trainer.py - train >> iter   560 (epoch  1): loss=0.23232\n",
            " 2024-07-03 06:12:10,953 - INFO -marigold_trainer.py - train >> iter   561 (epoch  1): loss=0.24007\n",
            " 2024-07-03 06:12:15,249 - INFO -marigold_trainer.py - train >> iter   562 (epoch  1): loss=0.26608\n",
            " 2024-07-03 06:12:19,550 - INFO -marigold_trainer.py - train >> iter   563 (epoch  1): loss=0.28201\n",
            " 2024-07-03 06:12:23,857 - INFO -marigold_trainer.py - train >> iter   564 (epoch  1): loss=0.22013\n",
            " 2024-07-03 06:12:28,144 - INFO -marigold_trainer.py - train >> iter   565 (epoch  1): loss=0.25614\n",
            " 2024-07-03 06:12:32,448 - INFO -marigold_trainer.py - train >> iter   566 (epoch  1): loss=0.29046\n",
            " 2024-07-03 06:12:36,798 - INFO -marigold_trainer.py - train >> iter   567 (epoch  1): loss=0.23977\n",
            " 2024-07-03 06:12:41,100 - INFO -marigold_trainer.py - train >> iter   568 (epoch  1): loss=0.27362\n",
            " 2024-07-03 06:12:45,441 - INFO -marigold_trainer.py - train >> iter   569 (epoch  1): loss=0.26641\n",
            " 2024-07-03 06:12:49,747 - INFO -marigold_trainer.py - train >> iter   570 (epoch  1): loss=0.29168\n",
            " 2024-07-03 06:12:54,033 - INFO -marigold_trainer.py - train >> iter   571 (epoch  1): loss=0.29459\n",
            " 2024-07-03 06:12:58,326 - INFO -marigold_trainer.py - train >> iter   572 (epoch  1): loss=0.25008\n",
            " 2024-07-03 06:13:02,705 - INFO -marigold_trainer.py - train >> iter   573 (epoch  1): loss=0.26290\n",
            " 2024-07-03 06:13:06,993 - INFO -marigold_trainer.py - train >> iter   574 (epoch  1): loss=0.22960\n",
            " 2024-07-03 06:13:11,316 - INFO -marigold_trainer.py - train >> iter   575 (epoch  1): loss=0.21419\n",
            " 2024-07-03 06:13:15,643 - INFO -marigold_trainer.py - train >> iter   576 (epoch  1): loss=0.19985\n",
            " 2024-07-03 06:13:20,143 - INFO -marigold_trainer.py - train >> iter   577 (epoch  1): loss=0.32834\n",
            " 2024-07-03 06:13:24,447 - INFO -marigold_trainer.py - train >> iter   578 (epoch  1): loss=0.28939\n",
            " 2024-07-03 06:13:28,737 - INFO -marigold_trainer.py - train >> iter   579 (epoch  1): loss=0.26652\n",
            " 2024-07-03 06:13:33,047 - INFO -marigold_trainer.py - train >> iter   580 (epoch  1): loss=0.29085\n",
            " 2024-07-03 06:13:37,344 - INFO -marigold_trainer.py - train >> iter   581 (epoch  1): loss=0.24721\n",
            " 2024-07-03 06:13:41,638 - INFO -marigold_trainer.py - train >> iter   582 (epoch  1): loss=0.28927\n",
            " 2024-07-03 06:13:45,942 - INFO -marigold_trainer.py - train >> iter   583 (epoch  1): loss=0.21575\n",
            " 2024-07-03 06:13:50,235 - INFO -marigold_trainer.py - train >> iter   584 (epoch  1): loss=0.31277\n",
            " 2024-07-03 06:13:54,528 - INFO -marigold_trainer.py - train >> iter   585 (epoch  1): loss=0.25373\n",
            " 2024-07-03 06:13:58,834 - INFO -marigold_trainer.py - train >> iter   586 (epoch  1): loss=0.24093\n",
            " 2024-07-03 06:14:03,193 - INFO -marigold_trainer.py - train >> iter   587 (epoch  1): loss=0.21555\n",
            " 2024-07-03 06:14:07,476 - INFO -marigold_trainer.py - train >> iter   588 (epoch  1): loss=0.20583\n",
            " 2024-07-03 06:14:11,786 - INFO -marigold_trainer.py - train >> iter   589 (epoch  1): loss=0.24053\n",
            " 2024-07-03 06:14:16,082 - INFO -marigold_trainer.py - train >> iter   590 (epoch  1): loss=0.25398\n",
            " 2024-07-03 06:14:20,382 - INFO -marigold_trainer.py - train >> iter   591 (epoch  1): loss=0.28724\n",
            " 2024-07-03 06:14:24,680 - INFO -marigold_trainer.py - train >> iter   592 (epoch  1): loss=0.29596\n",
            " 2024-07-03 06:14:28,985 - INFO -marigold_trainer.py - train >> iter   593 (epoch  1): loss=0.19442\n",
            " 2024-07-03 06:14:33,326 - INFO -marigold_trainer.py - train >> iter   594 (epoch  1): loss=0.30009\n",
            " 2024-07-03 06:14:37,615 - INFO -marigold_trainer.py - train >> iter   595 (epoch  1): loss=0.24795\n",
            " 2024-07-03 06:14:41,916 - INFO -marigold_trainer.py - train >> iter   596 (epoch  1): loss=0.26952\n",
            " 2024-07-03 06:14:46,236 - INFO -marigold_trainer.py - train >> iter   597 (epoch  1): loss=0.21329\n",
            " 2024-07-03 06:14:50,527 - INFO -marigold_trainer.py - train >> iter   598 (epoch  1): loss=0.30465\n",
            " 2024-07-03 06:14:54,829 - INFO -marigold_trainer.py - train >> iter   599 (epoch  1): loss=0.31189\n",
            " 2024-07-03 06:14:59,156 - INFO -marigold_trainer.py - train >> iter   600 (epoch  1): loss=0.21459\n",
            " 2024-07-03 06:14:59,157 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:15:07,231 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:15:26,414 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:15:32,206 - INFO -marigold_trainer.py - train >> iter   601 (epoch  1): loss=0.22526\n",
            " 2024-07-03 06:15:36,503 - INFO -marigold_trainer.py - train >> iter   602 (epoch  1): loss=0.26531\n",
            " 2024-07-03 06:15:40,802 - INFO -marigold_trainer.py - train >> iter   603 (epoch  1): loss=0.24831\n",
            " 2024-07-03 06:15:45,114 - INFO -marigold_trainer.py - train >> iter   604 (epoch  1): loss=0.27153\n",
            " 2024-07-03 06:15:49,446 - INFO -marigold_trainer.py - train >> iter   605 (epoch  1): loss=0.28108\n",
            " 2024-07-03 06:15:53,780 - INFO -marigold_trainer.py - train >> iter   606 (epoch  1): loss=0.19335\n",
            " 2024-07-03 06:15:58,130 - INFO -marigold_trainer.py - train >> iter   607 (epoch  1): loss=0.18569\n",
            " 2024-07-03 06:16:02,452 - INFO -marigold_trainer.py - train >> iter   608 (epoch  1): loss=0.23637\n",
            " 2024-07-03 06:16:06,897 - INFO -marigold_trainer.py - train >> iter   609 (epoch  1): loss=0.23532\n",
            " 2024-07-03 06:16:11,229 - INFO -marigold_trainer.py - train >> iter   610 (epoch  1): loss=0.24483\n",
            " 2024-07-03 06:16:15,534 - INFO -marigold_trainer.py - train >> iter   611 (epoch  1): loss=0.18813\n",
            " 2024-07-03 06:16:19,843 - INFO -marigold_trainer.py - train >> iter   612 (epoch  1): loss=0.28475\n",
            " 2024-07-03 06:16:24,150 - INFO -marigold_trainer.py - train >> iter   613 (epoch  1): loss=0.29064\n",
            " 2024-07-03 06:16:28,442 - INFO -marigold_trainer.py - train >> iter   614 (epoch  1): loss=0.25619\n",
            " 2024-07-03 06:16:32,743 - INFO -marigold_trainer.py - train >> iter   615 (epoch  1): loss=0.25100\n",
            " 2024-07-03 06:16:37,036 - INFO -marigold_trainer.py - train >> iter   616 (epoch  1): loss=0.27299\n",
            " 2024-07-03 06:16:41,326 - INFO -marigold_trainer.py - train >> iter   617 (epoch  1): loss=0.24127\n",
            " 2024-07-03 06:16:45,613 - INFO -marigold_trainer.py - train >> iter   618 (epoch  1): loss=0.25680\n",
            " 2024-07-03 06:16:49,903 - INFO -marigold_trainer.py - train >> iter   619 (epoch  1): loss=0.23150\n",
            " 2024-07-03 06:16:54,188 - INFO -marigold_trainer.py - train >> iter   620 (epoch  1): loss=0.26513\n",
            " 2024-07-03 06:16:58,490 - INFO -marigold_trainer.py - train >> iter   621 (epoch  1): loss=0.23800\n",
            " 2024-07-03 06:17:02,806 - INFO -marigold_trainer.py - train >> iter   622 (epoch  1): loss=0.25750\n",
            " 2024-07-03 06:17:07,186 - INFO -marigold_trainer.py - train >> iter   623 (epoch  1): loss=0.20979\n",
            " 2024-07-03 06:17:11,493 - INFO -marigold_trainer.py - train >> iter   624 (epoch  1): loss=0.23051\n",
            " 2024-07-03 06:17:15,788 - INFO -marigold_trainer.py - train >> iter   625 (epoch  1): loss=0.22072\n",
            " 2024-07-03 06:17:20,102 - INFO -marigold_trainer.py - train >> iter   626 (epoch  1): loss=0.28929\n",
            " 2024-07-03 06:17:24,423 - INFO -marigold_trainer.py - train >> iter   627 (epoch  1): loss=0.28520\n",
            " 2024-07-03 06:17:28,728 - INFO -marigold_trainer.py - train >> iter   628 (epoch  1): loss=0.26567\n",
            " 2024-07-03 06:17:33,064 - INFO -marigold_trainer.py - train >> iter   629 (epoch  1): loss=0.23830\n",
            " 2024-07-03 06:17:37,389 - INFO -marigold_trainer.py - train >> iter   630 (epoch  1): loss=0.34179\n",
            " 2024-07-03 06:17:41,687 - INFO -marigold_trainer.py - train >> iter   631 (epoch  1): loss=0.31293\n",
            " 2024-07-03 06:17:45,999 - INFO -marigold_trainer.py - train >> iter   632 (epoch  1): loss=0.23205\n",
            " 2024-07-03 06:17:50,322 - INFO -marigold_trainer.py - train >> iter   633 (epoch  1): loss=0.23908\n",
            " 2024-07-03 06:17:54,621 - INFO -marigold_trainer.py - train >> iter   634 (epoch  1): loss=0.24279\n",
            " 2024-07-03 06:17:58,926 - INFO -marigold_trainer.py - train >> iter   635 (epoch  1): loss=0.27393\n",
            " 2024-07-03 06:18:03,210 - INFO -marigold_trainer.py - train >> iter   636 (epoch  1): loss=0.27827\n",
            " 2024-07-03 06:18:07,607 - INFO -marigold_trainer.py - train >> iter   637 (epoch  1): loss=0.21003\n",
            " 2024-07-03 06:18:11,911 - INFO -marigold_trainer.py - train >> iter   638 (epoch  1): loss=0.20703\n",
            " 2024-07-03 06:18:16,226 - INFO -marigold_trainer.py - train >> iter   639 (epoch  1): loss=0.27501\n",
            " 2024-07-03 06:18:20,543 - INFO -marigold_trainer.py - train >> iter   640 (epoch  1): loss=0.22651\n",
            " 2024-07-03 06:18:24,859 - INFO -marigold_trainer.py - train >> iter   641 (epoch  1): loss=0.21957\n",
            " 2024-07-03 06:18:29,181 - INFO -marigold_trainer.py - train >> iter   642 (epoch  1): loss=0.26324\n",
            " 2024-07-03 06:18:33,499 - INFO -marigold_trainer.py - train >> iter   643 (epoch  1): loss=0.24742\n",
            " 2024-07-03 06:18:37,809 - INFO -marigold_trainer.py - train >> iter   644 (epoch  1): loss=0.21281\n",
            " 2024-07-03 06:18:42,100 - INFO -marigold_trainer.py - train >> iter   645 (epoch  1): loss=0.23478\n",
            " 2024-07-03 06:18:46,415 - INFO -marigold_trainer.py - train >> iter   646 (epoch  1): loss=0.28736\n",
            " 2024-07-03 06:18:50,717 - INFO -marigold_trainer.py - train >> iter   647 (epoch  1): loss=0.26559\n",
            " 2024-07-03 06:18:55,009 - INFO -marigold_trainer.py - train >> iter   648 (epoch  1): loss=0.21366\n",
            " 2024-07-03 06:18:59,315 - INFO -marigold_trainer.py - train >> iter   649 (epoch  1): loss=0.27197\n",
            " 2024-07-03 06:19:03,627 - INFO -marigold_trainer.py - train >> iter   650 (epoch  1): loss=0.18959\n",
            " 2024-07-03 06:19:03,628 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:19:17,195 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:19:35,086 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:19:40,903 - INFO -marigold_trainer.py - train >> iter   651 (epoch  1): loss=0.25546\n",
            " 2024-07-03 06:19:45,224 - INFO -marigold_trainer.py - train >> iter   652 (epoch  1): loss=0.24608\n",
            " 2024-07-03 06:19:49,523 - INFO -marigold_trainer.py - train >> iter   653 (epoch  1): loss=0.22864\n",
            " 2024-07-03 06:19:53,823 - INFO -marigold_trainer.py - train >> iter   654 (epoch  1): loss=0.29148\n",
            " 2024-07-03 06:19:58,159 - INFO -marigold_trainer.py - train >> iter   655 (epoch  1): loss=0.26127\n",
            " 2024-07-03 06:20:02,503 - INFO -marigold_trainer.py - train >> iter   656 (epoch  1): loss=0.20465\n",
            " 2024-07-03 06:20:06,828 - INFO -marigold_trainer.py - train >> iter   657 (epoch  1): loss=0.23736\n",
            " 2024-07-03 06:20:11,267 - INFO -marigold_trainer.py - train >> iter   658 (epoch  1): loss=0.23322\n",
            " 2024-07-03 06:20:15,567 - INFO -marigold_trainer.py - train >> iter   659 (epoch  1): loss=0.26318\n",
            " 2024-07-03 06:20:19,876 - INFO -marigold_trainer.py - train >> iter   660 (epoch  1): loss=0.18915\n",
            " 2024-07-03 06:20:24,190 - INFO -marigold_trainer.py - train >> iter   661 (epoch  1): loss=0.22601\n",
            " 2024-07-03 06:20:28,496 - INFO -marigold_trainer.py - train >> iter   662 (epoch  1): loss=0.21865\n",
            " 2024-07-03 06:20:32,828 - INFO -marigold_trainer.py - train >> iter   663 (epoch  1): loss=0.21227\n",
            " 2024-07-03 06:20:37,144 - INFO -marigold_trainer.py - train >> iter   664 (epoch  1): loss=0.23451\n",
            " 2024-07-03 06:20:41,448 - INFO -marigold_trainer.py - train >> iter   665 (epoch  1): loss=0.23092\n",
            " 2024-07-03 06:20:45,744 - INFO -marigold_trainer.py - train >> iter   666 (epoch  1): loss=0.18750\n",
            " 2024-07-03 06:20:50,034 - INFO -marigold_trainer.py - train >> iter   667 (epoch  1): loss=0.21496\n",
            " 2024-07-03 06:20:54,344 - INFO -marigold_trainer.py - train >> iter   668 (epoch  1): loss=0.19299\n",
            " 2024-07-03 06:20:58,661 - INFO -marigold_trainer.py - train >> iter   669 (epoch  1): loss=0.20454\n",
            " 2024-07-03 06:21:02,956 - INFO -marigold_trainer.py - train >> iter   670 (epoch  1): loss=0.23814\n",
            " 2024-07-03 06:21:07,252 - INFO -marigold_trainer.py - train >> iter   671 (epoch  1): loss=0.24218\n",
            " 2024-07-03 06:21:11,637 - INFO -marigold_trainer.py - train >> iter   672 (epoch  1): loss=0.25991\n",
            " 2024-07-03 06:21:15,927 - INFO -marigold_trainer.py - train >> iter   673 (epoch  1): loss=0.25760\n",
            " 2024-07-03 06:21:20,223 - INFO -marigold_trainer.py - train >> iter   674 (epoch  1): loss=0.23626\n",
            " 2024-07-03 06:21:24,509 - INFO -marigold_trainer.py - train >> iter   675 (epoch  1): loss=0.27993\n",
            " 2024-07-03 06:21:28,812 - INFO -marigold_trainer.py - train >> iter   676 (epoch  1): loss=0.17405\n",
            " 2024-07-03 06:21:33,127 - INFO -marigold_trainer.py - train >> iter   677 (epoch  1): loss=0.15824\n",
            " 2024-07-03 06:21:37,422 - INFO -marigold_trainer.py - train >> iter   678 (epoch  1): loss=0.18231\n",
            " 2024-07-03 06:21:41,719 - INFO -marigold_trainer.py - train >> iter   679 (epoch  1): loss=0.26367\n",
            " 2024-07-03 06:21:46,225 - INFO -marigold_trainer.py - train >> iter   680 (epoch  1): loss=0.22135\n",
            " 2024-07-03 06:21:50,521 - INFO -marigold_trainer.py - train >> iter   681 (epoch  1): loss=0.19619\n",
            " 2024-07-03 06:21:54,819 - INFO -marigold_trainer.py - train >> iter   682 (epoch  1): loss=0.17324\n",
            " 2024-07-03 06:21:59,145 - INFO -marigold_trainer.py - train >> iter   683 (epoch  1): loss=0.16803\n",
            " 2024-07-03 06:22:03,459 - INFO -marigold_trainer.py - train >> iter   684 (epoch  1): loss=0.25463\n",
            " 2024-07-03 06:22:07,774 - INFO -marigold_trainer.py - train >> iter   685 (epoch  1): loss=0.27391\n",
            " 2024-07-03 06:22:12,171 - INFO -marigold_trainer.py - train >> iter   686 (epoch  1): loss=0.18767\n",
            " 2024-07-03 06:22:16,468 - INFO -marigold_trainer.py - train >> iter   687 (epoch  1): loss=0.24263\n",
            " 2024-07-03 06:22:20,754 - INFO -marigold_trainer.py - train >> iter   688 (epoch  1): loss=0.25562\n",
            " 2024-07-03 06:22:25,055 - INFO -marigold_trainer.py - train >> iter   689 (epoch  1): loss=0.17234\n",
            " 2024-07-03 06:22:29,353 - INFO -marigold_trainer.py - train >> iter   690 (epoch  1): loss=0.21843\n",
            " 2024-07-03 06:22:33,660 - INFO -marigold_trainer.py - train >> iter   691 (epoch  1): loss=0.22470\n",
            " 2024-07-03 06:22:37,960 - INFO -marigold_trainer.py - train >> iter   692 (epoch  1): loss=0.24446\n",
            " 2024-07-03 06:22:42,277 - INFO -marigold_trainer.py - train >> iter   693 (epoch  1): loss=0.14358\n",
            " 2024-07-03 06:22:46,602 - INFO -marigold_trainer.py - train >> iter   694 (epoch  1): loss=0.18926\n",
            " 2024-07-03 06:22:50,930 - INFO -marigold_trainer.py - train >> iter   695 (epoch  1): loss=0.22946\n",
            " 2024-07-03 06:22:55,250 - INFO -marigold_trainer.py - train >> iter   696 (epoch  1): loss=0.21417\n",
            " 2024-07-03 06:22:59,582 - INFO -marigold_trainer.py - train >> iter   697 (epoch  1): loss=0.20379\n",
            " 2024-07-03 06:23:03,886 - INFO -marigold_trainer.py - train >> iter   698 (epoch  1): loss=0.28412\n",
            " 2024-07-03 06:23:08,202 - INFO -marigold_trainer.py - train >> iter   699 (epoch  1): loss=0.21670\n",
            " 2024-07-03 06:23:12,524 - INFO -marigold_trainer.py - train >> iter   700 (epoch  1): loss=0.20019\n",
            " 2024-07-03 06:23:12,525 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:23:22,038 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:23:43,247 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:23:49,047 - INFO -marigold_trainer.py - train >> iter   701 (epoch  1): loss=0.18155\n",
            " 2024-07-03 06:23:53,369 - INFO -marigold_trainer.py - train >> iter   702 (epoch  1): loss=0.22809\n",
            " 2024-07-03 06:23:57,688 - INFO -marigold_trainer.py - train >> iter   703 (epoch  1): loss=0.20145\n",
            " 2024-07-03 06:24:02,030 - INFO -marigold_trainer.py - train >> iter   704 (epoch  1): loss=0.19332\n",
            " 2024-07-03 06:24:06,372 - INFO -marigold_trainer.py - train >> iter   705 (epoch  1): loss=0.22459\n",
            " 2024-07-03 06:24:10,706 - INFO -marigold_trainer.py - train >> iter   706 (epoch  1): loss=0.20164\n",
            " 2024-07-03 06:24:15,153 - INFO -marigold_trainer.py - train >> iter   707 (epoch  1): loss=0.28169\n",
            " 2024-07-03 06:24:19,519 - INFO -marigold_trainer.py - train >> iter   708 (epoch  1): loss=0.17456\n",
            " 2024-07-03 06:24:23,881 - INFO -marigold_trainer.py - train >> iter   709 (epoch  1): loss=0.19151\n",
            " 2024-07-03 06:24:28,199 - INFO -marigold_trainer.py - train >> iter   710 (epoch  1): loss=0.25241\n",
            " 2024-07-03 06:24:32,528 - INFO -marigold_trainer.py - train >> iter   711 (epoch  1): loss=0.22411\n",
            " 2024-07-03 06:24:36,836 - INFO -marigold_trainer.py - train >> iter   712 (epoch  1): loss=0.20253\n",
            " 2024-07-03 06:24:41,175 - INFO -marigold_trainer.py - train >> iter   713 (epoch  1): loss=0.21564\n",
            " 2024-07-03 06:24:45,500 - INFO -marigold_trainer.py - train >> iter   714 (epoch  1): loss=0.19809\n",
            " 2024-07-03 06:24:49,809 - INFO -marigold_trainer.py - train >> iter   715 (epoch  1): loss=0.22698\n",
            " 2024-07-03 06:24:54,105 - INFO -marigold_trainer.py - train >> iter   716 (epoch  1): loss=0.21425\n",
            " 2024-07-03 06:24:58,429 - INFO -marigold_trainer.py - train >> iter   717 (epoch  1): loss=0.20676\n",
            " 2024-07-03 06:25:02,735 - INFO -marigold_trainer.py - train >> iter   718 (epoch  1): loss=0.20787\n",
            " 2024-07-03 06:25:07,040 - INFO -marigold_trainer.py - train >> iter   719 (epoch  1): loss=0.20081\n",
            " 2024-07-03 06:25:11,353 - INFO -marigold_trainer.py - train >> iter   720 (epoch  1): loss=0.24192\n",
            " 2024-07-03 06:25:15,679 - INFO -marigold_trainer.py - train >> iter   721 (epoch  1): loss=0.16971\n",
            " 2024-07-03 06:25:20,038 - INFO -marigold_trainer.py - train >> iter   722 (epoch  1): loss=0.18909\n",
            " 2024-07-03 06:25:24,364 - INFO -marigold_trainer.py - train >> iter   723 (epoch  1): loss=0.26059\n",
            " 2024-07-03 06:25:28,672 - INFO -marigold_trainer.py - train >> iter   724 (epoch  1): loss=0.24614\n",
            " 2024-07-03 06:25:32,996 - INFO -marigold_trainer.py - train >> iter   725 (epoch  1): loss=0.21575\n",
            " 2024-07-03 06:25:37,315 - INFO -marigold_trainer.py - train >> iter   726 (epoch  1): loss=0.26060\n",
            " 2024-07-03 06:25:41,633 - INFO -marigold_trainer.py - train >> iter   727 (epoch  1): loss=0.20453\n",
            " 2024-07-03 06:25:45,949 - INFO -marigold_trainer.py - train >> iter   728 (epoch  1): loss=0.17001\n",
            " 2024-07-03 06:25:50,264 - INFO -marigold_trainer.py - train >> iter   729 (epoch  1): loss=0.21511\n",
            " 2024-07-03 06:25:54,587 - INFO -marigold_trainer.py - train >> iter   730 (epoch  1): loss=0.16420\n",
            " 2024-07-03 06:25:58,922 - INFO -marigold_trainer.py - train >> iter   731 (epoch  1): loss=0.20499\n",
            " 2024-07-03 06:26:03,235 - INFO -marigold_trainer.py - train >> iter   732 (epoch  1): loss=0.21448\n",
            " 2024-07-03 06:26:07,540 - INFO -marigold_trainer.py - train >> iter   733 (epoch  1): loss=0.12583\n",
            " 2024-07-03 06:26:11,880 - INFO -marigold_trainer.py - train >> iter   734 (epoch  1): loss=0.19036\n",
            " 2024-07-03 06:26:16,176 - INFO -marigold_trainer.py - train >> iter   735 (epoch  1): loss=0.21217\n",
            " 2024-07-03 06:26:20,567 - INFO -marigold_trainer.py - train >> iter   736 (epoch  1): loss=0.20698\n",
            " 2024-07-03 06:26:24,871 - INFO -marigold_trainer.py - train >> iter   737 (epoch  1): loss=0.19876\n",
            " 2024-07-03 06:26:29,168 - INFO -marigold_trainer.py - train >> iter   738 (epoch  1): loss=0.19167\n",
            " 2024-07-03 06:26:33,494 - INFO -marigold_trainer.py - train >> iter   739 (epoch  1): loss=0.19678\n",
            " 2024-07-03 06:26:37,795 - INFO -marigold_trainer.py - train >> iter   740 (epoch  1): loss=0.17927\n",
            " 2024-07-03 06:26:42,094 - INFO -marigold_trainer.py - train >> iter   741 (epoch  1): loss=0.20131\n",
            " 2024-07-03 06:26:46,411 - INFO -marigold_trainer.py - train >> iter   742 (epoch  1): loss=0.15540\n",
            " 2024-07-03 06:26:50,707 - INFO -marigold_trainer.py - train >> iter   743 (epoch  1): loss=0.25180\n",
            " 2024-07-03 06:26:55,005 - INFO -marigold_trainer.py - train >> iter   744 (epoch  1): loss=0.15781\n",
            " 2024-07-03 06:26:59,302 - INFO -marigold_trainer.py - train >> iter   745 (epoch  1): loss=0.18637\n",
            " 2024-07-03 06:27:03,619 - INFO -marigold_trainer.py - train >> iter   746 (epoch  1): loss=0.18185\n",
            " 2024-07-03 06:27:07,922 - INFO -marigold_trainer.py - train >> iter   747 (epoch  1): loss=0.23182\n",
            " 2024-07-03 06:27:12,217 - INFO -marigold_trainer.py - train >> iter   748 (epoch  1): loss=0.12314\n",
            " 2024-07-03 06:27:16,518 - INFO -marigold_trainer.py - train >> iter   749 (epoch  1): loss=0.13710\n",
            " 2024-07-03 06:27:20,909 - INFO -marigold_trainer.py - train >> iter   750 (epoch  1): loss=0.24010\n",
            " 2024-07-03 06:27:20,910 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:27:28,926 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:27:48,163 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:27:53,950 - INFO -marigold_trainer.py - train >> iter   751 (epoch  1): loss=0.14980\n",
            " 2024-07-03 06:27:58,248 - INFO -marigold_trainer.py - train >> iter   752 (epoch  1): loss=0.19666\n",
            " 2024-07-03 06:28:02,573 - INFO -marigold_trainer.py - train >> iter   753 (epoch  1): loss=0.14722\n",
            " 2024-07-03 06:28:06,886 - INFO -marigold_trainer.py - train >> iter   754 (epoch  1): loss=0.18361\n",
            " 2024-07-03 06:28:11,206 - INFO -marigold_trainer.py - train >> iter   755 (epoch  1): loss=0.25513\n",
            " 2024-07-03 06:28:15,542 - INFO -marigold_trainer.py - train >> iter   756 (epoch  1): loss=0.17248\n",
            " 2024-07-03 06:28:19,865 - INFO -marigold_trainer.py - train >> iter   757 (epoch  1): loss=0.19573\n",
            " 2024-07-03 06:28:24,298 - INFO -marigold_trainer.py - train >> iter   758 (epoch  1): loss=0.23020\n",
            " 2024-07-03 06:28:28,627 - INFO -marigold_trainer.py - train >> iter   759 (epoch  1): loss=0.18932\n",
            " 2024-07-03 06:28:32,960 - INFO -marigold_trainer.py - train >> iter   760 (epoch  1): loss=0.15181\n",
            " 2024-07-03 06:28:37,267 - INFO -marigold_trainer.py - train >> iter   761 (epoch  1): loss=0.20290\n",
            " 2024-07-03 06:28:41,567 - INFO -marigold_trainer.py - train >> iter   762 (epoch  1): loss=0.18924\n",
            " 2024-07-03 06:28:45,902 - INFO -marigold_trainer.py - train >> iter   763 (epoch  1): loss=0.20625\n",
            " 2024-07-03 06:28:50,206 - INFO -marigold_trainer.py - train >> iter   764 (epoch  1): loss=0.19651\n",
            " 2024-07-03 06:28:54,508 - INFO -marigold_trainer.py - train >> iter   765 (epoch  1): loss=0.18510\n",
            " 2024-07-03 06:28:58,816 - INFO -marigold_trainer.py - train >> iter   766 (epoch  1): loss=0.15676\n",
            " 2024-07-03 06:29:03,113 - INFO -marigold_trainer.py - train >> iter   767 (epoch  1): loss=0.21143\n",
            " 2024-07-03 06:29:07,408 - INFO -marigold_trainer.py - train >> iter   768 (epoch  1): loss=0.12867\n",
            " 2024-07-03 06:29:11,714 - INFO -marigold_trainer.py - train >> iter   769 (epoch  1): loss=0.18200\n",
            " 2024-07-03 06:29:16,016 - INFO -marigold_trainer.py - train >> iter   770 (epoch  1): loss=0.21842\n",
            " 2024-07-03 06:29:20,325 - INFO -marigold_trainer.py - train >> iter   771 (epoch  1): loss=0.15461\n",
            " 2024-07-03 06:29:24,704 - INFO -marigold_trainer.py - train >> iter   772 (epoch  1): loss=0.19424\n",
            " 2024-07-03 06:29:28,988 - INFO -marigold_trainer.py - train >> iter   773 (epoch  1): loss=0.17438\n",
            " 2024-07-03 06:29:33,318 - INFO -marigold_trainer.py - train >> iter   774 (epoch  1): loss=0.15403\n",
            " 2024-07-03 06:29:37,605 - INFO -marigold_trainer.py - train >> iter   775 (epoch  1): loss=0.15995\n",
            " 2024-07-03 06:29:41,910 - INFO -marigold_trainer.py - train >> iter   776 (epoch  1): loss=0.14763\n",
            " 2024-07-03 06:29:46,214 - INFO -marigold_trainer.py - train >> iter   777 (epoch  1): loss=0.19164\n",
            " 2024-07-03 06:29:50,512 - INFO -marigold_trainer.py - train >> iter   778 (epoch  1): loss=0.15798\n",
            " 2024-07-03 06:29:54,832 - INFO -marigold_trainer.py - train >> iter   779 (epoch  1): loss=0.14699\n",
            " 2024-07-03 06:29:59,381 - INFO -marigold_trainer.py - train >> iter   780 (epoch  1): loss=0.14980\n",
            " 2024-07-03 06:30:03,676 - INFO -marigold_trainer.py - train >> iter   781 (epoch  1): loss=0.18641\n",
            " 2024-07-03 06:30:07,973 - INFO -marigold_trainer.py - train >> iter   782 (epoch  1): loss=0.14929\n",
            " 2024-07-03 06:30:12,275 - INFO -marigold_trainer.py - train >> iter   783 (epoch  1): loss=0.12747\n",
            " 2024-07-03 06:30:16,593 - INFO -marigold_trainer.py - train >> iter   784 (epoch  1): loss=0.20464\n",
            " 2024-07-03 06:30:20,895 - INFO -marigold_trainer.py - train >> iter   785 (epoch  1): loss=0.14185\n",
            " 2024-07-03 06:30:25,239 - INFO -marigold_trainer.py - train >> iter   786 (epoch  1): loss=0.17296\n",
            " 2024-07-03 06:30:29,536 - INFO -marigold_trainer.py - train >> iter   787 (epoch  1): loss=0.23333\n",
            " 2024-07-03 06:30:33,850 - INFO -marigold_trainer.py - train >> iter   788 (epoch  1): loss=0.15800\n",
            " 2024-07-03 06:30:38,157 - INFO -marigold_trainer.py - train >> iter   789 (epoch  1): loss=0.13375\n",
            " 2024-07-03 06:30:42,445 - INFO -marigold_trainer.py - train >> iter   790 (epoch  1): loss=0.21215\n",
            " 2024-07-03 06:30:46,754 - INFO -marigold_trainer.py - train >> iter   791 (epoch  1): loss=0.15400\n",
            " 2024-07-03 06:30:51,040 - INFO -marigold_trainer.py - train >> iter   792 (epoch  1): loss=0.17847\n",
            " 2024-07-03 06:30:55,346 - INFO -marigold_trainer.py - train >> iter   793 (epoch  1): loss=0.14500\n",
            " 2024-07-03 06:30:59,630 - INFO -marigold_trainer.py - train >> iter   794 (epoch  1): loss=0.19559\n",
            " 2024-07-03 06:31:03,922 - INFO -marigold_trainer.py - train >> iter   795 (epoch  1): loss=0.15234\n",
            " 2024-07-03 06:31:08,220 - INFO -marigold_trainer.py - train >> iter   796 (epoch  1): loss=0.16415\n",
            " 2024-07-03 06:31:12,517 - INFO -marigold_trainer.py - train >> iter   797 (epoch  1): loss=0.16783\n",
            " 2024-07-03 06:31:16,826 - INFO -marigold_trainer.py - train >> iter   798 (epoch  1): loss=0.18908\n",
            " 2024-07-03 06:31:21,144 - INFO -marigold_trainer.py - train >> iter   799 (epoch  1): loss=0.21537\n",
            " 2024-07-03 06:31:25,487 - INFO -marigold_trainer.py - train >> iter   800 (epoch  1): loss=0.19177\n",
            " 2024-07-03 06:31:25,488 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:31:38,197 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:31:56,799 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:32:02,643 - INFO -marigold_trainer.py - train >> iter   801 (epoch  1): loss=0.16063\n",
            " 2024-07-03 06:32:06,951 - INFO -marigold_trainer.py - train >> iter   802 (epoch  1): loss=0.13160\n",
            " 2024-07-03 06:32:11,268 - INFO -marigold_trainer.py - train >> iter   803 (epoch  1): loss=0.20184\n",
            " 2024-07-03 06:32:15,563 - INFO -marigold_trainer.py - train >> iter   804 (epoch  1): loss=0.17596\n",
            " 2024-07-03 06:32:19,886 - INFO -marigold_trainer.py - train >> iter   805 (epoch  1): loss=0.19678\n",
            " 2024-07-03 06:32:24,211 - INFO -marigold_trainer.py - train >> iter   806 (epoch  1): loss=0.16973\n",
            " 2024-07-03 06:32:28,618 - INFO -marigold_trainer.py - train >> iter   807 (epoch  1): loss=0.14937\n",
            " 2024-07-03 06:32:32,921 - INFO -marigold_trainer.py - train >> iter   808 (epoch  1): loss=0.13487\n",
            " 2024-07-03 06:32:37,217 - INFO -marigold_trainer.py - train >> iter   809 (epoch  1): loss=0.20316\n",
            " 2024-07-03 06:32:41,519 - INFO -marigold_trainer.py - train >> iter   810 (epoch  1): loss=0.15153\n",
            " 2024-07-03 06:32:45,835 - INFO -marigold_trainer.py - train >> iter   811 (epoch  1): loss=0.23216\n",
            " 2024-07-03 06:32:50,144 - INFO -marigold_trainer.py - train >> iter   812 (epoch  1): loss=0.24296\n",
            " 2024-07-03 06:32:54,442 - INFO -marigold_trainer.py - train >> iter   813 (epoch  1): loss=0.17879\n",
            " 2024-07-03 06:32:58,749 - INFO -marigold_trainer.py - train >> iter   814 (epoch  1): loss=0.18282\n",
            " 2024-07-03 06:33:03,026 - INFO -marigold_trainer.py - train >> iter   815 (epoch  1): loss=0.18035\n",
            " 2024-07-03 06:33:07,336 - INFO -marigold_trainer.py - train >> iter   816 (epoch  1): loss=0.17279\n",
            " 2024-07-03 06:33:11,620 - INFO -marigold_trainer.py - train >> iter   817 (epoch  1): loss=0.14236\n",
            " 2024-07-03 06:33:15,916 - INFO -marigold_trainer.py - train >> iter   818 (epoch  1): loss=0.18900\n",
            " 2024-07-03 06:33:20,235 - INFO -marigold_trainer.py - train >> iter   819 (epoch  1): loss=0.17473\n",
            " 2024-07-03 06:33:24,519 - INFO -marigold_trainer.py - train >> iter   820 (epoch  1): loss=0.15953\n",
            " 2024-07-03 06:33:28,832 - INFO -marigold_trainer.py - train >> iter   821 (epoch  1): loss=0.19487\n",
            " 2024-07-03 06:33:33,132 - INFO -marigold_trainer.py - train >> iter   822 (epoch  1): loss=0.19831\n",
            " 2024-07-03 06:33:37,422 - INFO -marigold_trainer.py - train >> iter   823 (epoch  1): loss=0.18982\n",
            " 2024-07-03 06:33:41,714 - INFO -marigold_trainer.py - train >> iter   824 (epoch  1): loss=0.15176\n",
            " 2024-07-03 06:33:46,045 - INFO -marigold_trainer.py - train >> iter   825 (epoch  1): loss=0.17313\n",
            " 2024-07-03 06:33:50,350 - INFO -marigold_trainer.py - train >> iter   826 (epoch  1): loss=0.12965\n",
            " 2024-07-03 06:33:54,653 - INFO -marigold_trainer.py - train >> iter   827 (epoch  1): loss=0.15022\n",
            " 2024-07-03 06:33:58,977 - INFO -marigold_trainer.py - train >> iter   828 (epoch  1): loss=0.15560\n",
            " 2024-07-03 06:34:03,265 - INFO -marigold_trainer.py - train >> iter   829 (epoch  1): loss=0.15203\n",
            " 2024-07-03 06:34:07,581 - INFO -marigold_trainer.py - train >> iter   830 (epoch  1): loss=0.12753\n",
            " 2024-07-03 06:34:11,886 - INFO -marigold_trainer.py - train >> iter   831 (epoch  1): loss=0.16801\n",
            " 2024-07-03 06:34:16,207 - INFO -marigold_trainer.py - train >> iter   832 (epoch  1): loss=0.20630\n",
            " 2024-07-03 06:34:20,529 - INFO -marigold_trainer.py - train >> iter   833 (epoch  1): loss=0.16055\n",
            " 2024-07-03 06:34:24,851 - INFO -marigold_trainer.py - train >> iter   834 (epoch  1): loss=0.13030\n",
            " 2024-07-03 06:34:29,218 - INFO -marigold_trainer.py - train >> iter   835 (epoch  1): loss=0.13576\n",
            " 2024-07-03 06:34:33,531 - INFO -marigold_trainer.py - train >> iter   836 (epoch  1): loss=0.14877\n",
            " 2024-07-03 06:34:37,845 - INFO -marigold_trainer.py - train >> iter   837 (epoch  1): loss=0.17013\n",
            " 2024-07-03 06:34:42,144 - INFO -marigold_trainer.py - train >> iter   838 (epoch  1): loss=0.15349\n",
            " 2024-07-03 06:34:46,451 - INFO -marigold_trainer.py - train >> iter   839 (epoch  1): loss=0.19401\n",
            " 2024-07-03 06:34:50,734 - INFO -marigold_trainer.py - train >> iter   840 (epoch  1): loss=0.19014\n",
            " 2024-07-03 06:34:55,027 - INFO -marigold_trainer.py - train >> iter   841 (epoch  1): loss=0.15251\n",
            " 2024-07-03 06:34:59,331 - INFO -marigold_trainer.py - train >> iter   842 (epoch  1): loss=0.13535\n",
            " 2024-07-03 06:35:03,632 - INFO -marigold_trainer.py - train >> iter   843 (epoch  1): loss=0.17521\n",
            " 2024-07-03 06:35:07,960 - INFO -marigold_trainer.py - train >> iter   844 (epoch  1): loss=0.12211\n",
            " 2024-07-03 06:35:12,238 - INFO -marigold_trainer.py - train >> iter   845 (epoch  1): loss=0.13404\n",
            " 2024-07-03 06:35:16,540 - INFO -marigold_trainer.py - train >> iter   846 (epoch  1): loss=0.15056\n",
            " 2024-07-03 06:35:20,846 - INFO -marigold_trainer.py - train >> iter   847 (epoch  1): loss=0.17649\n",
            " 2024-07-03 06:35:25,146 - INFO -marigold_trainer.py - train >> iter   848 (epoch  1): loss=0.12908\n",
            " 2024-07-03 06:35:29,438 - INFO -marigold_trainer.py - train >> iter   849 (epoch  1): loss=0.14089\n",
            " 2024-07-03 06:35:33,821 - INFO -marigold_trainer.py - train >> iter   850 (epoch  1): loss=0.20642\n",
            " 2024-07-03 06:35:33,822 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:35:45,953 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:36:05,506 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:36:11,243 - INFO -marigold_trainer.py - train >> iter   851 (epoch  1): loss=0.17591\n",
            " 2024-07-03 06:36:15,533 - INFO -marigold_trainer.py - train >> iter   852 (epoch  1): loss=0.09332\n",
            " 2024-07-03 06:36:19,826 - INFO -marigold_trainer.py - train >> iter   853 (epoch  1): loss=0.11471\n",
            " 2024-07-03 06:36:24,135 - INFO -marigold_trainer.py - train >> iter   854 (epoch  1): loss=0.18326\n",
            " 2024-07-03 06:36:28,470 - INFO -marigold_trainer.py - train >> iter   855 (epoch  1): loss=0.15286\n",
            " 2024-07-03 06:36:32,895 - INFO -marigold_trainer.py - train >> iter   856 (epoch  1): loss=0.17887\n",
            " 2024-07-03 06:36:37,218 - INFO -marigold_trainer.py - train >> iter   857 (epoch  1): loss=0.14823\n",
            " 2024-07-03 06:36:41,534 - INFO -marigold_trainer.py - train >> iter   858 (epoch  1): loss=0.14738\n",
            " 2024-07-03 06:36:45,886 - INFO -marigold_trainer.py - train >> iter   859 (epoch  1): loss=0.12650\n",
            " 2024-07-03 06:36:50,212 - INFO -marigold_trainer.py - train >> iter   860 (epoch  1): loss=0.15802\n",
            " 2024-07-03 06:36:54,526 - INFO -marigold_trainer.py - train >> iter   861 (epoch  1): loss=0.13642\n",
            " 2024-07-03 06:36:58,832 - INFO -marigold_trainer.py - train >> iter   862 (epoch  1): loss=0.14199\n",
            " 2024-07-03 06:37:03,131 - INFO -marigold_trainer.py - train >> iter   863 (epoch  1): loss=0.12568\n",
            " 2024-07-03 06:37:07,433 - INFO -marigold_trainer.py - train >> iter   864 (epoch  1): loss=0.14039\n",
            " 2024-07-03 06:37:11,730 - INFO -marigold_trainer.py - train >> iter   865 (epoch  1): loss=0.12113\n",
            " 2024-07-03 06:37:16,026 - INFO -marigold_trainer.py - train >> iter   866 (epoch  1): loss=0.21219\n",
            " 2024-07-03 06:37:20,326 - INFO -marigold_trainer.py - train >> iter   867 (epoch  1): loss=0.12365\n",
            " 2024-07-03 06:37:24,636 - INFO -marigold_trainer.py - train >> iter   868 (epoch  1): loss=0.10643\n",
            " 2024-07-03 06:37:28,923 - INFO -marigold_trainer.py - train >> iter   869 (epoch  1): loss=0.16235\n",
            " 2024-07-03 06:37:33,317 - INFO -marigold_trainer.py - train >> iter   870 (epoch  1): loss=0.15056\n",
            " 2024-07-03 06:37:37,593 - INFO -marigold_trainer.py - train >> iter   871 (epoch  1): loss=0.18982\n",
            " 2024-07-03 06:37:41,899 - INFO -marigold_trainer.py - train >> iter   872 (epoch  1): loss=0.13984\n",
            " 2024-07-03 06:37:46,223 - INFO -marigold_trainer.py - train >> iter   873 (epoch  1): loss=0.15369\n",
            " 2024-07-03 06:37:50,522 - INFO -marigold_trainer.py - train >> iter   874 (epoch  1): loss=0.09351\n",
            " 2024-07-03 06:37:54,833 - INFO -marigold_trainer.py - train >> iter   875 (epoch  1): loss=0.14259\n",
            " 2024-07-03 06:37:59,137 - INFO -marigold_trainer.py - train >> iter   876 (epoch  1): loss=0.13799\n",
            " 2024-07-03 06:38:03,435 - INFO -marigold_trainer.py - train >> iter   877 (epoch  1): loss=0.21175\n",
            " 2024-07-03 06:38:07,740 - INFO -marigold_trainer.py - train >> iter   878 (epoch  1): loss=0.18191\n",
            " 2024-07-03 06:38:12,049 - INFO -marigold_trainer.py - train >> iter   879 (epoch  1): loss=0.12370\n",
            " 2024-07-03 06:38:16,348 - INFO -marigold_trainer.py - train >> iter   880 (epoch  1): loss=0.16244\n",
            " 2024-07-03 06:38:20,679 - INFO -marigold_trainer.py - train >> iter   881 (epoch  1): loss=0.18803\n",
            " 2024-07-03 06:38:25,000 - INFO -marigold_trainer.py - train >> iter   882 (epoch  1): loss=0.15345\n",
            " 2024-07-03 06:38:29,324 - INFO -marigold_trainer.py - train >> iter   883 (epoch  1): loss=0.14580\n",
            " 2024-07-03 06:38:33,646 - INFO -marigold_trainer.py - train >> iter   884 (epoch  1): loss=0.11990\n",
            " 2024-07-03 06:38:38,032 - INFO -marigold_trainer.py - train >> iter   885 (epoch  1): loss=0.16737\n",
            " 2024-07-03 06:38:42,325 - INFO -marigold_trainer.py - train >> iter   886 (epoch  1): loss=0.14108\n",
            " 2024-07-03 06:38:46,637 - INFO -marigold_trainer.py - train >> iter   887 (epoch  1): loss=0.12782\n",
            " 2024-07-03 06:38:50,932 - INFO -marigold_trainer.py - train >> iter   888 (epoch  1): loss=0.11915\n",
            " 2024-07-03 06:38:55,255 - INFO -marigold_trainer.py - train >> iter   889 (epoch  1): loss=0.11662\n",
            " 2024-07-03 06:38:59,577 - INFO -marigold_trainer.py - train >> iter   890 (epoch  1): loss=0.14977\n",
            " 2024-07-03 06:39:03,884 - INFO -marigold_trainer.py - train >> iter   891 (epoch  1): loss=0.15496\n",
            " 2024-07-03 06:39:08,401 - INFO -marigold_trainer.py - train >> iter   892 (epoch  1): loss=0.12573\n",
            " 2024-07-03 06:39:12,701 - INFO -marigold_trainer.py - train >> iter   893 (epoch  1): loss=0.08971\n",
            " 2024-07-03 06:39:17,006 - INFO -marigold_trainer.py - train >> iter   894 (epoch  1): loss=0.18440\n",
            " 2024-07-03 06:39:21,329 - INFO -marigold_trainer.py - train >> iter   895 (epoch  1): loss=0.16937\n",
            " 2024-07-03 06:39:25,621 - INFO -marigold_trainer.py - train >> iter   896 (epoch  1): loss=0.14128\n",
            " 2024-07-03 06:39:29,926 - INFO -marigold_trainer.py - train >> iter   897 (epoch  1): loss=0.12877\n",
            " 2024-07-03 06:39:34,241 - INFO -marigold_trainer.py - train >> iter   898 (epoch  1): loss=0.11901\n",
            " 2024-07-03 06:39:38,612 - INFO -marigold_trainer.py - train >> iter   899 (epoch  1): loss=0.15941\n",
            " 2024-07-03 06:39:42,919 - INFO -marigold_trainer.py - train >> iter   900 (epoch  1): loss=0.12169\n",
            " 2024-07-03 06:39:42,920 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:39:53,358 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:40:11,722 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:40:17,566 - INFO -marigold_trainer.py - train >> iter   901 (epoch  1): loss=0.12092\n",
            " 2024-07-03 06:40:21,904 - INFO -marigold_trainer.py - train >> iter   902 (epoch  1): loss=0.09546\n",
            " 2024-07-03 06:40:26,217 - INFO -marigold_trainer.py - train >> iter   903 (epoch  1): loss=0.17920\n",
            " 2024-07-03 06:40:30,530 - INFO -marigold_trainer.py - train >> iter   904 (epoch  1): loss=0.10568\n",
            " 2024-07-03 06:40:34,857 - INFO -marigold_trainer.py - train >> iter   905 (epoch  1): loss=0.10391\n",
            " 2024-07-03 06:40:39,282 - INFO -marigold_trainer.py - train >> iter   906 (epoch  1): loss=0.14514\n",
            " 2024-07-03 06:40:43,619 - INFO -marigold_trainer.py - train >> iter   907 (epoch  1): loss=0.10291\n",
            " 2024-07-03 06:40:47,961 - INFO -marigold_trainer.py - train >> iter   908 (epoch  1): loss=0.13048\n",
            " 2024-07-03 06:40:52,288 - INFO -marigold_trainer.py - train >> iter   909 (epoch  1): loss=0.12430\n",
            " 2024-07-03 06:40:56,620 - INFO -marigold_trainer.py - train >> iter   910 (epoch  1): loss=0.10724\n",
            " 2024-07-03 06:41:00,937 - INFO -marigold_trainer.py - train >> iter   911 (epoch  1): loss=0.11782\n",
            " 2024-07-03 06:41:05,251 - INFO -marigold_trainer.py - train >> iter   912 (epoch  1): loss=0.16977\n",
            " 2024-07-03 06:41:09,572 - INFO -marigold_trainer.py - train >> iter   913 (epoch  1): loss=0.13964\n",
            " 2024-07-03 06:41:13,869 - INFO -marigold_trainer.py - train >> iter   914 (epoch  1): loss=0.16958\n",
            " 2024-07-03 06:41:18,174 - INFO -marigold_trainer.py - train >> iter   915 (epoch  1): loss=0.10104\n",
            " 2024-07-03 06:41:22,466 - INFO -marigold_trainer.py - train >> iter   916 (epoch  1): loss=0.16660\n",
            " 2024-07-03 06:41:26,777 - INFO -marigold_trainer.py - train >> iter   917 (epoch  1): loss=0.12761\n",
            " 2024-07-03 06:41:31,066 - INFO -marigold_trainer.py - train >> iter   918 (epoch  1): loss=0.17137\n",
            " 2024-07-03 06:41:35,345 - INFO -marigold_trainer.py - train >> iter   919 (epoch  1): loss=0.11677\n",
            " 2024-07-03 06:41:39,712 - INFO -marigold_trainer.py - train >> iter   920 (epoch  1): loss=0.15290\n",
            " 2024-07-03 06:41:44,015 - INFO -marigold_trainer.py - train >> iter   921 (epoch  1): loss=0.08045\n",
            " 2024-07-03 06:41:48,303 - INFO -marigold_trainer.py - train >> iter   922 (epoch  1): loss=0.20408\n",
            " 2024-07-03 06:41:52,595 - INFO -marigold_trainer.py - train >> iter   923 (epoch  1): loss=0.19013\n",
            " 2024-07-03 06:41:56,917 - INFO -marigold_trainer.py - train >> iter   924 (epoch  1): loss=0.12842\n",
            " 2024-07-03 06:42:01,213 - INFO -marigold_trainer.py - train >> iter   925 (epoch  1): loss=0.09037\n",
            " 2024-07-03 06:42:05,509 - INFO -marigold_trainer.py - train >> iter   926 (epoch  1): loss=0.11873\n",
            " 2024-07-03 06:42:09,823 - INFO -marigold_trainer.py - train >> iter   927 (epoch  1): loss=0.13755\n",
            " 2024-07-03 06:42:14,167 - INFO -marigold_trainer.py - train >> iter   928 (epoch  1): loss=0.13154\n",
            " 2024-07-03 06:42:18,471 - INFO -marigold_trainer.py - train >> iter   929 (epoch  1): loss=0.12510\n",
            " 2024-07-03 06:42:22,806 - INFO -marigold_trainer.py - train >> iter   930 (epoch  1): loss=0.09501\n",
            " 2024-07-03 06:42:27,107 - INFO -marigold_trainer.py - train >> iter   931 (epoch  1): loss=0.12996\n",
            " 2024-07-03 06:42:31,413 - INFO -marigold_trainer.py - train >> iter   932 (epoch  1): loss=0.11352\n",
            " 2024-07-03 06:42:35,719 - INFO -marigold_trainer.py - train >> iter   933 (epoch  1): loss=0.09014\n",
            " 2024-07-03 06:42:40,035 - INFO -marigold_trainer.py - train >> iter   934 (epoch  1): loss=0.15283\n",
            " 2024-07-03 06:42:44,450 - INFO -marigold_trainer.py - train >> iter   935 (epoch  1): loss=0.13699\n",
            " 2024-07-03 06:42:48,753 - INFO -marigold_trainer.py - train >> iter   936 (epoch  1): loss=0.12846\n",
            " 2024-07-03 06:42:53,056 - INFO -marigold_trainer.py - train >> iter   937 (epoch  1): loss=0.09427\n",
            " 2024-07-03 06:42:57,352 - INFO -marigold_trainer.py - train >> iter   938 (epoch  1): loss=0.12340\n",
            " 2024-07-03 06:43:01,659 - INFO -marigold_trainer.py - train >> iter   939 (epoch  1): loss=0.11630\n",
            " 2024-07-03 06:43:05,963 - INFO -marigold_trainer.py - train >> iter   940 (epoch  1): loss=0.09230\n",
            " 2024-07-03 06:43:10,268 - INFO -marigold_trainer.py - train >> iter   941 (epoch  1): loss=0.14949\n",
            " 2024-07-03 06:43:14,561 - INFO -marigold_trainer.py - train >> iter   942 (epoch  1): loss=0.12968\n",
            " 2024-07-03 06:43:18,871 - INFO -marigold_trainer.py - train >> iter   943 (epoch  1): loss=0.10550\n",
            " 2024-07-03 06:43:23,179 - INFO -marigold_trainer.py - train >> iter   944 (epoch  1): loss=0.16279\n",
            " 2024-07-03 06:43:27,515 - INFO -marigold_trainer.py - train >> iter   945 (epoch  1): loss=0.12906\n",
            " 2024-07-03 06:43:31,844 - INFO -marigold_trainer.py - train >> iter   946 (epoch  1): loss=0.15960\n",
            " 2024-07-03 06:43:36,142 - INFO -marigold_trainer.py - train >> iter   947 (epoch  1): loss=0.13988\n",
            " 2024-07-03 06:43:40,426 - INFO -marigold_trainer.py - train >> iter   948 (epoch  1): loss=0.16701\n",
            " 2024-07-03 06:43:44,785 - INFO -marigold_trainer.py - train >> iter   949 (epoch  1): loss=0.07675\n",
            " 2024-07-03 06:43:49,083 - INFO -marigold_trainer.py - train >> iter   950 (epoch  1): loss=0.14075\n",
            " 2024-07-03 06:43:49,084 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:44:01,701 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:44:21,189 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:44:27,006 - INFO -marigold_trainer.py - train >> iter   951 (epoch  1): loss=0.12188\n",
            " 2024-07-03 06:44:31,322 - INFO -marigold_trainer.py - train >> iter   952 (epoch  1): loss=0.09245\n",
            " 2024-07-03 06:44:35,608 - INFO -marigold_trainer.py - train >> iter   953 (epoch  1): loss=0.09487\n",
            " 2024-07-03 06:44:39,927 - INFO -marigold_trainer.py - train >> iter   954 (epoch  1): loss=0.15846\n",
            " 2024-07-03 06:44:44,358 - INFO -marigold_trainer.py - train >> iter   955 (epoch  1): loss=0.09803\n",
            " 2024-07-03 06:44:48,686 - INFO -marigold_trainer.py - train >> iter   956 (epoch  1): loss=0.09557\n",
            " 2024-07-03 06:44:53,013 - INFO -marigold_trainer.py - train >> iter   957 (epoch  1): loss=0.13075\n",
            " 2024-07-03 06:44:57,341 - INFO -marigold_trainer.py - train >> iter   958 (epoch  1): loss=0.07720\n",
            " 2024-07-03 06:45:01,656 - INFO -marigold_trainer.py - train >> iter   959 (epoch  1): loss=0.10052\n",
            " 2024-07-03 06:45:05,963 - INFO -marigold_trainer.py - train >> iter   960 (epoch  1): loss=0.10364\n",
            " 2024-07-03 06:45:10,276 - INFO -marigold_trainer.py - train >> iter   961 (epoch  1): loss=0.17222\n",
            " 2024-07-03 06:45:14,596 - INFO -marigold_trainer.py - train >> iter   962 (epoch  1): loss=0.12432\n",
            " 2024-07-03 06:45:18,911 - INFO -marigold_trainer.py - train >> iter   963 (epoch  1): loss=0.12175\n",
            " 2024-07-03 06:45:23,196 - INFO -marigold_trainer.py - train >> iter   964 (epoch  1): loss=0.07370\n",
            " 2024-07-03 06:45:27,480 - INFO -marigold_trainer.py - train >> iter   965 (epoch  1): loss=0.10087\n",
            " 2024-07-03 06:45:31,809 - INFO -marigold_trainer.py - train >> iter   966 (epoch  1): loss=0.12397\n",
            " 2024-07-03 06:45:36,101 - INFO -marigold_trainer.py - train >> iter   967 (epoch  1): loss=0.10585\n",
            " 2024-07-03 06:45:40,398 - INFO -marigold_trainer.py - train >> iter   968 (epoch  1): loss=0.13737\n",
            " 2024-07-03 06:45:44,763 - INFO -marigold_trainer.py - train >> iter   969 (epoch  1): loss=0.14784\n",
            " 2024-07-03 06:45:49,012 - INFO -marigold_trainer.py - train >> iter   970 (epoch  1): loss=0.08729\n",
            " 2024-07-03 06:45:53,316 - INFO -marigold_trainer.py - train >> iter   971 (epoch  1): loss=0.14138\n",
            " 2024-07-03 06:45:57,635 - INFO -marigold_trainer.py - train >> iter   972 (epoch  1): loss=0.12060\n",
            " 2024-07-03 06:46:01,947 - INFO -marigold_trainer.py - train >> iter   973 (epoch  1): loss=0.11414\n",
            " 2024-07-03 06:46:06,248 - INFO -marigold_trainer.py - train >> iter   974 (epoch  1): loss=0.10104\n",
            " 2024-07-03 06:46:10,556 - INFO -marigold_trainer.py - train >> iter   975 (epoch  1): loss=0.14771\n",
            " 2024-07-03 06:46:14,874 - INFO -marigold_trainer.py - train >> iter   976 (epoch  1): loss=0.17974\n",
            " 2024-07-03 06:46:19,210 - INFO -marigold_trainer.py - train >> iter   977 (epoch  1): loss=0.13144\n",
            " 2024-07-03 06:46:23,506 - INFO -marigold_trainer.py - train >> iter   978 (epoch  1): loss=0.13854\n",
            " 2024-07-03 06:46:27,804 - INFO -marigold_trainer.py - train >> iter   979 (epoch  1): loss=0.08695\n",
            " 2024-07-03 06:46:32,110 - INFO -marigold_trainer.py - train >> iter   980 (epoch  1): loss=0.08071\n",
            " 2024-07-03 06:46:36,419 - INFO -marigold_trainer.py - train >> iter   981 (epoch  1): loss=0.11755\n",
            " 2024-07-03 06:46:40,724 - INFO -marigold_trainer.py - train >> iter   982 (epoch  1): loss=0.09302\n",
            " 2024-07-03 06:46:45,019 - INFO -marigold_trainer.py - train >> iter   983 (epoch  1): loss=0.16196\n",
            " 2024-07-03 06:46:49,399 - INFO -marigold_trainer.py - train >> iter   984 (epoch  1): loss=0.11698\n",
            " 2024-07-03 06:46:53,732 - INFO -marigold_trainer.py - train >> iter   985 (epoch  1): loss=0.13330\n",
            " 2024-07-03 06:46:58,059 - INFO -marigold_trainer.py - train >> iter   986 (epoch  1): loss=0.08918\n",
            " 2024-07-03 06:47:02,356 - INFO -marigold_trainer.py - train >> iter   987 (epoch  1): loss=0.14810\n",
            " 2024-07-03 06:47:06,689 - INFO -marigold_trainer.py - train >> iter   988 (epoch  1): loss=0.10886\n",
            " 2024-07-03 06:47:11,219 - INFO -marigold_trainer.py - train >> iter   989 (epoch  1): loss=0.11488\n",
            " 2024-07-03 06:47:15,534 - INFO -marigold_trainer.py - train >> iter   990 (epoch  1): loss=0.12983\n",
            " 2024-07-03 06:47:19,866 - INFO -marigold_trainer.py - train >> iter   991 (epoch  1): loss=0.10563\n",
            " 2024-07-03 06:47:24,184 - INFO -marigold_trainer.py - train >> iter   992 (epoch  1): loss=0.12656\n",
            " 2024-07-03 06:47:28,465 - INFO -marigold_trainer.py - train >> iter   993 (epoch  1): loss=0.07772\n",
            " 2024-07-03 06:47:32,771 - INFO -marigold_trainer.py - train >> iter   994 (epoch  1): loss=0.10691\n",
            " 2024-07-03 06:47:37,060 - INFO -marigold_trainer.py - train >> iter   995 (epoch  1): loss=0.10142\n",
            " 2024-07-03 06:47:41,361 - INFO -marigold_trainer.py - train >> iter   996 (epoch  1): loss=0.13807\n",
            " 2024-07-03 06:47:45,694 - INFO -marigold_trainer.py - train >> iter   997 (epoch  1): loss=0.09925\n",
            " 2024-07-03 06:47:50,058 - INFO -marigold_trainer.py - train >> iter   998 (epoch  1): loss=0.08657\n",
            " 2024-07-03 06:47:54,364 - INFO -marigold_trainer.py - train >> iter   999 (epoch  1): loss=0.09179\n",
            " 2024-07-03 06:47:58,681 - INFO -marigold_trainer.py - train >> iter  1000 (epoch  1): loss=0.12495\n",
            " 2024-07-03 06:47:58,682 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:48:12,369 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:48:32,394 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:48:38,281 - INFO -marigold_trainer.py - train >> iter  1001 (epoch  1): loss=0.07526\n",
            " 2024-07-03 06:48:42,589 - INFO -marigold_trainer.py - train >> iter  1002 (epoch  1): loss=0.13001\n",
            " 2024-07-03 06:48:46,893 - INFO -marigold_trainer.py - train >> iter  1003 (epoch  1): loss=0.09747\n",
            " 2024-07-03 06:48:51,283 - INFO -marigold_trainer.py - train >> iter  1004 (epoch  1): loss=0.13998\n",
            " 2024-07-03 06:48:55,614 - INFO -marigold_trainer.py - train >> iter  1005 (epoch  1): loss=0.11090\n",
            " 2024-07-03 06:48:59,943 - INFO -marigold_trainer.py - train >> iter  1006 (epoch  1): loss=0.11378\n",
            " 2024-07-03 06:49:04,301 - INFO -marigold_trainer.py - train >> iter  1007 (epoch  1): loss=0.10402\n",
            " 2024-07-03 06:49:08,658 - INFO -marigold_trainer.py - train >> iter  1008 (epoch  1): loss=0.10846\n",
            " 2024-07-03 06:49:12,987 - INFO -marigold_trainer.py - train >> iter  1009 (epoch  1): loss=0.15600\n",
            " 2024-07-03 06:49:17,315 - INFO -marigold_trainer.py - train >> iter  1010 (epoch  1): loss=0.11231\n",
            " 2024-07-03 06:49:21,659 - INFO -marigold_trainer.py - train >> iter  1011 (epoch  1): loss=0.11476\n",
            " 2024-07-03 06:49:25,995 - INFO -marigold_trainer.py - train >> iter  1012 (epoch  1): loss=0.12614\n",
            " 2024-07-03 06:49:30,333 - INFO -marigold_trainer.py - train >> iter  1013 (epoch  1): loss=0.07357\n",
            " 2024-07-03 06:49:34,647 - INFO -marigold_trainer.py - train >> iter  1014 (epoch  1): loss=0.09416\n",
            " 2024-07-03 06:49:38,971 - INFO -marigold_trainer.py - train >> iter  1015 (epoch  1): loss=0.09113\n",
            " 2024-07-03 06:49:43,321 - INFO -marigold_trainer.py - train >> iter  1016 (epoch  1): loss=0.11897\n",
            " 2024-07-03 06:49:47,631 - INFO -marigold_trainer.py - train >> iter  1017 (epoch  1): loss=0.10093\n",
            " 2024-07-03 06:49:51,986 - INFO -marigold_trainer.py - train >> iter  1018 (epoch  1): loss=0.11598\n",
            " 2024-07-03 06:49:56,311 - INFO -marigold_trainer.py - train >> iter  1019 (epoch  1): loss=0.08914\n",
            " 2024-07-03 06:50:00,662 - INFO -marigold_trainer.py - train >> iter  1020 (epoch  1): loss=0.09827\n",
            " 2024-07-03 06:50:04,985 - INFO -marigold_trainer.py - train >> iter  1021 (epoch  1): loss=0.10809\n",
            " 2024-07-03 06:50:09,328 - INFO -marigold_trainer.py - train >> iter  1022 (epoch  1): loss=0.10665\n",
            " 2024-07-03 06:50:13,635 - INFO -marigold_trainer.py - train >> iter  1023 (epoch  1): loss=0.14813\n",
            " 2024-07-03 06:50:17,963 - INFO -marigold_trainer.py - train >> iter  1024 (epoch  1): loss=0.12278\n",
            " 2024-07-03 06:50:22,279 - INFO -marigold_trainer.py - train >> iter  1025 (epoch  1): loss=0.08647\n",
            " 2024-07-03 06:50:26,616 - INFO -marigold_trainer.py - train >> iter  1026 (epoch  1): loss=0.09765\n",
            " 2024-07-03 06:50:30,930 - INFO -marigold_trainer.py - train >> iter  1027 (epoch  1): loss=0.10523\n",
            " 2024-07-03 06:50:35,252 - INFO -marigold_trainer.py - train >> iter  1028 (epoch  1): loss=0.12157\n",
            " 2024-07-03 06:50:39,562 - INFO -marigold_trainer.py - train >> iter  1029 (epoch  1): loss=0.10974\n",
            " 2024-07-03 06:50:43,872 - INFO -marigold_trainer.py - train >> iter  1030 (epoch  1): loss=0.09018\n",
            " 2024-07-03 06:50:48,184 - INFO -marigold_trainer.py - train >> iter  1031 (epoch  1): loss=0.10816\n",
            " 2024-07-03 06:50:52,614 - INFO -marigold_trainer.py - train >> iter  1032 (epoch  1): loss=0.10593\n",
            " 2024-07-03 06:50:56,957 - INFO -marigold_trainer.py - train >> iter  1033 (epoch  1): loss=0.15215\n",
            " 2024-07-03 06:51:01,274 - INFO -marigold_trainer.py - train >> iter  1034 (epoch  1): loss=0.11199\n",
            " 2024-07-03 06:51:05,597 - INFO -marigold_trainer.py - train >> iter  1035 (epoch  1): loss=0.11320\n",
            " 2024-07-03 06:51:09,943 - INFO -marigold_trainer.py - train >> iter  1036 (epoch  1): loss=0.07860\n",
            " 2024-07-03 06:51:14,240 - INFO -marigold_trainer.py - train >> iter  1037 (epoch  1): loss=0.08590\n",
            " 2024-07-03 06:51:18,564 - INFO -marigold_trainer.py - train >> iter  1038 (epoch  1): loss=0.14405\n",
            " 2024-07-03 06:51:22,874 - INFO -marigold_trainer.py - train >> iter  1039 (epoch  1): loss=0.10723\n",
            " 2024-07-03 06:51:27,181 - INFO -marigold_trainer.py - train >> iter  1040 (epoch  1): loss=0.11780\n",
            " 2024-07-03 06:51:31,501 - INFO -marigold_trainer.py - train >> iter  1041 (epoch  1): loss=0.14045\n",
            " 2024-07-03 06:51:35,793 - INFO -marigold_trainer.py - train >> iter  1042 (epoch  1): loss=0.12575\n",
            " 2024-07-03 06:51:40,101 - INFO -marigold_trainer.py - train >> iter  1043 (epoch  1): loss=0.09468\n",
            " 2024-07-03 06:51:44,408 - INFO -marigold_trainer.py - train >> iter  1044 (epoch  1): loss=0.11908\n",
            " 2024-07-03 06:51:48,705 - INFO -marigold_trainer.py - train >> iter  1045 (epoch  1): loss=0.13132\n",
            " 2024-07-03 06:51:53,011 - INFO -marigold_trainer.py - train >> iter  1046 (epoch  1): loss=0.11554\n",
            " 2024-07-03 06:51:57,431 - INFO -marigold_trainer.py - train >> iter  1047 (epoch  1): loss=0.11363\n",
            " 2024-07-03 06:52:01,726 - INFO -marigold_trainer.py - train >> iter  1048 (epoch  1): loss=0.09707\n",
            " 2024-07-03 06:52:06,025 - INFO -marigold_trainer.py - train >> iter  1049 (epoch  1): loss=0.13083\n",
            " 2024-07-03 06:52:10,335 - INFO -marigold_trainer.py - train >> iter  1050 (epoch  1): loss=0.13103\n",
            " 2024-07-03 06:52:10,336 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:52:19,999 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:52:38,641 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:52:44,491 - INFO -marigold_trainer.py - train >> iter  1051 (epoch  1): loss=0.12374\n",
            " 2024-07-03 06:52:48,788 - INFO -marigold_trainer.py - train >> iter  1052 (epoch  1): loss=0.11101\n",
            " 2024-07-03 06:52:53,087 - INFO -marigold_trainer.py - train >> iter  1053 (epoch  1): loss=0.13234\n",
            " 2024-07-03 06:52:57,503 - INFO -marigold_trainer.py - train >> iter  1054 (epoch  1): loss=0.13475\n",
            " 2024-07-03 06:53:01,806 - INFO -marigold_trainer.py - train >> iter  1055 (epoch  1): loss=0.15045\n",
            " 2024-07-03 06:53:06,127 - INFO -marigold_trainer.py - train >> iter  1056 (epoch  1): loss=0.11941\n",
            " 2024-07-03 06:53:10,463 - INFO -marigold_trainer.py - train >> iter  1057 (epoch  1): loss=0.10052\n",
            " 2024-07-03 06:53:14,760 - INFO -marigold_trainer.py - train >> iter  1058 (epoch  1): loss=0.11379\n",
            " 2024-07-03 06:53:19,076 - INFO -marigold_trainer.py - train >> iter  1059 (epoch  1): loss=0.06511\n",
            " 2024-07-03 06:53:23,389 - INFO -marigold_trainer.py - train >> iter  1060 (epoch  1): loss=0.12607\n",
            " 2024-07-03 06:53:27,696 - INFO -marigold_trainer.py - train >> iter  1061 (epoch  1): loss=0.10306\n",
            " 2024-07-03 06:53:32,013 - INFO -marigold_trainer.py - train >> iter  1062 (epoch  1): loss=0.10901\n",
            " 2024-07-03 06:53:36,312 - INFO -marigold_trainer.py - train >> iter  1063 (epoch  1): loss=0.07979\n",
            " 2024-07-03 06:53:40,616 - INFO -marigold_trainer.py - train >> iter  1064 (epoch  1): loss=0.12976\n",
            " 2024-07-03 06:53:44,901 - INFO -marigold_trainer.py - train >> iter  1065 (epoch  1): loss=0.10628\n",
            " 2024-07-03 06:53:49,202 - INFO -marigold_trainer.py - train >> iter  1066 (epoch  1): loss=0.11696\n",
            " 2024-07-03 06:53:53,508 - INFO -marigold_trainer.py - train >> iter  1067 (epoch  1): loss=0.15779\n",
            " 2024-07-03 06:53:57,857 - INFO -marigold_trainer.py - train >> iter  1068 (epoch  1): loss=0.11800\n",
            " 2024-07-03 06:54:02,139 - INFO -marigold_trainer.py - train >> iter  1069 (epoch  1): loss=0.10427\n",
            " 2024-07-03 06:54:06,453 - INFO -marigold_trainer.py - train >> iter  1070 (epoch  1): loss=0.13499\n",
            " 2024-07-03 06:54:10,802 - INFO -marigold_trainer.py - train >> iter  1071 (epoch  1): loss=0.14098\n",
            " 2024-07-03 06:54:15,137 - INFO -marigold_trainer.py - train >> iter  1072 (epoch  1): loss=0.09168\n",
            " 2024-07-03 06:54:19,449 - INFO -marigold_trainer.py - train >> iter  1073 (epoch  1): loss=0.11057\n",
            " 2024-07-03 06:54:23,754 - INFO -marigold_trainer.py - train >> iter  1074 (epoch  1): loss=0.11832\n",
            " 2024-07-03 06:54:28,111 - INFO -marigold_trainer.py - train >> iter  1075 (epoch  1): loss=0.11172\n",
            " 2024-07-03 06:54:32,490 - INFO -marigold_trainer.py - train >> iter  1076 (epoch  1): loss=0.12610\n",
            " 2024-07-03 06:54:36,807 - INFO -marigold_trainer.py - train >> iter  1077 (epoch  1): loss=0.10454\n",
            " 2024-07-03 06:54:41,133 - INFO -marigold_trainer.py - train >> iter  1078 (epoch  1): loss=0.11943\n",
            " 2024-07-03 06:54:45,450 - INFO -marigold_trainer.py - train >> iter  1079 (epoch  1): loss=0.10858\n",
            " 2024-07-03 06:54:49,770 - INFO -marigold_trainer.py - train >> iter  1080 (epoch  1): loss=0.09726\n",
            " 2024-07-03 06:54:54,081 - INFO -marigold_trainer.py - train >> iter  1081 (epoch  1): loss=0.12954\n",
            " 2024-07-03 06:54:58,478 - INFO -marigold_trainer.py - train >> iter  1082 (epoch  1): loss=0.10785\n",
            " 2024-07-03 06:55:02,786 - INFO -marigold_trainer.py - train >> iter  1083 (epoch  1): loss=0.10274\n",
            " 2024-07-03 06:55:07,110 - INFO -marigold_trainer.py - train >> iter  1084 (epoch  1): loss=0.11591\n",
            " 2024-07-03 06:55:11,416 - INFO -marigold_trainer.py - train >> iter  1085 (epoch  1): loss=0.11492\n",
            " 2024-07-03 06:55:15,726 - INFO -marigold_trainer.py - train >> iter  1086 (epoch  1): loss=0.12300\n",
            " 2024-07-03 06:55:20,034 - INFO -marigold_trainer.py - train >> iter  1087 (epoch  1): loss=0.09383\n",
            " 2024-07-03 06:55:24,344 - INFO -marigold_trainer.py - train >> iter  1088 (epoch  1): loss=0.09480\n",
            " 2024-07-03 06:55:28,640 - INFO -marigold_trainer.py - train >> iter  1089 (epoch  1): loss=0.15285\n",
            " 2024-07-03 06:55:32,949 - INFO -marigold_trainer.py - train >> iter  1090 (epoch  1): loss=0.11532\n",
            " 2024-07-03 06:55:37,243 - INFO -marigold_trainer.py - train >> iter  1091 (epoch  1): loss=0.10655\n",
            " 2024-07-03 06:55:41,562 - INFO -marigold_trainer.py - train >> iter  1092 (epoch  1): loss=0.11074\n",
            " 2024-07-03 06:55:45,847 - INFO -marigold_trainer.py - train >> iter  1093 (epoch  1): loss=0.12374\n",
            " 2024-07-03 06:55:50,147 - INFO -marigold_trainer.py - train >> iter  1094 (epoch  1): loss=0.13835\n",
            " 2024-07-03 06:55:54,445 - INFO -marigold_trainer.py - train >> iter  1095 (epoch  1): loss=0.11048\n",
            " 2024-07-03 06:55:58,748 - INFO -marigold_trainer.py - train >> iter  1096 (epoch  1): loss=0.12710\n",
            " 2024-07-03 06:56:03,125 - INFO -marigold_trainer.py - train >> iter  1097 (epoch  1): loss=0.10538\n",
            " 2024-07-03 06:56:07,626 - INFO -marigold_trainer.py - train >> iter  1098 (epoch  1): loss=0.08050\n",
            " 2024-07-03 06:56:11,915 - INFO -marigold_trainer.py - train >> iter  1099 (epoch  1): loss=0.13943\n",
            " 2024-07-03 06:56:16,217 - INFO -marigold_trainer.py - train >> iter  1100 (epoch  1): loss=0.09491\n",
            " 2024-07-03 06:56:16,218 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 06:56:28,448 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 06:56:47,399 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 06:56:53,229 - INFO -marigold_trainer.py - train >> iter  1101 (epoch  1): loss=0.10522\n",
            " 2024-07-03 06:56:57,510 - INFO -marigold_trainer.py - train >> iter  1102 (epoch  1): loss=0.10350\n",
            " 2024-07-03 06:57:01,891 - INFO -marigold_trainer.py - train >> iter  1103 (epoch  1): loss=0.15375\n",
            " 2024-07-03 06:57:06,239 - INFO -marigold_trainer.py - train >> iter  1104 (epoch  1): loss=0.18123\n",
            " 2024-07-03 06:57:10,565 - INFO -marigold_trainer.py - train >> iter  1105 (epoch  1): loss=0.10782\n",
            " 2024-07-03 06:57:14,882 - INFO -marigold_trainer.py - train >> iter  1106 (epoch  1): loss=0.10840\n",
            " 2024-07-03 06:57:19,233 - INFO -marigold_trainer.py - train >> iter  1107 (epoch  1): loss=0.15373\n",
            " 2024-07-03 06:57:23,542 - INFO -marigold_trainer.py - train >> iter  1108 (epoch  1): loss=0.09557\n",
            " 2024-07-03 06:57:27,872 - INFO -marigold_trainer.py - train >> iter  1109 (epoch  1): loss=0.08408\n",
            " 2024-07-03 06:57:32,209 - INFO -marigold_trainer.py - train >> iter  1110 (epoch  1): loss=0.13775\n",
            " 2024-07-03 06:57:36,525 - INFO -marigold_trainer.py - train >> iter  1111 (epoch  1): loss=0.11125\n",
            " 2024-07-03 06:57:40,852 - INFO -marigold_trainer.py - train >> iter  1112 (epoch  1): loss=0.08719\n",
            " 2024-07-03 06:57:45,148 - INFO -marigold_trainer.py - train >> iter  1113 (epoch  1): loss=0.11680\n",
            " 2024-07-03 06:57:49,451 - INFO -marigold_trainer.py - train >> iter  1114 (epoch  1): loss=0.11047\n",
            " 2024-07-03 06:57:53,750 - INFO -marigold_trainer.py - train >> iter  1115 (epoch  1): loss=0.09773\n",
            " 2024-07-03 06:57:58,058 - INFO -marigold_trainer.py - train >> iter  1116 (epoch  1): loss=0.11963\n",
            " 2024-07-03 06:58:02,419 - INFO -marigold_trainer.py - train >> iter  1117 (epoch  1): loss=0.08879\n",
            " 2024-07-03 06:58:06,743 - INFO -marigold_trainer.py - train >> iter  1118 (epoch  1): loss=0.11177\n",
            " 2024-07-03 06:58:11,035 - INFO -marigold_trainer.py - train >> iter  1119 (epoch  1): loss=0.12926\n",
            " 2024-07-03 06:58:15,332 - INFO -marigold_trainer.py - train >> iter  1120 (epoch  1): loss=0.08818\n",
            " 2024-07-03 06:58:19,632 - INFO -marigold_trainer.py - train >> iter  1121 (epoch  1): loss=0.11613\n",
            " 2024-07-03 06:58:23,947 - INFO -marigold_trainer.py - train >> iter  1122 (epoch  1): loss=0.10410\n",
            " 2024-07-03 06:58:28,245 - INFO -marigold_trainer.py - train >> iter  1123 (epoch  1): loss=0.10292\n",
            " 2024-07-03 06:58:32,545 - INFO -marigold_trainer.py - train >> iter  1124 (epoch  1): loss=0.11840\n",
            " 2024-07-03 06:58:36,864 - INFO -marigold_trainer.py - train >> iter  1125 (epoch  1): loss=0.11453\n",
            " 2024-07-03 06:58:41,178 - INFO -marigold_trainer.py - train >> iter  1126 (epoch  1): loss=0.13699\n",
            " 2024-07-03 06:58:45,481 - INFO -marigold_trainer.py - train >> iter  1127 (epoch  1): loss=0.10068\n",
            " 2024-07-03 06:58:49,774 - INFO -marigold_trainer.py - train >> iter  1128 (epoch  1): loss=0.08475\n",
            " 2024-07-03 06:58:54,101 - INFO -marigold_trainer.py - train >> iter  1129 (epoch  1): loss=0.13043\n",
            " 2024-07-03 06:58:58,407 - INFO -marigold_trainer.py - train >> iter  1130 (epoch  1): loss=0.11725\n",
            " 2024-07-03 06:59:02,717 - INFO -marigold_trainer.py - train >> iter  1131 (epoch  1): loss=0.09688\n",
            " 2024-07-03 06:59:07,140 - INFO -marigold_trainer.py - train >> iter  1132 (epoch  1): loss=0.07988\n",
            " 2024-07-03 06:59:11,455 - INFO -marigold_trainer.py - train >> iter  1133 (epoch  1): loss=0.12113\n",
            " 2024-07-03 06:59:15,757 - INFO -marigold_trainer.py - train >> iter  1134 (epoch  1): loss=0.09097\n",
            " 2024-07-03 06:59:20,057 - INFO -marigold_trainer.py - train >> iter  1135 (epoch  1): loss=0.08864\n",
            " 2024-07-03 06:59:24,363 - INFO -marigold_trainer.py - train >> iter  1136 (epoch  1): loss=0.09834\n",
            " 2024-07-03 06:59:28,679 - INFO -marigold_trainer.py - train >> iter  1137 (epoch  1): loss=0.12389\n",
            " 2024-07-03 06:59:32,966 - INFO -marigold_trainer.py - train >> iter  1138 (epoch  1): loss=0.08627\n",
            " 2024-07-03 06:59:37,255 - INFO -marigold_trainer.py - train >> iter  1139 (epoch  1): loss=0.12429\n",
            " 2024-07-03 06:59:41,560 - INFO -marigold_trainer.py - train >> iter  1140 (epoch  1): loss=0.08473\n",
            " 2024-07-03 06:59:45,866 - INFO -marigold_trainer.py - train >> iter  1141 (epoch  1): loss=0.10702\n",
            " 2024-07-03 06:59:50,172 - INFO -marigold_trainer.py - train >> iter  1142 (epoch  1): loss=0.16593\n",
            " 2024-07-03 06:59:54,494 - INFO -marigold_trainer.py - train >> iter  1143 (epoch  1): loss=0.11992\n",
            " 2024-07-03 06:59:58,790 - INFO -marigold_trainer.py - train >> iter  1144 (epoch  1): loss=0.09121\n",
            " 2024-07-03 07:00:03,097 - INFO -marigold_trainer.py - train >> iter  1145 (epoch  1): loss=0.09815\n",
            " 2024-07-03 07:00:07,451 - INFO -marigold_trainer.py - train >> iter  1146 (epoch  1): loss=0.10299\n",
            " 2024-07-03 07:00:11,764 - INFO -marigold_trainer.py - train >> iter  1147 (epoch  1): loss=0.15190\n",
            " 2024-07-03 07:00:16,071 - INFO -marigold_trainer.py - train >> iter  1148 (epoch  1): loss=0.07073\n",
            " 2024-07-03 07:00:20,360 - INFO -marigold_trainer.py - train >> iter  1149 (epoch  1): loss=0.09629\n",
            " 2024-07-03 07:00:24,656 - INFO -marigold_trainer.py - train >> iter  1150 (epoch  1): loss=0.10294\n",
            " 2024-07-03 07:00:24,657 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:00:37,861 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:00:56,662 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:01:02,625 - INFO -marigold_trainer.py - train >> iter  1151 (epoch  1): loss=0.14498\n",
            " 2024-07-03 07:01:06,994 - INFO -marigold_trainer.py - train >> iter  1152 (epoch  1): loss=0.12138\n",
            " 2024-07-03 07:01:11,299 - INFO -marigold_trainer.py - train >> iter  1153 (epoch  1): loss=0.11108\n",
            " 2024-07-03 07:01:15,632 - INFO -marigold_trainer.py - train >> iter  1154 (epoch  1): loss=0.11360\n",
            " 2024-07-03 07:01:19,947 - INFO -marigold_trainer.py - train >> iter  1155 (epoch  1): loss=0.08419\n",
            " 2024-07-03 07:01:24,267 - INFO -marigold_trainer.py - train >> iter  1156 (epoch  1): loss=0.12673\n",
            " 2024-07-03 07:01:28,604 - INFO -marigold_trainer.py - train >> iter  1157 (epoch  1): loss=0.11503\n",
            " 2024-07-03 07:01:32,929 - INFO -marigold_trainer.py - train >> iter  1158 (epoch  1): loss=0.11693\n",
            " 2024-07-03 07:01:37,238 - INFO -marigold_trainer.py - train >> iter  1159 (epoch  1): loss=0.10438\n",
            " 2024-07-03 07:01:41,558 - INFO -marigold_trainer.py - train >> iter  1160 (epoch  1): loss=0.10638\n",
            " 2024-07-03 07:01:45,873 - INFO -marigold_trainer.py - train >> iter  1161 (epoch  1): loss=0.08987\n",
            " 2024-07-03 07:01:50,175 - INFO -marigold_trainer.py - train >> iter  1162 (epoch  1): loss=0.10336\n",
            " 2024-07-03 07:01:54,490 - INFO -marigold_trainer.py - train >> iter  1163 (epoch  1): loss=0.11331\n",
            " 2024-07-03 07:01:58,780 - INFO -marigold_trainer.py - train >> iter  1164 (epoch  1): loss=0.12951\n",
            " 2024-07-03 07:02:03,080 - INFO -marigold_trainer.py - train >> iter  1165 (epoch  1): loss=0.09760\n",
            " 2024-07-03 07:02:07,368 - INFO -marigold_trainer.py - train >> iter  1166 (epoch  1): loss=0.08855\n",
            " 2024-07-03 07:02:11,737 - INFO -marigold_trainer.py - train >> iter  1167 (epoch  1): loss=0.10708\n",
            " 2024-07-03 07:02:16,029 - INFO -marigold_trainer.py - train >> iter  1168 (epoch  1): loss=0.17329\n",
            " 2024-07-03 07:02:20,326 - INFO -marigold_trainer.py - train >> iter  1169 (epoch  1): loss=0.07013\n",
            " 2024-07-03 07:02:24,609 - INFO -marigold_trainer.py - train >> iter  1170 (epoch  1): loss=0.09412\n",
            " 2024-07-03 07:02:28,892 - INFO -marigold_trainer.py - train >> iter  1171 (epoch  1): loss=0.11735\n",
            " 2024-07-03 07:02:33,176 - INFO -marigold_trainer.py - train >> iter  1172 (epoch  1): loss=0.08668\n",
            " 2024-07-03 07:02:37,468 - INFO -marigold_trainer.py - train >> iter  1173 (epoch  1): loss=0.08847\n",
            " 2024-07-03 07:02:41,772 - INFO -marigold_trainer.py - train >> iter  1174 (epoch  1): loss=0.12358\n",
            " 2024-07-03 07:02:46,092 - INFO -marigold_trainer.py - train >> iter  1175 (epoch  1): loss=0.07132\n",
            " 2024-07-03 07:02:50,405 - INFO -marigold_trainer.py - train >> iter  1176 (epoch  1): loss=0.12501\n",
            " 2024-07-03 07:02:54,731 - INFO -marigold_trainer.py - train >> iter  1177 (epoch  1): loss=0.10844\n",
            " 2024-07-03 07:02:59,039 - INFO -marigold_trainer.py - train >> iter  1178 (epoch  1): loss=0.11185\n",
            " 2024-07-03 07:03:03,348 - INFO -marigold_trainer.py - train >> iter  1179 (epoch  1): loss=0.09932\n",
            " 2024-07-03 07:03:07,650 - INFO -marigold_trainer.py - train >> iter  1180 (epoch  1): loss=0.10008\n",
            " 2024-07-03 07:03:12,040 - INFO -marigold_trainer.py - train >> iter  1181 (epoch  1): loss=0.10799\n",
            " 2024-07-03 07:03:16,345 - INFO -marigold_trainer.py - train >> iter  1182 (epoch  1): loss=0.11731\n",
            " 2024-07-03 07:03:20,647 - INFO -marigold_trainer.py - train >> iter  1183 (epoch  1): loss=0.14000\n",
            " 2024-07-03 07:03:24,944 - INFO -marigold_trainer.py - train >> iter  1184 (epoch  1): loss=0.10109\n",
            " 2024-07-03 07:03:29,264 - INFO -marigold_trainer.py - train >> iter  1185 (epoch  1): loss=0.13368\n",
            " 2024-07-03 07:03:33,555 - INFO -marigold_trainer.py - train >> iter  1186 (epoch  1): loss=0.13927\n",
            " 2024-07-03 07:03:37,852 - INFO -marigold_trainer.py - train >> iter  1187 (epoch  1): loss=0.11326\n",
            " 2024-07-03 07:03:42,169 - INFO -marigold_trainer.py - train >> iter  1188 (epoch  1): loss=0.08539\n",
            " 2024-07-03 07:03:46,469 - INFO -marigold_trainer.py - train >> iter  1189 (epoch  1): loss=0.10887\n",
            " 2024-07-03 07:03:50,766 - INFO -marigold_trainer.py - train >> iter  1190 (epoch  1): loss=0.09775\n",
            " 2024-07-03 07:03:55,080 - INFO -marigold_trainer.py - train >> iter  1191 (epoch  1): loss=0.11518\n",
            " 2024-07-03 07:03:59,365 - INFO -marigold_trainer.py - train >> iter  1192 (epoch  1): loss=0.08540\n",
            " 2024-07-03 07:04:03,674 - INFO -marigold_trainer.py - train >> iter  1193 (epoch  1): loss=0.06419\n",
            " 2024-07-03 07:04:07,980 - INFO -marigold_trainer.py - train >> iter  1194 (epoch  1): loss=0.12851\n",
            " 2024-07-03 07:04:12,348 - INFO -marigold_trainer.py - train >> iter  1195 (epoch  1): loss=0.11513\n",
            " 2024-07-03 07:04:16,659 - INFO -marigold_trainer.py - train >> iter  1196 (epoch  1): loss=0.08905\n",
            " 2024-07-03 07:04:20,958 - INFO -marigold_trainer.py - train >> iter  1197 (epoch  1): loss=0.06992\n",
            " 2024-07-03 07:04:25,251 - INFO -marigold_trainer.py - train >> iter  1198 (epoch  1): loss=0.10580\n",
            " 2024-07-03 07:04:29,558 - INFO -marigold_trainer.py - train >> iter  1199 (epoch  1): loss=0.12345\n",
            " 2024-07-03 07:04:33,856 - INFO -marigold_trainer.py - train >> iter  1200 (epoch  1): loss=0.08692\n",
            " 2024-07-03 07:04:33,857 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:04:42,350 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:05:04,613 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:05:10,423 - INFO -marigold_trainer.py - train >> iter  1201 (epoch  1): loss=0.06483\n",
            " 2024-07-03 07:05:14,810 - INFO -marigold_trainer.py - train >> iter  1202 (epoch  1): loss=0.14405\n",
            " 2024-07-03 07:05:19,330 - INFO -marigold_trainer.py - train >> iter  1203 (epoch  1): loss=0.08998\n",
            " 2024-07-03 07:05:23,646 - INFO -marigold_trainer.py - train >> iter  1204 (epoch  1): loss=0.13226\n",
            " 2024-07-03 07:05:27,986 - INFO -marigold_trainer.py - train >> iter  1205 (epoch  1): loss=0.08571\n",
            " 2024-07-03 07:05:32,305 - INFO -marigold_trainer.py - train >> iter  1206 (epoch  1): loss=0.13764\n",
            " 2024-07-03 07:05:36,601 - INFO -marigold_trainer.py - train >> iter  1207 (epoch  1): loss=0.09849\n",
            " 2024-07-03 07:05:40,927 - INFO -marigold_trainer.py - train >> iter  1208 (epoch  1): loss=0.08110\n",
            " 2024-07-03 07:05:45,250 - INFO -marigold_trainer.py - train >> iter  1209 (epoch  1): loss=0.08706\n",
            " 2024-07-03 07:05:49,559 - INFO -marigold_trainer.py - train >> iter  1210 (epoch  1): loss=0.11449\n",
            " 2024-07-03 07:05:53,884 - INFO -marigold_trainer.py - train >> iter  1211 (epoch  1): loss=0.09547\n",
            " 2024-07-03 07:05:58,192 - INFO -marigold_trainer.py - train >> iter  1212 (epoch  1): loss=0.13111\n",
            " 2024-07-03 07:06:02,512 - INFO -marigold_trainer.py - train >> iter  1213 (epoch  1): loss=0.10861\n",
            " 2024-07-03 07:06:06,828 - INFO -marigold_trainer.py - train >> iter  1214 (epoch  1): loss=0.07431\n",
            " 2024-07-03 07:06:11,124 - INFO -marigold_trainer.py - train >> iter  1215 (epoch  1): loss=0.09677\n",
            " 2024-07-03 07:06:15,508 - INFO -marigold_trainer.py - train >> iter  1216 (epoch  1): loss=0.06977\n",
            " 2024-07-03 07:06:19,824 - INFO -marigold_trainer.py - train >> iter  1217 (epoch  1): loss=0.10332\n",
            " 2024-07-03 07:06:24,112 - INFO -marigold_trainer.py - train >> iter  1218 (epoch  1): loss=0.08679\n",
            " 2024-07-03 07:06:28,406 - INFO -marigold_trainer.py - train >> iter  1219 (epoch  1): loss=0.10724\n",
            " 2024-07-03 07:06:32,695 - INFO -marigold_trainer.py - train >> iter  1220 (epoch  1): loss=0.12201\n",
            " 2024-07-03 07:06:36,983 - INFO -marigold_trainer.py - train >> iter  1221 (epoch  1): loss=0.06406\n",
            " 2024-07-03 07:06:41,291 - INFO -marigold_trainer.py - train >> iter  1222 (epoch  1): loss=0.10994\n",
            " 2024-07-03 07:06:45,593 - INFO -marigold_trainer.py - train >> iter  1223 (epoch  1): loss=0.14752\n",
            " 2024-07-03 07:06:49,881 - INFO -marigold_trainer.py - train >> iter  1224 (epoch  1): loss=0.09689\n",
            " 2024-07-03 07:06:54,201 - INFO -marigold_trainer.py - train >> iter  1225 (epoch  1): loss=0.10856\n",
            " 2024-07-03 07:06:58,505 - INFO -marigold_trainer.py - train >> iter  1226 (epoch  1): loss=0.11143\n",
            " 2024-07-03 07:07:02,818 - INFO -marigold_trainer.py - train >> iter  1227 (epoch  1): loss=0.08345\n",
            " 2024-07-03 07:07:07,111 - INFO -marigold_trainer.py - train >> iter  1228 (epoch  1): loss=0.09956\n",
            " 2024-07-03 07:07:11,409 - INFO -marigold_trainer.py - train >> iter  1229 (epoch  1): loss=0.09227\n",
            " 2024-07-03 07:07:15,809 - INFO -marigold_trainer.py - train >> iter  1230 (epoch  1): loss=0.08365\n",
            " 2024-07-03 07:07:20,109 - INFO -marigold_trainer.py - train >> iter  1231 (epoch  1): loss=0.08436\n",
            " 2024-07-03 07:07:24,407 - INFO -marigold_trainer.py - train >> iter  1232 (epoch  1): loss=0.11105\n",
            " 2024-07-03 07:07:28,733 - INFO -marigold_trainer.py - train >> iter  1233 (epoch  1): loss=0.12092\n",
            " 2024-07-03 07:07:33,064 - INFO -marigold_trainer.py - train >> iter  1234 (epoch  1): loss=0.09713\n",
            " 2024-07-03 07:07:37,399 - INFO -marigold_trainer.py - train >> iter  1235 (epoch  1): loss=0.08267\n",
            " 2024-07-03 07:07:41,695 - INFO -marigold_trainer.py - train >> iter  1236 (epoch  1): loss=0.13389\n",
            " 2024-07-03 07:07:45,987 - INFO -marigold_trainer.py - train >> iter  1237 (epoch  1): loss=0.10252\n",
            " 2024-07-03 07:07:50,311 - INFO -marigold_trainer.py - train >> iter  1238 (epoch  1): loss=0.09936\n",
            " 2024-07-03 07:07:54,606 - INFO -marigold_trainer.py - train >> iter  1239 (epoch  1): loss=0.07578\n",
            " 2024-07-03 07:07:58,910 - INFO -marigold_trainer.py - train >> iter  1240 (epoch  1): loss=0.16051\n",
            " 2024-07-03 07:08:03,212 - INFO -marigold_trainer.py - train >> iter  1241 (epoch  1): loss=0.08009\n",
            " 2024-07-03 07:08:07,516 - INFO -marigold_trainer.py - train >> iter  1242 (epoch  1): loss=0.08087\n",
            " 2024-07-03 07:08:11,822 - INFO -marigold_trainer.py - train >> iter  1243 (epoch  1): loss=0.11646\n",
            " 2024-07-03 07:08:16,128 - INFO -marigold_trainer.py - train >> iter  1244 (epoch  1): loss=0.09244\n",
            " 2024-07-03 07:08:20,477 - INFO -marigold_trainer.py - train >> iter  1245 (epoch  1): loss=0.08840\n",
            " 2024-07-03 07:08:24,805 - INFO -marigold_trainer.py - train >> iter  1246 (epoch  1): loss=0.05847\n",
            " 2024-07-03 07:08:29,123 - INFO -marigold_trainer.py - train >> iter  1247 (epoch  1): loss=0.09990\n",
            " 2024-07-03 07:08:33,418 - INFO -marigold_trainer.py - train >> iter  1248 (epoch  1): loss=0.12415\n",
            " 2024-07-03 07:08:37,723 - INFO -marigold_trainer.py - train >> iter  1249 (epoch  1): loss=0.09486\n",
            " 2024-07-03 07:08:42,017 - INFO -marigold_trainer.py - train >> iter  1250 (epoch  1): loss=0.10511\n",
            " 2024-07-03 07:08:42,018 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:08:55,783 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:09:15,853 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:09:21,806 - INFO -marigold_trainer.py - train >> iter  1251 (epoch  1): loss=0.12712\n",
            " 2024-07-03 07:09:26,107 - INFO -marigold_trainer.py - train >> iter  1252 (epoch  1): loss=0.14502\n",
            " 2024-07-03 07:09:30,412 - INFO -marigold_trainer.py - train >> iter  1253 (epoch  1): loss=0.08707\n",
            " 2024-07-03 07:09:34,718 - INFO -marigold_trainer.py - train >> iter  1254 (epoch  1): loss=0.11070\n",
            " 2024-07-03 07:09:39,043 - INFO -marigold_trainer.py - train >> iter  1255 (epoch  1): loss=0.07887\n",
            " 2024-07-03 07:09:43,382 - INFO -marigold_trainer.py - train >> iter  1256 (epoch  1): loss=0.09621\n",
            " 2024-07-03 07:09:47,711 - INFO -marigold_trainer.py - train >> iter  1257 (epoch  1): loss=0.10385\n",
            " 2024-07-03 07:09:52,062 - INFO -marigold_trainer.py - train >> iter  1258 (epoch  1): loss=0.10850\n",
            " 2024-07-03 07:09:56,376 - INFO -marigold_trainer.py - train >> iter  1259 (epoch  1): loss=0.10871\n",
            " 2024-07-03 07:10:00,678 - INFO -marigold_trainer.py - train >> iter  1260 (epoch  1): loss=0.11399\n",
            " 2024-07-03 07:10:04,990 - INFO -marigold_trainer.py - train >> iter  1261 (epoch  1): loss=0.15240\n",
            " 2024-07-03 07:10:09,294 - INFO -marigold_trainer.py - train >> iter  1262 (epoch  1): loss=0.12408\n",
            " 2024-07-03 07:10:13,599 - INFO -marigold_trainer.py - train >> iter  1263 (epoch  1): loss=0.10055\n",
            " 2024-07-03 07:10:17,919 - INFO -marigold_trainer.py - train >> iter  1264 (epoch  1): loss=0.12501\n",
            " 2024-07-03 07:10:22,290 - INFO -marigold_trainer.py - train >> iter  1265 (epoch  1): loss=0.06852\n",
            " 2024-07-03 07:10:26,582 - INFO -marigold_trainer.py - train >> iter  1266 (epoch  1): loss=0.07106\n",
            " 2024-07-03 07:10:30,886 - INFO -marigold_trainer.py - train >> iter  1267 (epoch  1): loss=0.11657\n",
            " 2024-07-03 07:10:35,191 - INFO -marigold_trainer.py - train >> iter  1268 (epoch  1): loss=0.09145\n",
            " 2024-07-03 07:10:39,494 - INFO -marigold_trainer.py - train >> iter  1269 (epoch  1): loss=0.08883\n",
            " 2024-07-03 07:10:43,775 - INFO -marigold_trainer.py - train >> iter  1270 (epoch  1): loss=0.09949\n",
            " 2024-07-03 07:10:48,093 - INFO -marigold_trainer.py - train >> iter  1271 (epoch  1): loss=0.09441\n",
            " 2024-07-03 07:10:52,411 - INFO -marigold_trainer.py - train >> iter  1272 (epoch  1): loss=0.10671\n",
            " 2024-07-03 07:10:56,752 - INFO -marigold_trainer.py - train >> iter  1273 (epoch  1): loss=0.08106\n",
            " 2024-07-03 07:11:01,059 - INFO -marigold_trainer.py - train >> iter  1274 (epoch  1): loss=0.11835\n",
            " 2024-07-03 07:11:05,368 - INFO -marigold_trainer.py - train >> iter  1275 (epoch  1): loss=0.13445\n",
            " 2024-07-03 07:11:09,677 - INFO -marigold_trainer.py - train >> iter  1276 (epoch  1): loss=0.10827\n",
            " 2024-07-03 07:11:14,000 - INFO -marigold_trainer.py - train >> iter  1277 (epoch  1): loss=0.09162\n",
            " 2024-07-03 07:11:18,310 - INFO -marigold_trainer.py - train >> iter  1278 (epoch  1): loss=0.11587\n",
            " 2024-07-03 07:11:22,741 - INFO -marigold_trainer.py - train >> iter  1279 (epoch  1): loss=0.11426\n",
            " 2024-07-03 07:11:27,089 - INFO -marigold_trainer.py - train >> iter  1280 (epoch  1): loss=0.06886\n",
            " 2024-07-03 07:11:31,409 - INFO -marigold_trainer.py - train >> iter  1281 (epoch  1): loss=0.08092\n",
            " 2024-07-03 07:11:35,725 - INFO -marigold_trainer.py - train >> iter  1282 (epoch  1): loss=0.10414\n",
            " 2024-07-03 07:11:40,059 - INFO -marigold_trainer.py - train >> iter  1283 (epoch  1): loss=0.13515\n",
            " 2024-07-03 07:11:44,369 - INFO -marigold_trainer.py - train >> iter  1284 (epoch  1): loss=0.09592\n",
            " 2024-07-03 07:11:48,695 - INFO -marigold_trainer.py - train >> iter  1285 (epoch  1): loss=0.11655\n",
            " 2024-07-03 07:11:53,023 - INFO -marigold_trainer.py - train >> iter  1286 (epoch  1): loss=0.09686\n",
            " 2024-07-03 07:11:57,353 - INFO -marigold_trainer.py - train >> iter  1287 (epoch  1): loss=0.09252\n",
            " 2024-07-03 07:12:01,687 - INFO -marigold_trainer.py - train >> iter  1288 (epoch  1): loss=0.09021\n",
            " 2024-07-03 07:12:05,998 - INFO -marigold_trainer.py - train >> iter  1289 (epoch  1): loss=0.07073\n",
            " 2024-07-03 07:12:10,337 - INFO -marigold_trainer.py - train >> iter  1290 (epoch  1): loss=0.11639\n",
            " 2024-07-03 07:12:14,684 - INFO -marigold_trainer.py - train >> iter  1291 (epoch  1): loss=0.08182\n",
            " 2024-07-03 07:12:18,993 - INFO -marigold_trainer.py - train >> iter  1292 (epoch  1): loss=0.08504\n",
            " 2024-07-03 07:12:23,388 - INFO -marigold_trainer.py - train >> iter  1293 (epoch  1): loss=0.10865\n",
            " 2024-07-03 07:12:27,721 - INFO -marigold_trainer.py - train >> iter  1294 (epoch  1): loss=0.08971\n",
            " 2024-07-03 07:12:32,026 - INFO -marigold_trainer.py - train >> iter  1295 (epoch  1): loss=0.09547\n",
            " 2024-07-03 07:12:36,334 - INFO -marigold_trainer.py - train >> iter  1296 (epoch  1): loss=0.05830\n",
            " 2024-07-03 07:12:40,645 - INFO -marigold_trainer.py - train >> iter  1297 (epoch  1): loss=0.07886\n",
            " 2024-07-03 07:12:44,974 - INFO -marigold_trainer.py - train >> iter  1298 (epoch  1): loss=0.07240\n",
            " 2024-07-03 07:12:49,285 - INFO -marigold_trainer.py - train >> iter  1299 (epoch  1): loss=0.10997\n",
            " 2024-07-03 07:12:53,603 - INFO -marigold_trainer.py - train >> iter  1300 (epoch  1): loss=0.08593\n",
            " 2024-07-03 07:12:53,604 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:13:07,674 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:13:27,396 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:13:33,231 - INFO -marigold_trainer.py - train >> iter  1301 (epoch  1): loss=0.13514\n",
            " 2024-07-03 07:13:37,567 - INFO -marigold_trainer.py - train >> iter  1302 (epoch  1): loss=0.08331\n",
            " 2024-07-03 07:13:41,850 - INFO -marigold_trainer.py - train >> iter  1303 (epoch  1): loss=0.10440\n",
            " 2024-07-03 07:13:46,186 - INFO -marigold_trainer.py - train >> iter  1304 (epoch  1): loss=0.11604\n",
            " 2024-07-03 07:13:50,542 - INFO -marigold_trainer.py - train >> iter  1305 (epoch  1): loss=0.12671\n",
            " 2024-07-03 07:13:54,878 - INFO -marigold_trainer.py - train >> iter  1306 (epoch  1): loss=0.10442\n",
            " 2024-07-03 07:13:59,219 - INFO -marigold_trainer.py - train >> iter  1307 (epoch  1): loss=0.08507\n",
            " 2024-07-03 07:14:03,572 - INFO -marigold_trainer.py - train >> iter  1308 (epoch  1): loss=0.18304\n",
            " 2024-07-03 07:14:07,910 - INFO -marigold_trainer.py - train >> iter  1309 (epoch  1): loss=0.06531\n",
            " 2024-07-03 07:14:12,241 - INFO -marigold_trainer.py - train >> iter  1310 (epoch  1): loss=0.08804\n",
            " 2024-07-03 07:14:16,566 - INFO -marigold_trainer.py - train >> iter  1311 (epoch  1): loss=0.11593\n",
            " 2024-07-03 07:14:20,886 - INFO -marigold_trainer.py - train >> iter  1312 (epoch  1): loss=0.07780\n",
            " 2024-07-03 07:14:25,253 - INFO -marigold_trainer.py - train >> iter  1313 (epoch  1): loss=0.08255\n",
            " 2024-07-03 07:14:29,586 - INFO -marigold_trainer.py - train >> iter  1314 (epoch  1): loss=0.11113\n",
            " 2024-07-03 07:14:33,900 - INFO -marigold_trainer.py - train >> iter  1315 (epoch  1): loss=0.09591\n",
            " 2024-07-03 07:14:38,213 - INFO -marigold_trainer.py - train >> iter  1316 (epoch  1): loss=0.11422\n",
            " 2024-07-03 07:14:42,526 - INFO -marigold_trainer.py - train >> iter  1317 (epoch  1): loss=0.11104\n",
            " 2024-07-03 07:14:46,820 - INFO -marigold_trainer.py - train >> iter  1318 (epoch  1): loss=0.10926\n",
            " 2024-07-03 07:14:51,419 - INFO -marigold_trainer.py - train >> iter  1319 (epoch  1): loss=0.13534\n",
            " 2024-07-03 07:14:55,704 - INFO -marigold_trainer.py - train >> iter  1320 (epoch  1): loss=0.10575\n",
            " 2024-07-03 07:15:00,012 - INFO -marigold_trainer.py - train >> iter  1321 (epoch  1): loss=0.09334\n",
            " 2024-07-03 07:15:04,332 - INFO -marigold_trainer.py - train >> iter  1322 (epoch  1): loss=0.07048\n",
            " 2024-07-03 07:15:08,642 - INFO -marigold_trainer.py - train >> iter  1323 (epoch  1): loss=0.09633\n",
            " 2024-07-03 07:15:12,985 - INFO -marigold_trainer.py - train >> iter  1324 (epoch  1): loss=0.10536\n",
            " 2024-07-03 07:15:17,337 - INFO -marigold_trainer.py - train >> iter  1325 (epoch  1): loss=0.09257\n",
            " 2024-07-03 07:15:21,650 - INFO -marigold_trainer.py - train >> iter  1326 (epoch  1): loss=0.07456\n",
            " 2024-07-03 07:15:25,964 - INFO -marigold_trainer.py - train >> iter  1327 (epoch  1): loss=0.10578\n",
            " 2024-07-03 07:15:30,392 - INFO -marigold_trainer.py - train >> iter  1328 (epoch  1): loss=0.09669\n",
            " 2024-07-03 07:15:34,691 - INFO -marigold_trainer.py - train >> iter  1329 (epoch  1): loss=0.10064\n",
            " 2024-07-03 07:15:39,027 - INFO -marigold_trainer.py - train >> iter  1330 (epoch  1): loss=0.08531\n",
            " 2024-07-03 07:15:43,341 - INFO -marigold_trainer.py - train >> iter  1331 (epoch  1): loss=0.10866\n",
            " 2024-07-03 07:15:47,656 - INFO -marigold_trainer.py - train >> iter  1332 (epoch  1): loss=0.08034\n",
            " 2024-07-03 07:15:51,966 - INFO -marigold_trainer.py - train >> iter  1333 (epoch  1): loss=0.06775\n",
            " 2024-07-03 07:15:56,280 - INFO -marigold_trainer.py - train >> iter  1334 (epoch  1): loss=0.09786\n",
            " 2024-07-03 07:16:00,581 - INFO -marigold_trainer.py - train >> iter  1335 (epoch  1): loss=0.08446\n",
            " 2024-07-03 07:16:04,897 - INFO -marigold_trainer.py - train >> iter  1336 (epoch  1): loss=0.10955\n",
            " 2024-07-03 07:16:09,212 - INFO -marigold_trainer.py - train >> iter  1337 (epoch  1): loss=0.06479\n",
            " 2024-07-03 07:16:13,518 - INFO -marigold_trainer.py - train >> iter  1338 (epoch  1): loss=0.12958\n",
            " 2024-07-03 07:16:17,817 - INFO -marigold_trainer.py - train >> iter  1339 (epoch  1): loss=0.05155\n",
            " 2024-07-03 07:16:22,106 - INFO -marigold_trainer.py - train >> iter  1340 (epoch  1): loss=0.06637\n",
            " 2024-07-03 07:16:26,425 - INFO -marigold_trainer.py - train >> iter  1341 (epoch  1): loss=0.11074\n",
            " 2024-07-03 07:16:30,761 - INFO -marigold_trainer.py - train >> iter  1342 (epoch  1): loss=0.13792\n",
            " 2024-07-03 07:16:35,060 - INFO -marigold_trainer.py - train >> iter  1343 (epoch  1): loss=0.07811\n",
            " 2024-07-03 07:16:39,394 - INFO -marigold_trainer.py - train >> iter  1344 (epoch  1): loss=0.08069\n",
            " 2024-07-03 07:16:43,695 - INFO -marigold_trainer.py - train >> iter  1345 (epoch  1): loss=0.13795\n",
            " 2024-07-03 07:16:48,004 - INFO -marigold_trainer.py - train >> iter  1346 (epoch  1): loss=0.08196\n",
            " 2024-07-03 07:16:52,328 - INFO -marigold_trainer.py - train >> iter  1347 (epoch  1): loss=0.10757\n",
            " 2024-07-03 07:16:56,630 - INFO -marigold_trainer.py - train >> iter  1348 (epoch  1): loss=0.05708\n",
            " 2024-07-03 07:17:00,951 - INFO -marigold_trainer.py - train >> iter  1349 (epoch  1): loss=0.13712\n",
            " 2024-07-03 07:17:05,256 - INFO -marigold_trainer.py - train >> iter  1350 (epoch  1): loss=0.09422\n",
            " 2024-07-03 07:17:05,257 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:17:16,547 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:17:36,824 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:17:42,688 - INFO -marigold_trainer.py - train >> iter  1351 (epoch  1): loss=0.11673\n",
            " 2024-07-03 07:17:46,984 - INFO -marigold_trainer.py - train >> iter  1352 (epoch  1): loss=0.06404\n",
            " 2024-07-03 07:17:51,308 - INFO -marigold_trainer.py - train >> iter  1353 (epoch  1): loss=0.10484\n",
            " 2024-07-03 07:17:55,636 - INFO -marigold_trainer.py - train >> iter  1354 (epoch  1): loss=0.15002\n",
            " 2024-07-03 07:17:59,961 - INFO -marigold_trainer.py - train >> iter  1355 (epoch  1): loss=0.12280\n",
            " 2024-07-03 07:18:04,288 - INFO -marigold_trainer.py - train >> iter  1356 (epoch  1): loss=0.08919\n",
            " 2024-07-03 07:18:08,606 - INFO -marigold_trainer.py - train >> iter  1357 (epoch  1): loss=0.10045\n",
            " 2024-07-03 07:18:12,954 - INFO -marigold_trainer.py - train >> iter  1358 (epoch  1): loss=0.09136\n",
            " 2024-07-03 07:18:17,277 - INFO -marigold_trainer.py - train >> iter  1359 (epoch  1): loss=0.05573\n",
            " 2024-07-03 07:18:21,598 - INFO -marigold_trainer.py - train >> iter  1360 (epoch  1): loss=0.08389\n",
            " 2024-07-03 07:18:25,928 - INFO -marigold_trainer.py - train >> iter  1361 (epoch  1): loss=0.09806\n",
            " 2024-07-03 07:18:30,246 - INFO -marigold_trainer.py - train >> iter  1362 (epoch  1): loss=0.06767\n",
            " 2024-07-03 07:18:34,590 - INFO -marigold_trainer.py - train >> iter  1363 (epoch  1): loss=0.05317\n",
            " 2024-07-03 07:18:38,914 - INFO -marigold_trainer.py - train >> iter  1364 (epoch  1): loss=0.11463\n",
            " 2024-07-03 07:18:43,199 - INFO -marigold_trainer.py - train >> iter  1365 (epoch  1): loss=0.11309\n",
            " 2024-07-03 07:18:47,500 - INFO -marigold_trainer.py - train >> iter  1366 (epoch  1): loss=0.10160\n",
            " 2024-07-03 07:18:51,795 - INFO -marigold_trainer.py - train >> iter  1367 (epoch  1): loss=0.09072\n",
            " 2024-07-03 07:18:56,080 - INFO -marigold_trainer.py - train >> iter  1368 (epoch  1): loss=0.11664\n",
            " 2024-07-03 07:19:00,389 - INFO -marigold_trainer.py - train >> iter  1369 (epoch  1): loss=0.08845\n",
            " 2024-07-03 07:19:04,685 - INFO -marigold_trainer.py - train >> iter  1370 (epoch  1): loss=0.11505\n",
            " 2024-07-03 07:19:08,977 - INFO -marigold_trainer.py - train >> iter  1371 (epoch  1): loss=0.12787\n",
            " 2024-07-03 07:19:13,296 - INFO -marigold_trainer.py - train >> iter  1372 (epoch  1): loss=0.09252\n",
            " 2024-07-03 07:19:17,592 - INFO -marigold_trainer.py - train >> iter  1373 (epoch  1): loss=0.11933\n",
            " 2024-07-03 07:19:21,894 - INFO -marigold_trainer.py - train >> iter  1374 (epoch  1): loss=0.07802\n",
            " 2024-07-03 07:19:26,217 - INFO -marigold_trainer.py - train >> iter  1375 (epoch  1): loss=0.10197\n",
            " 2024-07-03 07:19:30,511 - INFO -marigold_trainer.py - train >> iter  1376 (epoch  1): loss=0.07646\n",
            " 2024-07-03 07:19:34,874 - INFO -marigold_trainer.py - train >> iter  1377 (epoch  1): loss=0.13163\n",
            " 2024-07-03 07:19:39,218 - INFO -marigold_trainer.py - train >> iter  1378 (epoch  1): loss=0.07029\n",
            " 2024-07-03 07:19:43,520 - INFO -marigold_trainer.py - train >> iter  1379 (epoch  1): loss=0.12683\n",
            " 2024-07-03 07:19:47,827 - INFO -marigold_trainer.py - train >> iter  1380 (epoch  1): loss=0.11535\n",
            " 2024-07-03 07:19:52,149 - INFO -marigold_trainer.py - train >> iter  1381 (epoch  1): loss=0.16901\n",
            " 2024-07-03 07:19:56,447 - INFO -marigold_trainer.py - train >> iter  1382 (epoch  1): loss=0.04912\n",
            " 2024-07-03 07:20:00,759 - INFO -marigold_trainer.py - train >> iter  1383 (epoch  1): loss=0.09151\n",
            " 2024-07-03 07:20:05,053 - INFO -marigold_trainer.py - train >> iter  1384 (epoch  1): loss=0.11274\n",
            " 2024-07-03 07:20:09,352 - INFO -marigold_trainer.py - train >> iter  1385 (epoch  1): loss=0.12948\n",
            " 2024-07-03 07:20:13,666 - INFO -marigold_trainer.py - train >> iter  1386 (epoch  1): loss=0.10395\n",
            " 2024-07-03 07:20:17,971 - INFO -marigold_trainer.py - train >> iter  1387 (epoch  1): loss=0.06227\n",
            " 2024-07-03 07:20:22,277 - INFO -marigold_trainer.py - train >> iter  1388 (epoch  1): loss=0.10945\n",
            " 2024-07-03 07:20:26,594 - INFO -marigold_trainer.py - train >> iter  1389 (epoch  1): loss=0.08234\n",
            " 2024-07-03 07:20:30,907 - INFO -marigold_trainer.py - train >> iter  1390 (epoch  1): loss=0.07369\n",
            " 2024-07-03 07:20:35,273 - INFO -marigold_trainer.py - train >> iter  1391 (epoch  1): loss=0.10629\n",
            " 2024-07-03 07:20:39,590 - INFO -marigold_trainer.py - train >> iter  1392 (epoch  1): loss=0.14334\n",
            " 2024-07-03 07:20:43,884 - INFO -marigold_trainer.py - train >> iter  1393 (epoch  1): loss=0.10376\n",
            " 2024-07-03 07:20:48,194 - INFO -marigold_trainer.py - train >> iter  1394 (epoch  1): loss=0.12097\n",
            " 2024-07-03 07:20:52,518 - INFO -marigold_trainer.py - train >> iter  1395 (epoch  1): loss=0.09400\n",
            " 2024-07-03 07:20:56,807 - INFO -marigold_trainer.py - train >> iter  1396 (epoch  1): loss=0.10574\n",
            " 2024-07-03 07:21:01,105 - INFO -marigold_trainer.py - train >> iter  1397 (epoch  1): loss=0.06298\n",
            " 2024-07-03 07:21:05,406 - INFO -marigold_trainer.py - train >> iter  1398 (epoch  1): loss=0.11087\n",
            " 2024-07-03 07:21:09,703 - INFO -marigold_trainer.py - train >> iter  1399 (epoch  1): loss=0.10802\n",
            " 2024-07-03 07:21:14,010 - INFO -marigold_trainer.py - train >> iter  1400 (epoch  1): loss=0.06576\n",
            " 2024-07-03 07:21:14,011 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:21:25,635 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:21:44,030 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:21:49,846 - INFO -marigold_trainer.py - train >> iter  1401 (epoch  1): loss=0.07927\n",
            " 2024-07-03 07:21:54,149 - INFO -marigold_trainer.py - train >> iter  1402 (epoch  1): loss=0.09548\n",
            " 2024-07-03 07:21:58,464 - INFO -marigold_trainer.py - train >> iter  1403 (epoch  1): loss=0.09614\n",
            " 2024-07-03 07:22:02,781 - INFO -marigold_trainer.py - train >> iter  1404 (epoch  1): loss=0.08422\n",
            " 2024-07-03 07:22:07,083 - INFO -marigold_trainer.py - train >> iter  1405 (epoch  1): loss=0.11127\n",
            " 2024-07-03 07:22:11,398 - INFO -marigold_trainer.py - train >> iter  1406 (epoch  1): loss=0.12128\n",
            " 2024-07-03 07:22:15,734 - INFO -marigold_trainer.py - train >> iter  1407 (epoch  1): loss=0.09487\n",
            " 2024-07-03 07:22:20,070 - INFO -marigold_trainer.py - train >> iter  1408 (epoch  1): loss=0.11873\n",
            " 2024-07-03 07:22:24,382 - INFO -marigold_trainer.py - train >> iter  1409 (epoch  1): loss=0.13113\n",
            " 2024-07-03 07:22:28,709 - INFO -marigold_trainer.py - train >> iter  1410 (epoch  1): loss=0.09009\n",
            " 2024-07-03 07:22:33,015 - INFO -marigold_trainer.py - train >> iter  1411 (epoch  1): loss=0.09832\n",
            " 2024-07-03 07:22:37,402 - INFO -marigold_trainer.py - train >> iter  1412 (epoch  1): loss=0.11754\n",
            " 2024-07-03 07:22:41,708 - INFO -marigold_trainer.py - train >> iter  1413 (epoch  1): loss=0.09555\n",
            " 2024-07-03 07:22:46,011 - INFO -marigold_trainer.py - train >> iter  1414 (epoch  1): loss=0.09881\n",
            " 2024-07-03 07:22:50,326 - INFO -marigold_trainer.py - train >> iter  1415 (epoch  1): loss=0.09845\n",
            " 2024-07-03 07:22:54,640 - INFO -marigold_trainer.py - train >> iter  1416 (epoch  1): loss=0.09283\n",
            " 2024-07-03 07:22:58,944 - INFO -marigold_trainer.py - train >> iter  1417 (epoch  1): loss=0.11933\n",
            " 2024-07-03 07:23:03,261 - INFO -marigold_trainer.py - train >> iter  1418 (epoch  1): loss=0.11706\n",
            " 2024-07-03 07:23:07,552 - INFO -marigold_trainer.py - train >> iter  1419 (epoch  1): loss=0.09230\n",
            " 2024-07-03 07:23:11,863 - INFO -marigold_trainer.py - train >> iter  1420 (epoch  1): loss=0.10549\n",
            " 2024-07-03 07:23:16,174 - INFO -marigold_trainer.py - train >> iter  1421 (epoch  1): loss=0.08872\n",
            " 2024-07-03 07:23:20,460 - INFO -marigold_trainer.py - train >> iter  1422 (epoch  1): loss=0.10365\n",
            " 2024-07-03 07:23:24,775 - INFO -marigold_trainer.py - train >> iter  1423 (epoch  1): loss=0.07995\n",
            " 2024-07-03 07:23:29,066 - INFO -marigold_trainer.py - train >> iter  1424 (epoch  1): loss=0.10827\n",
            " 2024-07-03 07:23:33,363 - INFO -marigold_trainer.py - train >> iter  1425 (epoch  1): loss=0.08509\n",
            " 2024-07-03 07:23:37,675 - INFO -marigold_trainer.py - train >> iter  1426 (epoch  1): loss=0.07649\n",
            " 2024-07-03 07:23:42,104 - INFO -marigold_trainer.py - train >> iter  1427 (epoch  1): loss=0.10769\n",
            " 2024-07-03 07:23:46,409 - INFO -marigold_trainer.py - train >> iter  1428 (epoch  1): loss=0.11993\n",
            " 2024-07-03 07:23:50,731 - INFO -marigold_trainer.py - train >> iter  1429 (epoch  1): loss=0.10325\n",
            " 2024-07-03 07:23:55,048 - INFO -marigold_trainer.py - train >> iter  1430 (epoch  1): loss=0.09399\n",
            " 2024-07-03 07:23:59,357 - INFO -marigold_trainer.py - train >> iter  1431 (epoch  1): loss=0.12826\n",
            " 2024-07-03 07:24:03,674 - INFO -marigold_trainer.py - train >> iter  1432 (epoch  1): loss=0.07907\n",
            " 2024-07-03 07:24:07,986 - INFO -marigold_trainer.py - train >> iter  1433 (epoch  1): loss=0.10368\n",
            " 2024-07-03 07:24:12,289 - INFO -marigold_trainer.py - train >> iter  1434 (epoch  1): loss=0.08919\n",
            " 2024-07-03 07:24:16,816 - INFO -marigold_trainer.py - train >> iter  1435 (epoch  1): loss=0.09601\n",
            " 2024-07-03 07:24:21,128 - INFO -marigold_trainer.py - train >> iter  1436 (epoch  1): loss=0.11716\n",
            " 2024-07-03 07:24:25,436 - INFO -marigold_trainer.py - train >> iter  1437 (epoch  1): loss=0.08920\n",
            " 2024-07-03 07:24:29,732 - INFO -marigold_trainer.py - train >> iter  1438 (epoch  1): loss=0.06614\n",
            " 2024-07-03 07:24:34,031 - INFO -marigold_trainer.py - train >> iter  1439 (epoch  1): loss=0.08052\n",
            " 2024-07-03 07:24:38,354 - INFO -marigold_trainer.py - train >> iter  1440 (epoch  1): loss=0.06214\n",
            " 2024-07-03 07:24:42,735 - INFO -marigold_trainer.py - train >> iter  1441 (epoch  1): loss=0.08091\n",
            " 2024-07-03 07:24:47,057 - INFO -marigold_trainer.py - train >> iter  1442 (epoch  1): loss=0.12041\n",
            " 2024-07-03 07:24:51,359 - INFO -marigold_trainer.py - train >> iter  1443 (epoch  1): loss=0.09708\n",
            " 2024-07-03 07:24:55,661 - INFO -marigold_trainer.py - train >> iter  1444 (epoch  1): loss=0.05962\n",
            " 2024-07-03 07:24:59,965 - INFO -marigold_trainer.py - train >> iter  1445 (epoch  1): loss=0.11160\n",
            " 2024-07-03 07:25:04,262 - INFO -marigold_trainer.py - train >> iter  1446 (epoch  1): loss=0.12717\n",
            " 2024-07-03 07:25:08,551 - INFO -marigold_trainer.py - train >> iter  1447 (epoch  1): loss=0.08422\n",
            " 2024-07-03 07:25:12,879 - INFO -marigold_trainer.py - train >> iter  1448 (epoch  1): loss=0.06723\n",
            " 2024-07-03 07:25:17,183 - INFO -marigold_trainer.py - train >> iter  1449 (epoch  1): loss=0.06674\n",
            " 2024-07-03 07:25:21,475 - INFO -marigold_trainer.py - train >> iter  1450 (epoch  1): loss=0.08488\n",
            " 2024-07-03 07:25:21,476 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:25:31,089 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:25:50,553 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:25:56,392 - INFO -marigold_trainer.py - train >> iter  1451 (epoch  1): loss=0.05853\n",
            " 2024-07-03 07:26:00,703 - INFO -marigold_trainer.py - train >> iter  1452 (epoch  1): loss=0.09728\n",
            " 2024-07-03 07:26:05,005 - INFO -marigold_trainer.py - train >> iter  1453 (epoch  1): loss=0.05105\n",
            " 2024-07-03 07:26:09,303 - INFO -marigold_trainer.py - train >> iter  1454 (epoch  1): loss=0.10301\n",
            " 2024-07-03 07:26:13,624 - INFO -marigold_trainer.py - train >> iter  1455 (epoch  1): loss=0.06534\n",
            " 2024-07-03 07:26:17,940 - INFO -marigold_trainer.py - train >> iter  1456 (epoch  1): loss=0.11646\n",
            " 2024-07-03 07:26:22,259 - INFO -marigold_trainer.py - train >> iter  1457 (epoch  1): loss=0.06544\n",
            " 2024-07-03 07:26:26,601 - INFO -marigold_trainer.py - train >> iter  1458 (epoch  1): loss=0.11690\n",
            " 2024-07-03 07:26:30,916 - INFO -marigold_trainer.py - train >> iter  1459 (epoch  1): loss=0.13663\n",
            " 2024-07-03 07:26:35,227 - INFO -marigold_trainer.py - train >> iter  1460 (epoch  1): loss=0.11209\n",
            " 2024-07-03 07:26:39,547 - INFO -marigold_trainer.py - train >> iter  1461 (epoch  1): loss=0.06891\n",
            " 2024-07-03 07:26:43,930 - INFO -marigold_trainer.py - train >> iter  1462 (epoch  1): loss=0.05847\n",
            " 2024-07-03 07:26:48,235 - INFO -marigold_trainer.py - train >> iter  1463 (epoch  1): loss=0.06787\n",
            " 2024-07-03 07:26:52,529 - INFO -marigold_trainer.py - train >> iter  1464 (epoch  1): loss=0.08511\n",
            " 2024-07-03 07:26:56,819 - INFO -marigold_trainer.py - train >> iter  1465 (epoch  1): loss=0.08747\n",
            " 2024-07-03 07:27:01,148 - INFO -marigold_trainer.py - train >> iter  1466 (epoch  1): loss=0.10044\n",
            " 2024-07-03 07:27:05,433 - INFO -marigold_trainer.py - train >> iter  1467 (epoch  1): loss=0.04887\n",
            " 2024-07-03 07:27:09,734 - INFO -marigold_trainer.py - train >> iter  1468 (epoch  1): loss=0.15601\n",
            " 2024-07-03 07:27:14,036 - INFO -marigold_trainer.py - train >> iter  1469 (epoch  1): loss=0.09020\n",
            " 2024-07-03 07:27:18,325 - INFO -marigold_trainer.py - train >> iter  1470 (epoch  1): loss=0.07333\n",
            " 2024-07-03 07:27:22,615 - INFO -marigold_trainer.py - train >> iter  1471 (epoch  1): loss=0.08876\n",
            " 2024-07-03 07:27:26,934 - INFO -marigold_trainer.py - train >> iter  1472 (epoch  1): loss=0.08209\n",
            " 2024-07-03 07:27:31,227 - INFO -marigold_trainer.py - train >> iter  1473 (epoch  1): loss=0.07350\n",
            " 2024-07-03 07:27:35,540 - INFO -marigold_trainer.py - train >> iter  1474 (epoch  1): loss=0.13774\n",
            " 2024-07-03 07:27:39,830 - INFO -marigold_trainer.py - train >> iter  1475 (epoch  1): loss=0.06382\n",
            " 2024-07-03 07:27:44,199 - INFO -marigold_trainer.py - train >> iter  1476 (epoch  1): loss=0.06964\n",
            " 2024-07-03 07:27:48,532 - INFO -marigold_trainer.py - train >> iter  1477 (epoch  1): loss=0.11734\n",
            " 2024-07-03 07:27:52,877 - INFO -marigold_trainer.py - train >> iter  1478 (epoch  1): loss=0.11912\n",
            " 2024-07-03 07:27:57,170 - INFO -marigold_trainer.py - train >> iter  1479 (epoch  1): loss=0.09782\n",
            " 2024-07-03 07:28:01,466 - INFO -marigold_trainer.py - train >> iter  1480 (epoch  1): loss=0.08841\n",
            " 2024-07-03 07:28:05,767 - INFO -marigold_trainer.py - train >> iter  1481 (epoch  1): loss=0.09631\n",
            " 2024-07-03 07:28:10,072 - INFO -marigold_trainer.py - train >> iter  1482 (epoch  1): loss=0.06954\n",
            " 2024-07-03 07:28:14,400 - INFO -marigold_trainer.py - train >> iter  1483 (epoch  1): loss=0.11782\n",
            " 2024-07-03 07:28:18,728 - INFO -marigold_trainer.py - train >> iter  1484 (epoch  1): loss=0.11911\n",
            " 2024-07-03 07:28:23,061 - INFO -marigold_trainer.py - train >> iter  1485 (epoch  1): loss=0.05846\n",
            " 2024-07-03 07:28:27,359 - INFO -marigold_trainer.py - train >> iter  1486 (epoch  1): loss=0.08982\n",
            " 2024-07-03 07:28:31,656 - INFO -marigold_trainer.py - train >> iter  1487 (epoch  1): loss=0.11826\n",
            " 2024-07-03 07:28:35,973 - INFO -marigold_trainer.py - train >> iter  1488 (epoch  1): loss=0.09970\n",
            " 2024-07-03 07:28:40,275 - INFO -marigold_trainer.py - train >> iter  1489 (epoch  1): loss=0.06570\n",
            " 2024-07-03 07:28:44,596 - INFO -marigold_trainer.py - train >> iter  1490 (epoch  1): loss=0.11665\n",
            " 2024-07-03 07:28:48,991 - INFO -marigold_trainer.py - train >> iter  1491 (epoch  1): loss=0.10896\n",
            " 2024-07-03 07:28:53,293 - INFO -marigold_trainer.py - train >> iter  1492 (epoch  1): loss=0.08271\n",
            " 2024-07-03 07:28:57,584 - INFO -marigold_trainer.py - train >> iter  1493 (epoch  1): loss=0.07965\n",
            " 2024-07-03 07:29:01,929 - INFO -marigold_trainer.py - train >> iter  1494 (epoch  1): loss=0.07193\n",
            " 2024-07-03 07:29:06,218 - INFO -marigold_trainer.py - train >> iter  1495 (epoch  1): loss=0.07530\n",
            " 2024-07-03 07:29:10,526 - INFO -marigold_trainer.py - train >> iter  1496 (epoch  1): loss=0.09381\n",
            " 2024-07-03 07:29:14,837 - INFO -marigold_trainer.py - train >> iter  1497 (epoch  1): loss=0.06563\n",
            " 2024-07-03 07:29:19,151 - INFO -marigold_trainer.py - train >> iter  1498 (epoch  1): loss=0.09041\n",
            " 2024-07-03 07:29:23,454 - INFO -marigold_trainer.py - train >> iter  1499 (epoch  1): loss=0.07629\n",
            " 2024-07-03 07:29:27,758 - INFO -marigold_trainer.py - train >> iter  1500 (epoch  1): loss=0.06518\n",
            " 2024-07-03 07:29:27,758 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:29:37,078 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:29:55,743 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:30:01,561 - INFO -marigold_trainer.py - train >> iter  1501 (epoch  1): loss=0.08901\n",
            " 2024-07-03 07:30:05,858 - INFO -marigold_trainer.py - train >> iter  1502 (epoch  1): loss=0.08595\n",
            " 2024-07-03 07:30:10,168 - INFO -marigold_trainer.py - train >> iter  1503 (epoch  1): loss=0.06084\n",
            " 2024-07-03 07:30:14,483 - INFO -marigold_trainer.py - train >> iter  1504 (epoch  1): loss=0.09122\n",
            " 2024-07-03 07:30:18,802 - INFO -marigold_trainer.py - train >> iter  1505 (epoch  1): loss=0.07292\n",
            " 2024-07-03 07:30:23,143 - INFO -marigold_trainer.py - train >> iter  1506 (epoch  1): loss=0.12064\n",
            " 2024-07-03 07:30:27,455 - INFO -marigold_trainer.py - train >> iter  1507 (epoch  1): loss=0.08427\n",
            " 2024-07-03 07:30:31,775 - INFO -marigold_trainer.py - train >> iter  1508 (epoch  1): loss=0.13338\n",
            " 2024-07-03 07:30:36,096 - INFO -marigold_trainer.py - train >> iter  1509 (epoch  1): loss=0.10373\n",
            " 2024-07-03 07:30:40,411 - INFO -marigold_trainer.py - train >> iter  1510 (epoch  1): loss=0.08844\n",
            " 2024-07-03 07:30:44,714 - INFO -marigold_trainer.py - train >> iter  1511 (epoch  1): loss=0.08199\n",
            " 2024-07-03 07:30:49,120 - INFO -marigold_trainer.py - train >> iter  1512 (epoch  1): loss=0.06332\n",
            " 2024-07-03 07:30:53,413 - INFO -marigold_trainer.py - train >> iter  1513 (epoch  1): loss=0.08887\n",
            " 2024-07-03 07:30:57,722 - INFO -marigold_trainer.py - train >> iter  1514 (epoch  1): loss=0.11160\n",
            " 2024-07-03 07:31:02,015 - INFO -marigold_trainer.py - train >> iter  1515 (epoch  1): loss=0.08312\n",
            " 2024-07-03 07:31:06,318 - INFO -marigold_trainer.py - train >> iter  1516 (epoch  1): loss=0.10647\n",
            " 2024-07-03 07:31:10,618 - INFO -marigold_trainer.py - train >> iter  1517 (epoch  1): loss=0.07038\n",
            " 2024-07-03 07:31:14,916 - INFO -marigold_trainer.py - train >> iter  1518 (epoch  1): loss=0.08976\n",
            " 2024-07-03 07:31:19,203 - INFO -marigold_trainer.py - train >> iter  1519 (epoch  1): loss=0.05913\n",
            " 2024-07-03 07:31:23,509 - INFO -marigold_trainer.py - train >> iter  1520 (epoch  1): loss=0.12595\n",
            " 2024-07-03 07:31:27,803 - INFO -marigold_trainer.py - train >> iter  1521 (epoch  1): loss=0.11963\n",
            " 2024-07-03 07:31:32,088 - INFO -marigold_trainer.py - train >> iter  1522 (epoch  1): loss=0.10020\n",
            " 2024-07-03 07:31:36,418 - INFO -marigold_trainer.py - train >> iter  1523 (epoch  1): loss=0.08767\n",
            " 2024-07-03 07:31:40,713 - INFO -marigold_trainer.py - train >> iter  1524 (epoch  1): loss=0.10162\n",
            " 2024-07-03 07:31:45,015 - INFO -marigold_trainer.py - train >> iter  1525 (epoch  1): loss=0.12460\n",
            " 2024-07-03 07:31:49,310 - INFO -marigold_trainer.py - train >> iter  1526 (epoch  1): loss=0.07658\n",
            " 2024-07-03 07:31:53,622 - INFO -marigold_trainer.py - train >> iter  1527 (epoch  1): loss=0.09930\n",
            " 2024-07-03 07:31:57,911 - INFO -marigold_trainer.py - train >> iter  1528 (epoch  1): loss=0.09225\n",
            " 2024-07-03 07:32:02,212 - INFO -marigold_trainer.py - train >> iter  1529 (epoch  1): loss=0.07512\n",
            " 2024-07-03 07:32:06,503 - INFO -marigold_trainer.py - train >> iter  1530 (epoch  1): loss=0.07433\n",
            " 2024-07-03 07:32:10,802 - INFO -marigold_trainer.py - train >> iter  1531 (epoch  1): loss=0.07778\n",
            " 2024-07-03 07:32:15,094 - INFO -marigold_trainer.py - train >> iter  1532 (epoch  1): loss=0.05988\n",
            " 2024-07-03 07:32:19,398 - INFO -marigold_trainer.py - train >> iter  1533 (epoch  1): loss=0.08777\n",
            " 2024-07-03 07:32:23,703 - INFO -marigold_trainer.py - train >> iter  1534 (epoch  1): loss=0.10835\n",
            " 2024-07-03 07:32:27,997 - INFO -marigold_trainer.py - train >> iter  1535 (epoch  1): loss=0.05543\n",
            " 2024-07-03 07:32:32,301 - INFO -marigold_trainer.py - train >> iter  1536 (epoch  1): loss=0.06163\n",
            " 2024-07-03 07:32:36,617 - INFO -marigold_trainer.py - train >> iter  1537 (epoch  1): loss=0.08537\n",
            " 2024-07-03 07:32:40,930 - INFO -marigold_trainer.py - train >> iter  1538 (epoch  1): loss=0.07473\n",
            " 2024-07-03 07:32:45,211 - INFO -marigold_trainer.py - train >> iter  1539 (epoch  1): loss=0.11203\n",
            " 2024-07-03 07:32:49,511 - INFO -marigold_trainer.py - train >> iter  1540 (epoch  1): loss=0.08851\n",
            " 2024-07-03 07:32:53,923 - INFO -marigold_trainer.py - train >> iter  1541 (epoch  1): loss=0.09276\n",
            " 2024-07-03 07:32:58,250 - INFO -marigold_trainer.py - train >> iter  1542 (epoch  1): loss=0.07838\n",
            " 2024-07-03 07:33:02,547 - INFO -marigold_trainer.py - train >> iter  1543 (epoch  1): loss=0.14258\n",
            " 2024-07-03 07:33:06,837 - INFO -marigold_trainer.py - train >> iter  1544 (epoch  1): loss=0.12673\n",
            " 2024-07-03 07:33:11,149 - INFO -marigold_trainer.py - train >> iter  1545 (epoch  1): loss=0.08705\n",
            " 2024-07-03 07:33:15,443 - INFO -marigold_trainer.py - train >> iter  1546 (epoch  1): loss=0.11540\n",
            " 2024-07-03 07:33:19,743 - INFO -marigold_trainer.py - train >> iter  1547 (epoch  1): loss=0.09187\n",
            " 2024-07-03 07:33:24,043 - INFO -marigold_trainer.py - train >> iter  1548 (epoch  1): loss=0.11209\n",
            " 2024-07-03 07:33:28,333 - INFO -marigold_trainer.py - train >> iter  1549 (epoch  1): loss=0.08879\n",
            " 2024-07-03 07:33:32,647 - INFO -marigold_trainer.py - train >> iter  1550 (epoch  1): loss=0.06959\n",
            " 2024-07-03 07:33:32,648 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:33:41,359 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:34:00,691 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:34:06,544 - INFO -marigold_trainer.py - train >> iter  1551 (epoch  1): loss=0.09620\n",
            " 2024-07-03 07:34:10,841 - INFO -marigold_trainer.py - train >> iter  1552 (epoch  1): loss=0.08379\n",
            " 2024-07-03 07:34:15,145 - INFO -marigold_trainer.py - train >> iter  1553 (epoch  1): loss=0.09025\n",
            " 2024-07-03 07:34:19,476 - INFO -marigold_trainer.py - train >> iter  1554 (epoch  1): loss=0.06714\n",
            " 2024-07-03 07:34:23,807 - INFO -marigold_trainer.py - train >> iter  1555 (epoch  1): loss=0.08886\n",
            " 2024-07-03 07:34:28,120 - INFO -marigold_trainer.py - train >> iter  1556 (epoch  1): loss=0.07928\n",
            " 2024-07-03 07:34:32,433 - INFO -marigold_trainer.py - train >> iter  1557 (epoch  1): loss=0.09359\n",
            " 2024-07-03 07:34:36,804 - INFO -marigold_trainer.py - train >> iter  1558 (epoch  1): loss=0.12537\n",
            " 2024-07-03 07:34:41,118 - INFO -marigold_trainer.py - train >> iter  1559 (epoch  1): loss=0.09975\n",
            " 2024-07-03 07:34:45,417 - INFO -marigold_trainer.py - train >> iter  1560 (epoch  1): loss=0.13905\n",
            " 2024-07-03 07:34:49,747 - INFO -marigold_trainer.py - train >> iter  1561 (epoch  1): loss=0.09082\n",
            " 2024-07-03 07:34:54,155 - INFO -marigold_trainer.py - train >> iter  1562 (epoch  1): loss=0.09900\n",
            " 2024-07-03 07:34:58,739 - INFO -marigold_trainer.py - train >> iter  1563 (epoch  2): loss=0.10280\n",
            " 2024-07-03 07:35:03,059 - INFO -marigold_trainer.py - train >> iter  1564 (epoch  2): loss=0.09089\n",
            " 2024-07-03 07:35:07,374 - INFO -marigold_trainer.py - train >> iter  1565 (epoch  2): loss=0.08882\n",
            " 2024-07-03 07:35:11,692 - INFO -marigold_trainer.py - train >> iter  1566 (epoch  2): loss=0.08232\n",
            " 2024-07-03 07:35:16,180 - INFO -marigold_trainer.py - train >> iter  1567 (epoch  2): loss=0.11248\n",
            " 2024-07-03 07:35:20,577 - INFO -marigold_trainer.py - train >> iter  1568 (epoch  2): loss=0.09794\n",
            " 2024-07-03 07:35:24,909 - INFO -marigold_trainer.py - train >> iter  1569 (epoch  2): loss=0.09445\n",
            " 2024-07-03 07:35:29,219 - INFO -marigold_trainer.py - train >> iter  1570 (epoch  2): loss=0.05194\n",
            " 2024-07-03 07:35:33,545 - INFO -marigold_trainer.py - train >> iter  1571 (epoch  2): loss=0.06830\n",
            " 2024-07-03 07:35:37,865 - INFO -marigold_trainer.py - train >> iter  1572 (epoch  2): loss=0.10526\n",
            " 2024-07-03 07:35:42,199 - INFO -marigold_trainer.py - train >> iter  1573 (epoch  2): loss=0.13083\n",
            " 2024-07-03 07:35:46,527 - INFO -marigold_trainer.py - train >> iter  1574 (epoch  2): loss=0.09431\n",
            " 2024-07-03 07:35:50,834 - INFO -marigold_trainer.py - train >> iter  1575 (epoch  2): loss=0.07204\n",
            " 2024-07-03 07:35:55,168 - INFO -marigold_trainer.py - train >> iter  1576 (epoch  2): loss=0.09612\n",
            " 2024-07-03 07:35:59,523 - INFO -marigold_trainer.py - train >> iter  1577 (epoch  2): loss=0.09019\n",
            " 2024-07-03 07:36:03,860 - INFO -marigold_trainer.py - train >> iter  1578 (epoch  2): loss=0.12870\n",
            " 2024-07-03 07:36:08,205 - INFO -marigold_trainer.py - train >> iter  1579 (epoch  2): loss=0.12245\n",
            " 2024-07-03 07:36:12,538 - INFO -marigold_trainer.py - train >> iter  1580 (epoch  2): loss=0.08755\n",
            " 2024-07-03 07:36:16,871 - INFO -marigold_trainer.py - train >> iter  1581 (epoch  2): loss=0.07338\n",
            " 2024-07-03 07:36:21,210 - INFO -marigold_trainer.py - train >> iter  1582 (epoch  2): loss=0.08403\n",
            " 2024-07-03 07:36:25,567 - INFO -marigold_trainer.py - train >> iter  1583 (epoch  2): loss=0.17081\n",
            " 2024-07-03 07:36:29,905 - INFO -marigold_trainer.py - train >> iter  1584 (epoch  2): loss=0.06655\n",
            " 2024-07-03 07:36:34,247 - INFO -marigold_trainer.py - train >> iter  1585 (epoch  2): loss=0.06477\n",
            " 2024-07-03 07:36:38,581 - INFO -marigold_trainer.py - train >> iter  1586 (epoch  2): loss=0.11051\n",
            " 2024-07-03 07:36:42,907 - INFO -marigold_trainer.py - train >> iter  1587 (epoch  2): loss=0.07073\n",
            " 2024-07-03 07:36:47,269 - INFO -marigold_trainer.py - train >> iter  1588 (epoch  2): loss=0.09574\n",
            " 2024-07-03 07:36:51,581 - INFO -marigold_trainer.py - train >> iter  1589 (epoch  2): loss=0.09328\n",
            " 2024-07-03 07:36:55,900 - INFO -marigold_trainer.py - train >> iter  1590 (epoch  2): loss=0.09845\n",
            " 2024-07-03 07:37:00,297 - INFO -marigold_trainer.py - train >> iter  1591 (epoch  2): loss=0.14163\n",
            " 2024-07-03 07:37:04,618 - INFO -marigold_trainer.py - train >> iter  1592 (epoch  2): loss=0.06385\n",
            " 2024-07-03 07:37:08,926 - INFO -marigold_trainer.py - train >> iter  1593 (epoch  2): loss=0.10549\n",
            " 2024-07-03 07:37:13,255 - INFO -marigold_trainer.py - train >> iter  1594 (epoch  2): loss=0.07100\n",
            " 2024-07-03 07:37:17,569 - INFO -marigold_trainer.py - train >> iter  1595 (epoch  2): loss=0.09254\n",
            " 2024-07-03 07:37:21,904 - INFO -marigold_trainer.py - train >> iter  1596 (epoch  2): loss=0.09460\n",
            " 2024-07-03 07:37:26,223 - INFO -marigold_trainer.py - train >> iter  1597 (epoch  2): loss=0.10901\n",
            " 2024-07-03 07:37:30,547 - INFO -marigold_trainer.py - train >> iter  1598 (epoch  2): loss=0.07474\n",
            " 2024-07-03 07:37:34,895 - INFO -marigold_trainer.py - train >> iter  1599 (epoch  2): loss=0.05936\n",
            " 2024-07-03 07:37:39,206 - INFO -marigold_trainer.py - train >> iter  1600 (epoch  2): loss=0.08296\n",
            " 2024-07-03 07:37:39,207 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:37:51,508 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:38:11,960 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:38:18,580 - INFO -marigold_trainer.py - train >> iter  1601 (epoch  2): loss=0.07041\n",
            " 2024-07-03 07:38:23,110 - INFO -marigold_trainer.py - train >> iter  1602 (epoch  2): loss=0.08665\n",
            " 2024-07-03 07:38:27,542 - INFO -marigold_trainer.py - train >> iter  1603 (epoch  2): loss=0.10214\n",
            " 2024-07-03 07:38:31,869 - INFO -marigold_trainer.py - train >> iter  1604 (epoch  2): loss=0.08998\n",
            " 2024-07-03 07:38:36,211 - INFO -marigold_trainer.py - train >> iter  1605 (epoch  2): loss=0.10148\n",
            " 2024-07-03 07:38:40,567 - INFO -marigold_trainer.py - train >> iter  1606 (epoch  2): loss=0.09314\n",
            " 2024-07-03 07:38:44,922 - INFO -marigold_trainer.py - train >> iter  1607 (epoch  2): loss=0.09009\n",
            " 2024-07-03 07:38:49,268 - INFO -marigold_trainer.py - train >> iter  1608 (epoch  2): loss=0.12698\n",
            " 2024-07-03 07:38:53,610 - INFO -marigold_trainer.py - train >> iter  1609 (epoch  2): loss=0.08249\n",
            " 2024-07-03 07:38:57,960 - INFO -marigold_trainer.py - train >> iter  1610 (epoch  2): loss=0.15363\n",
            " 2024-07-03 07:39:02,378 - INFO -marigold_trainer.py - train >> iter  1611 (epoch  2): loss=0.08685\n",
            " 2024-07-03 07:39:06,698 - INFO -marigold_trainer.py - train >> iter  1612 (epoch  2): loss=0.08048\n",
            " 2024-07-03 07:39:11,032 - INFO -marigold_trainer.py - train >> iter  1613 (epoch  2): loss=0.13764\n",
            " 2024-07-03 07:39:15,365 - INFO -marigold_trainer.py - train >> iter  1614 (epoch  2): loss=0.09442\n",
            " 2024-07-03 07:39:19,687 - INFO -marigold_trainer.py - train >> iter  1615 (epoch  2): loss=0.06648\n",
            " 2024-07-03 07:39:24,052 - INFO -marigold_trainer.py - train >> iter  1616 (epoch  2): loss=0.10089\n",
            " 2024-07-03 07:39:28,371 - INFO -marigold_trainer.py - train >> iter  1617 (epoch  2): loss=0.10123\n",
            " 2024-07-03 07:39:32,685 - INFO -marigold_trainer.py - train >> iter  1618 (epoch  2): loss=0.09247\n",
            " 2024-07-03 07:39:37,045 - INFO -marigold_trainer.py - train >> iter  1619 (epoch  2): loss=0.11864\n",
            " 2024-07-03 07:39:41,344 - INFO -marigold_trainer.py - train >> iter  1620 (epoch  2): loss=0.09300\n",
            " 2024-07-03 07:39:45,665 - INFO -marigold_trainer.py - train >> iter  1621 (epoch  2): loss=0.10242\n",
            " 2024-07-03 07:39:49,985 - INFO -marigold_trainer.py - train >> iter  1622 (epoch  2): loss=0.06871\n",
            " 2024-07-03 07:39:54,300 - INFO -marigold_trainer.py - train >> iter  1623 (epoch  2): loss=0.09136\n",
            " 2024-07-03 07:39:58,632 - INFO -marigold_trainer.py - train >> iter  1624 (epoch  2): loss=0.10267\n",
            " 2024-07-03 07:40:03,041 - INFO -marigold_trainer.py - train >> iter  1625 (epoch  2): loss=0.10015\n",
            " 2024-07-03 07:40:07,358 - INFO -marigold_trainer.py - train >> iter  1626 (epoch  2): loss=0.11985\n",
            " 2024-07-03 07:40:11,690 - INFO -marigold_trainer.py - train >> iter  1627 (epoch  2): loss=0.07778\n",
            " 2024-07-03 07:40:16,015 - INFO -marigold_trainer.py - train >> iter  1628 (epoch  2): loss=0.12006\n",
            " 2024-07-03 07:40:20,335 - INFO -marigold_trainer.py - train >> iter  1629 (epoch  2): loss=0.09721\n",
            " 2024-07-03 07:40:24,658 - INFO -marigold_trainer.py - train >> iter  1630 (epoch  2): loss=0.08253\n",
            " 2024-07-03 07:40:28,972 - INFO -marigold_trainer.py - train >> iter  1631 (epoch  2): loss=0.11514\n",
            " 2024-07-03 07:40:33,300 - INFO -marigold_trainer.py - train >> iter  1632 (epoch  2): loss=0.09794\n",
            " 2024-07-03 07:40:37,616 - INFO -marigold_trainer.py - train >> iter  1633 (epoch  2): loss=0.12199\n",
            " 2024-07-03 07:40:41,940 - INFO -marigold_trainer.py - train >> iter  1634 (epoch  2): loss=0.06829\n",
            " 2024-07-03 07:40:46,260 - INFO -marigold_trainer.py - train >> iter  1635 (epoch  2): loss=0.07360\n",
            " 2024-07-03 07:40:50,593 - INFO -marigold_trainer.py - train >> iter  1636 (epoch  2): loss=0.08728\n",
            " 2024-07-03 07:40:54,914 - INFO -marigold_trainer.py - train >> iter  1637 (epoch  2): loss=0.05798\n",
            " 2024-07-03 07:40:59,235 - INFO -marigold_trainer.py - train >> iter  1638 (epoch  2): loss=0.09149\n",
            " 2024-07-03 07:41:03,619 - INFO -marigold_trainer.py - train >> iter  1639 (epoch  2): loss=0.07129\n",
            " 2024-07-03 07:41:07,941 - INFO -marigold_trainer.py - train >> iter  1640 (epoch  2): loss=0.06520\n",
            " 2024-07-03 07:41:12,293 - INFO -marigold_trainer.py - train >> iter  1641 (epoch  2): loss=0.09846\n",
            " 2024-07-03 07:41:16,622 - INFO -marigold_trainer.py - train >> iter  1642 (epoch  2): loss=0.05136\n",
            " 2024-07-03 07:41:20,943 - INFO -marigold_trainer.py - train >> iter  1643 (epoch  2): loss=0.10063\n",
            " 2024-07-03 07:41:25,275 - INFO -marigold_trainer.py - train >> iter  1644 (epoch  2): loss=0.11424\n",
            " 2024-07-03 07:41:29,583 - INFO -marigold_trainer.py - train >> iter  1645 (epoch  2): loss=0.08078\n",
            " 2024-07-03 07:41:33,931 - INFO -marigold_trainer.py - train >> iter  1646 (epoch  2): loss=0.07464\n",
            " 2024-07-03 07:41:38,231 - INFO -marigold_trainer.py - train >> iter  1647 (epoch  2): loss=0.08916\n",
            " 2024-07-03 07:41:42,549 - INFO -marigold_trainer.py - train >> iter  1648 (epoch  2): loss=0.14116\n",
            " 2024-07-03 07:41:46,886 - INFO -marigold_trainer.py - train >> iter  1649 (epoch  2): loss=0.08090\n",
            " 2024-07-03 07:41:51,206 - INFO -marigold_trainer.py - train >> iter  1650 (epoch  2): loss=0.07862\n",
            " 2024-07-03 07:41:51,207 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:41:59,733 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:42:19,382 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:42:25,248 - INFO -marigold_trainer.py - train >> iter  1651 (epoch  2): loss=0.06906\n",
            " 2024-07-03 07:42:29,552 - INFO -marigold_trainer.py - train >> iter  1652 (epoch  2): loss=0.06495\n",
            " 2024-07-03 07:42:33,873 - INFO -marigold_trainer.py - train >> iter  1653 (epoch  2): loss=0.10172\n",
            " 2024-07-03 07:42:38,177 - INFO -marigold_trainer.py - train >> iter  1654 (epoch  2): loss=0.10838\n",
            " 2024-07-03 07:42:42,487 - INFO -marigold_trainer.py - train >> iter  1655 (epoch  2): loss=0.08404\n",
            " 2024-07-03 07:42:46,819 - INFO -marigold_trainer.py - train >> iter  1656 (epoch  2): loss=0.09538\n",
            " 2024-07-03 07:42:51,147 - INFO -marigold_trainer.py - train >> iter  1657 (epoch  2): loss=0.10752\n",
            " 2024-07-03 07:42:55,467 - INFO -marigold_trainer.py - train >> iter  1658 (epoch  2): loss=0.09067\n",
            " 2024-07-03 07:42:59,805 - INFO -marigold_trainer.py - train >> iter  1659 (epoch  2): loss=0.06419\n",
            " 2024-07-03 07:43:04,118 - INFO -marigold_trainer.py - train >> iter  1660 (epoch  2): loss=0.11860\n",
            " 2024-07-03 07:43:08,474 - INFO -marigold_trainer.py - train >> iter  1661 (epoch  2): loss=0.08942\n",
            " 2024-07-03 07:43:12,799 - INFO -marigold_trainer.py - train >> iter  1662 (epoch  2): loss=0.08661\n",
            " 2024-07-03 07:43:17,119 - INFO -marigold_trainer.py - train >> iter  1663 (epoch  2): loss=0.09897\n",
            " 2024-07-03 07:43:21,443 - INFO -marigold_trainer.py - train >> iter  1664 (epoch  2): loss=0.06882\n",
            " 2024-07-03 07:43:25,755 - INFO -marigold_trainer.py - train >> iter  1665 (epoch  2): loss=0.09997\n",
            " 2024-07-03 07:43:30,072 - INFO -marigold_trainer.py - train >> iter  1666 (epoch  2): loss=0.08718\n",
            " 2024-07-03 07:43:34,382 - INFO -marigold_trainer.py - train >> iter  1667 (epoch  2): loss=0.06261\n",
            " 2024-07-03 07:43:38,690 - INFO -marigold_trainer.py - train >> iter  1668 (epoch  2): loss=0.08421\n",
            " 2024-07-03 07:43:43,007 - INFO -marigold_trainer.py - train >> iter  1669 (epoch  2): loss=0.07156\n",
            " 2024-07-03 07:43:47,320 - INFO -marigold_trainer.py - train >> iter  1670 (epoch  2): loss=0.09384\n",
            " 2024-07-03 07:43:51,621 - INFO -marigold_trainer.py - train >> iter  1671 (epoch  2): loss=0.08710\n",
            " 2024-07-03 07:43:55,924 - INFO -marigold_trainer.py - train >> iter  1672 (epoch  2): loss=0.09326\n",
            " 2024-07-03 07:44:00,228 - INFO -marigold_trainer.py - train >> iter  1673 (epoch  2): loss=0.08836\n",
            " 2024-07-03 07:44:04,562 - INFO -marigold_trainer.py - train >> iter  1674 (epoch  2): loss=0.08224\n",
            " 2024-07-03 07:44:08,938 - INFO -marigold_trainer.py - train >> iter  1675 (epoch  2): loss=0.13312\n",
            " 2024-07-03 07:44:13,268 - INFO -marigold_trainer.py - train >> iter  1676 (epoch  2): loss=0.05623\n",
            " 2024-07-03 07:44:17,578 - INFO -marigold_trainer.py - train >> iter  1677 (epoch  2): loss=0.09009\n",
            " 2024-07-03 07:44:21,929 - INFO -marigold_trainer.py - train >> iter  1678 (epoch  2): loss=0.09613\n",
            " 2024-07-03 07:44:26,253 - INFO -marigold_trainer.py - train >> iter  1679 (epoch  2): loss=0.08636\n",
            " 2024-07-03 07:44:30,556 - INFO -marigold_trainer.py - train >> iter  1680 (epoch  2): loss=0.06721\n",
            " 2024-07-03 07:44:34,875 - INFO -marigold_trainer.py - train >> iter  1681 (epoch  2): loss=0.10086\n",
            " 2024-07-03 07:44:39,194 - INFO -marigold_trainer.py - train >> iter  1682 (epoch  2): loss=0.08604\n",
            " 2024-07-03 07:44:43,509 - INFO -marigold_trainer.py - train >> iter  1683 (epoch  2): loss=0.08707\n",
            " 2024-07-03 07:44:47,858 - INFO -marigold_trainer.py - train >> iter  1684 (epoch  2): loss=0.07427\n",
            " 2024-07-03 07:44:52,204 - INFO -marigold_trainer.py - train >> iter  1685 (epoch  2): loss=0.12125\n",
            " 2024-07-03 07:44:56,521 - INFO -marigold_trainer.py - train >> iter  1686 (epoch  2): loss=0.11455\n",
            " 2024-07-03 07:45:00,839 - INFO -marigold_trainer.py - train >> iter  1687 (epoch  2): loss=0.08317\n",
            " 2024-07-03 07:45:05,161 - INFO -marigold_trainer.py - train >> iter  1688 (epoch  2): loss=0.10117\n",
            " 2024-07-03 07:45:09,532 - INFO -marigold_trainer.py - train >> iter  1689 (epoch  2): loss=0.09045\n",
            " 2024-07-03 07:45:13,833 - INFO -marigold_trainer.py - train >> iter  1690 (epoch  2): loss=0.11839\n",
            " 2024-07-03 07:45:18,147 - INFO -marigold_trainer.py - train >> iter  1691 (epoch  2): loss=0.07022\n",
            " 2024-07-03 07:45:22,472 - INFO -marigold_trainer.py - train >> iter  1692 (epoch  2): loss=0.07948\n",
            " 2024-07-03 07:45:26,772 - INFO -marigold_trainer.py - train >> iter  1693 (epoch  2): loss=0.06652\n",
            " 2024-07-03 07:45:31,070 - INFO -marigold_trainer.py - train >> iter  1694 (epoch  2): loss=0.12451\n",
            " 2024-07-03 07:45:35,389 - INFO -marigold_trainer.py - train >> iter  1695 (epoch  2): loss=0.08973\n",
            " 2024-07-03 07:45:39,681 - INFO -marigold_trainer.py - train >> iter  1696 (epoch  2): loss=0.07717\n",
            " 2024-07-03 07:45:43,985 - INFO -marigold_trainer.py - train >> iter  1697 (epoch  2): loss=0.08451\n",
            " 2024-07-03 07:45:48,308 - INFO -marigold_trainer.py - train >> iter  1698 (epoch  2): loss=0.12750\n",
            " 2024-07-03 07:45:52,627 - INFO -marigold_trainer.py - train >> iter  1699 (epoch  2): loss=0.10585\n",
            " 2024-07-03 07:45:56,961 - INFO -marigold_trainer.py - train >> iter  1700 (epoch  2): loss=0.06081\n",
            " 2024-07-03 07:45:56,963 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:46:06,210 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:46:25,558 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:46:32,205 - INFO -marigold_trainer.py - train >> iter  1701 (epoch  2): loss=0.09174\n",
            " 2024-07-03 07:46:36,783 - INFO -marigold_trainer.py - train >> iter  1702 (epoch  2): loss=0.07009\n",
            " 2024-07-03 07:46:41,401 - INFO -marigold_trainer.py - train >> iter  1703 (epoch  2): loss=0.08205\n",
            " 2024-07-03 07:46:45,990 - INFO -marigold_trainer.py - train >> iter  1704 (epoch  2): loss=0.08872\n",
            " 2024-07-03 07:46:50,542 - INFO -marigold_trainer.py - train >> iter  1705 (epoch  2): loss=0.05904\n",
            " 2024-07-03 07:46:55,039 - INFO -marigold_trainer.py - train >> iter  1706 (epoch  2): loss=0.08271\n",
            " 2024-07-03 07:46:59,589 - INFO -marigold_trainer.py - train >> iter  1707 (epoch  2): loss=0.11804\n",
            " 2024-07-03 07:47:04,149 - INFO -marigold_trainer.py - train >> iter  1708 (epoch  2): loss=0.10149\n",
            " 2024-07-03 07:47:08,664 - INFO -marigold_trainer.py - train >> iter  1709 (epoch  2): loss=0.07175\n",
            " 2024-07-03 07:47:13,262 - INFO -marigold_trainer.py - train >> iter  1710 (epoch  2): loss=0.07232\n",
            " 2024-07-03 07:47:17,731 - INFO -marigold_trainer.py - train >> iter  1711 (epoch  2): loss=0.10905\n",
            " 2024-07-03 07:47:22,226 - INFO -marigold_trainer.py - train >> iter  1712 (epoch  2): loss=0.08189\n",
            " 2024-07-03 07:47:26,702 - INFO -marigold_trainer.py - train >> iter  1713 (epoch  2): loss=0.09818\n",
            " 2024-07-03 07:47:31,169 - INFO -marigold_trainer.py - train >> iter  1714 (epoch  2): loss=0.06529\n",
            " 2024-07-03 07:47:35,677 - INFO -marigold_trainer.py - train >> iter  1715 (epoch  2): loss=0.14054\n",
            " 2024-07-03 07:47:40,129 - INFO -marigold_trainer.py - train >> iter  1716 (epoch  2): loss=0.05829\n",
            " 2024-07-03 07:47:44,613 - INFO -marigold_trainer.py - train >> iter  1717 (epoch  2): loss=0.11011\n",
            " 2024-07-03 07:47:49,041 - INFO -marigold_trainer.py - train >> iter  1718 (epoch  2): loss=0.11757\n",
            " 2024-07-03 07:47:53,422 - INFO -marigold_trainer.py - train >> iter  1719 (epoch  2): loss=0.08864\n",
            " 2024-07-03 07:47:57,727 - INFO -marigold_trainer.py - train >> iter  1720 (epoch  2): loss=0.12260\n",
            " 2024-07-03 07:48:02,041 - INFO -marigold_trainer.py - train >> iter  1721 (epoch  2): loss=0.09084\n",
            " 2024-07-03 07:48:06,374 - INFO -marigold_trainer.py - train >> iter  1722 (epoch  2): loss=0.06698\n",
            " 2024-07-03 07:48:10,694 - INFO -marigold_trainer.py - train >> iter  1723 (epoch  2): loss=0.08587\n",
            " 2024-07-03 07:48:15,122 - INFO -marigold_trainer.py - train >> iter  1724 (epoch  2): loss=0.05928\n",
            " 2024-07-03 07:48:19,462 - INFO -marigold_trainer.py - train >> iter  1725 (epoch  2): loss=0.09038\n",
            " 2024-07-03 07:48:23,795 - INFO -marigold_trainer.py - train >> iter  1726 (epoch  2): loss=0.05479\n",
            " 2024-07-03 07:48:28,127 - INFO -marigold_trainer.py - train >> iter  1727 (epoch  2): loss=0.08710\n",
            " 2024-07-03 07:48:32,456 - INFO -marigold_trainer.py - train >> iter  1728 (epoch  2): loss=0.07352\n",
            " 2024-07-03 07:48:36,779 - INFO -marigold_trainer.py - train >> iter  1729 (epoch  2): loss=0.08402\n",
            " 2024-07-03 07:48:41,114 - INFO -marigold_trainer.py - train >> iter  1730 (epoch  2): loss=0.11676\n",
            " 2024-07-03 07:48:45,455 - INFO -marigold_trainer.py - train >> iter  1731 (epoch  2): loss=0.08793\n",
            " 2024-07-03 07:48:49,789 - INFO -marigold_trainer.py - train >> iter  1732 (epoch  2): loss=0.11307\n",
            " 2024-07-03 07:48:54,145 - INFO -marigold_trainer.py - train >> iter  1733 (epoch  2): loss=0.08902\n",
            " 2024-07-03 07:48:58,473 - INFO -marigold_trainer.py - train >> iter  1734 (epoch  2): loss=0.11839\n",
            " 2024-07-03 07:49:02,794 - INFO -marigold_trainer.py - train >> iter  1735 (epoch  2): loss=0.07593\n",
            " 2024-07-03 07:49:07,127 - INFO -marigold_trainer.py - train >> iter  1736 (epoch  2): loss=0.09399\n",
            " 2024-07-03 07:49:11,462 - INFO -marigold_trainer.py - train >> iter  1737 (epoch  2): loss=0.10642\n",
            " 2024-07-03 07:49:15,871 - INFO -marigold_trainer.py - train >> iter  1738 (epoch  2): loss=0.13925\n",
            " 2024-07-03 07:49:20,189 - INFO -marigold_trainer.py - train >> iter  1739 (epoch  2): loss=0.11648\n",
            " 2024-07-03 07:49:24,519 - INFO -marigold_trainer.py - train >> iter  1740 (epoch  2): loss=0.07964\n",
            " 2024-07-03 07:49:28,836 - INFO -marigold_trainer.py - train >> iter  1741 (epoch  2): loss=0.09589\n",
            " 2024-07-03 07:49:33,176 - INFO -marigold_trainer.py - train >> iter  1742 (epoch  2): loss=0.08507\n",
            " 2024-07-03 07:49:37,506 - INFO -marigold_trainer.py - train >> iter  1743 (epoch  2): loss=0.06761\n",
            " 2024-07-03 07:49:41,832 - INFO -marigold_trainer.py - train >> iter  1744 (epoch  2): loss=0.09841\n",
            " 2024-07-03 07:49:46,157 - INFO -marigold_trainer.py - train >> iter  1745 (epoch  2): loss=0.08488\n",
            " 2024-07-03 07:49:50,474 - INFO -marigold_trainer.py - train >> iter  1746 (epoch  2): loss=0.11376\n",
            " 2024-07-03 07:49:54,820 - INFO -marigold_trainer.py - train >> iter  1747 (epoch  2): loss=0.05217\n",
            " 2024-07-03 07:49:59,149 - INFO -marigold_trainer.py - train >> iter  1748 (epoch  2): loss=0.12250\n",
            " 2024-07-03 07:50:03,468 - INFO -marigold_trainer.py - train >> iter  1749 (epoch  2): loss=0.08467\n",
            " 2024-07-03 07:50:07,822 - INFO -marigold_trainer.py - train >> iter  1750 (epoch  2): loss=0.09055\n",
            " 2024-07-03 07:50:07,823 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:50:20,435 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:50:39,219 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:50:45,075 - INFO -marigold_trainer.py - train >> iter  1751 (epoch  2): loss=0.05953\n",
            " 2024-07-03 07:50:49,400 - INFO -marigold_trainer.py - train >> iter  1752 (epoch  2): loss=0.06935\n",
            " 2024-07-03 07:50:53,718 - INFO -marigold_trainer.py - train >> iter  1753 (epoch  2): loss=0.07624\n",
            " 2024-07-03 07:50:58,041 - INFO -marigold_trainer.py - train >> iter  1754 (epoch  2): loss=0.05447\n",
            " 2024-07-03 07:51:02,361 - INFO -marigold_trainer.py - train >> iter  1755 (epoch  2): loss=0.09949\n",
            " 2024-07-03 07:51:06,707 - INFO -marigold_trainer.py - train >> iter  1756 (epoch  2): loss=0.10854\n",
            " 2024-07-03 07:51:11,063 - INFO -marigold_trainer.py - train >> iter  1757 (epoch  2): loss=0.09913\n",
            " 2024-07-03 07:51:15,406 - INFO -marigold_trainer.py - train >> iter  1758 (epoch  2): loss=0.12300\n",
            " 2024-07-03 07:51:19,824 - INFO -marigold_trainer.py - train >> iter  1759 (epoch  2): loss=0.09805\n",
            " 2024-07-03 07:51:24,161 - INFO -marigold_trainer.py - train >> iter  1760 (epoch  2): loss=0.07498\n",
            " 2024-07-03 07:51:28,477 - INFO -marigold_trainer.py - train >> iter  1761 (epoch  2): loss=0.13401\n",
            " 2024-07-03 07:51:32,821 - INFO -marigold_trainer.py - train >> iter  1762 (epoch  2): loss=0.08165\n",
            " 2024-07-03 07:51:37,155 - INFO -marigold_trainer.py - train >> iter  1763 (epoch  2): loss=0.10679\n",
            " 2024-07-03 07:51:41,460 - INFO -marigold_trainer.py - train >> iter  1764 (epoch  2): loss=0.09053\n",
            " 2024-07-03 07:51:45,775 - INFO -marigold_trainer.py - train >> iter  1765 (epoch  2): loss=0.10130\n",
            " 2024-07-03 07:51:50,088 - INFO -marigold_trainer.py - train >> iter  1766 (epoch  2): loss=0.09295\n",
            " 2024-07-03 07:51:54,387 - INFO -marigold_trainer.py - train >> iter  1767 (epoch  2): loss=0.08509\n",
            " 2024-07-03 07:51:58,691 - INFO -marigold_trainer.py - train >> iter  1768 (epoch  2): loss=0.09712\n",
            " 2024-07-03 07:52:03,002 - INFO -marigold_trainer.py - train >> iter  1769 (epoch  2): loss=0.12053\n",
            " 2024-07-03 07:52:07,308 - INFO -marigold_trainer.py - train >> iter  1770 (epoch  2): loss=0.09742\n",
            " 2024-07-03 07:52:11,623 - INFO -marigold_trainer.py - train >> iter  1771 (epoch  2): loss=0.06352\n",
            " 2024-07-03 07:52:15,948 - INFO -marigold_trainer.py - train >> iter  1772 (epoch  2): loss=0.06695\n",
            " 2024-07-03 07:52:20,346 - INFO -marigold_trainer.py - train >> iter  1773 (epoch  2): loss=0.10989\n",
            " 2024-07-03 07:52:24,664 - INFO -marigold_trainer.py - train >> iter  1774 (epoch  2): loss=0.07751\n",
            " 2024-07-03 07:52:28,974 - INFO -marigold_trainer.py - train >> iter  1775 (epoch  2): loss=0.12166\n",
            " 2024-07-03 07:52:33,294 - INFO -marigold_trainer.py - train >> iter  1776 (epoch  2): loss=0.10692\n",
            " 2024-07-03 07:52:37,612 - INFO -marigold_trainer.py - train >> iter  1777 (epoch  2): loss=0.08439\n",
            " 2024-07-03 07:52:41,937 - INFO -marigold_trainer.py - train >> iter  1778 (epoch  2): loss=0.09683\n",
            " 2024-07-03 07:52:46,525 - INFO -marigold_trainer.py - train >> iter  1779 (epoch  2): loss=0.08742\n",
            " 2024-07-03 07:52:50,869 - INFO -marigold_trainer.py - train >> iter  1780 (epoch  2): loss=0.06709\n",
            " 2024-07-03 07:52:55,198 - INFO -marigold_trainer.py - train >> iter  1781 (epoch  2): loss=0.10295\n",
            " 2024-07-03 07:52:59,558 - INFO -marigold_trainer.py - train >> iter  1782 (epoch  2): loss=0.07865\n",
            " 2024-07-03 07:53:03,878 - INFO -marigold_trainer.py - train >> iter  1783 (epoch  2): loss=0.07979\n",
            " 2024-07-03 07:53:08,186 - INFO -marigold_trainer.py - train >> iter  1784 (epoch  2): loss=0.07020\n",
            " 2024-07-03 07:53:12,564 - INFO -marigold_trainer.py - train >> iter  1785 (epoch  2): loss=0.08726\n",
            " 2024-07-03 07:53:16,872 - INFO -marigold_trainer.py - train >> iter  1786 (epoch  2): loss=0.08015\n",
            " 2024-07-03 07:53:21,279 - INFO -marigold_trainer.py - train >> iter  1787 (epoch  2): loss=0.10943\n",
            " 2024-07-03 07:53:25,596 - INFO -marigold_trainer.py - train >> iter  1788 (epoch  2): loss=0.06181\n",
            " 2024-07-03 07:53:29,924 - INFO -marigold_trainer.py - train >> iter  1789 (epoch  2): loss=0.05984\n",
            " 2024-07-03 07:53:34,289 - INFO -marigold_trainer.py - train >> iter  1790 (epoch  2): loss=0.04597\n",
            " 2024-07-03 07:53:38,619 - INFO -marigold_trainer.py - train >> iter  1791 (epoch  2): loss=0.09248\n",
            " 2024-07-03 07:53:42,954 - INFO -marigold_trainer.py - train >> iter  1792 (epoch  2): loss=0.14800\n",
            " 2024-07-03 07:53:47,300 - INFO -marigold_trainer.py - train >> iter  1793 (epoch  2): loss=0.09193\n",
            " 2024-07-03 07:53:51,633 - INFO -marigold_trainer.py - train >> iter  1794 (epoch  2): loss=0.07080\n",
            " 2024-07-03 07:53:55,965 - INFO -marigold_trainer.py - train >> iter  1795 (epoch  2): loss=0.07367\n",
            " 2024-07-03 07:54:00,297 - INFO -marigold_trainer.py - train >> iter  1796 (epoch  2): loss=0.12712\n",
            " 2024-07-03 07:54:04,631 - INFO -marigold_trainer.py - train >> iter  1797 (epoch  2): loss=0.11145\n",
            " 2024-07-03 07:54:08,952 - INFO -marigold_trainer.py - train >> iter  1798 (epoch  2): loss=0.06156\n",
            " 2024-07-03 07:54:13,287 - INFO -marigold_trainer.py - train >> iter  1799 (epoch  2): loss=0.05920\n",
            " 2024-07-03 07:54:17,621 - INFO -marigold_trainer.py - train >> iter  1800 (epoch  2): loss=0.08364\n",
            " 2024-07-03 07:54:17,622 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:54:29,841 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:54:49,892 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:54:55,734 - INFO -marigold_trainer.py - train >> iter  1801 (epoch  2): loss=0.07006\n",
            " 2024-07-03 07:55:00,072 - INFO -marigold_trainer.py - train >> iter  1802 (epoch  2): loss=0.09105\n",
            " 2024-07-03 07:55:04,397 - INFO -marigold_trainer.py - train >> iter  1803 (epoch  2): loss=0.11232\n",
            " 2024-07-03 07:55:08,714 - INFO -marigold_trainer.py - train >> iter  1804 (epoch  2): loss=0.10087\n",
            " 2024-07-03 07:55:13,061 - INFO -marigold_trainer.py - train >> iter  1805 (epoch  2): loss=0.12467\n",
            " 2024-07-03 07:55:17,408 - INFO -marigold_trainer.py - train >> iter  1806 (epoch  2): loss=0.10220\n",
            " 2024-07-03 07:55:21,758 - INFO -marigold_trainer.py - train >> iter  1807 (epoch  2): loss=0.10227\n",
            " 2024-07-03 07:55:26,206 - INFO -marigold_trainer.py - train >> iter  1808 (epoch  2): loss=0.07316\n",
            " 2024-07-03 07:55:30,562 - INFO -marigold_trainer.py - train >> iter  1809 (epoch  2): loss=0.14675\n",
            " 2024-07-03 07:55:34,903 - INFO -marigold_trainer.py - train >> iter  1810 (epoch  2): loss=0.11666\n",
            " 2024-07-03 07:55:39,239 - INFO -marigold_trainer.py - train >> iter  1811 (epoch  2): loss=0.11108\n",
            " 2024-07-03 07:55:43,573 - INFO -marigold_trainer.py - train >> iter  1812 (epoch  2): loss=0.07807\n",
            " 2024-07-03 07:55:47,917 - INFO -marigold_trainer.py - train >> iter  1813 (epoch  2): loss=0.08816\n",
            " 2024-07-03 07:55:52,236 - INFO -marigold_trainer.py - train >> iter  1814 (epoch  2): loss=0.07844\n",
            " 2024-07-03 07:55:56,555 - INFO -marigold_trainer.py - train >> iter  1815 (epoch  2): loss=0.05943\n",
            " 2024-07-03 07:56:00,873 - INFO -marigold_trainer.py - train >> iter  1816 (epoch  2): loss=0.06171\n",
            " 2024-07-03 07:56:05,192 - INFO -marigold_trainer.py - train >> iter  1817 (epoch  2): loss=0.09491\n",
            " 2024-07-03 07:56:09,908 - INFO -marigold_trainer.py - train >> iter  1818 (epoch  2): loss=0.08947\n",
            " 2024-07-03 07:56:14,656 - INFO -marigold_trainer.py - train >> iter  1819 (epoch  2): loss=0.09770\n",
            " 2024-07-03 07:56:19,249 - INFO -marigold_trainer.py - train >> iter  1820 (epoch  2): loss=0.11074\n",
            " 2024-07-03 07:56:23,829 - INFO -marigold_trainer.py - train >> iter  1821 (epoch  2): loss=0.08870\n",
            " 2024-07-03 07:56:28,390 - INFO -marigold_trainer.py - train >> iter  1822 (epoch  2): loss=0.09730\n",
            " 2024-07-03 07:56:32,981 - INFO -marigold_trainer.py - train >> iter  1823 (epoch  2): loss=0.09606\n",
            " 2024-07-03 07:56:37,475 - INFO -marigold_trainer.py - train >> iter  1824 (epoch  2): loss=0.10435\n",
            " 2024-07-03 07:56:41,976 - INFO -marigold_trainer.py - train >> iter  1825 (epoch  2): loss=0.06507\n",
            " 2024-07-03 07:56:46,444 - INFO -marigold_trainer.py - train >> iter  1826 (epoch  2): loss=0.09867\n",
            " 2024-07-03 07:56:50,940 - INFO -marigold_trainer.py - train >> iter  1827 (epoch  2): loss=0.10659\n",
            " 2024-07-03 07:56:55,392 - INFO -marigold_trainer.py - train >> iter  1828 (epoch  2): loss=0.09146\n",
            " 2024-07-03 07:56:59,877 - INFO -marigold_trainer.py - train >> iter  1829 (epoch  2): loss=0.06123\n",
            " 2024-07-03 07:57:04,344 - INFO -marigold_trainer.py - train >> iter  1830 (epoch  2): loss=0.09274\n",
            " 2024-07-03 07:57:08,832 - INFO -marigold_trainer.py - train >> iter  1831 (epoch  2): loss=0.10560\n",
            " 2024-07-03 07:57:13,313 - INFO -marigold_trainer.py - train >> iter  1832 (epoch  2): loss=0.08089\n",
            " 2024-07-03 07:57:17,791 - INFO -marigold_trainer.py - train >> iter  1833 (epoch  2): loss=0.09232\n",
            " 2024-07-03 07:57:22,248 - INFO -marigold_trainer.py - train >> iter  1834 (epoch  2): loss=0.06711\n",
            " 2024-07-03 07:57:26,721 - INFO -marigold_trainer.py - train >> iter  1835 (epoch  2): loss=0.12592\n",
            " 2024-07-03 07:57:31,132 - INFO -marigold_trainer.py - train >> iter  1836 (epoch  2): loss=0.07419\n",
            " 2024-07-03 07:57:35,515 - INFO -marigold_trainer.py - train >> iter  1837 (epoch  2): loss=0.06961\n",
            " 2024-07-03 07:57:39,850 - INFO -marigold_trainer.py - train >> iter  1838 (epoch  2): loss=0.12718\n",
            " 2024-07-03 07:57:44,196 - INFO -marigold_trainer.py - train >> iter  1839 (epoch  2): loss=0.14507\n",
            " 2024-07-03 07:57:48,544 - INFO -marigold_trainer.py - train >> iter  1840 (epoch  2): loss=0.05745\n",
            " 2024-07-03 07:57:52,869 - INFO -marigold_trainer.py - train >> iter  1841 (epoch  2): loss=0.08340\n",
            " 2024-07-03 07:57:57,202 - INFO -marigold_trainer.py - train >> iter  1842 (epoch  2): loss=0.07096\n",
            " 2024-07-03 07:58:01,521 - INFO -marigold_trainer.py - train >> iter  1843 (epoch  2): loss=0.10080\n",
            " 2024-07-03 07:58:05,847 - INFO -marigold_trainer.py - train >> iter  1844 (epoch  2): loss=0.08326\n",
            " 2024-07-03 07:58:10,175 - INFO -marigold_trainer.py - train >> iter  1845 (epoch  2): loss=0.08556\n",
            " 2024-07-03 07:58:14,512 - INFO -marigold_trainer.py - train >> iter  1846 (epoch  2): loss=0.08396\n",
            " 2024-07-03 07:58:18,851 - INFO -marigold_trainer.py - train >> iter  1847 (epoch  2): loss=0.11299\n",
            " 2024-07-03 07:58:23,213 - INFO -marigold_trainer.py - train >> iter  1848 (epoch  2): loss=0.08432\n",
            " 2024-07-03 07:58:27,658 - INFO -marigold_trainer.py - train >> iter  1849 (epoch  2): loss=0.08879\n",
            " 2024-07-03 07:58:31,970 - INFO -marigold_trainer.py - train >> iter  1850 (epoch  2): loss=0.09204\n",
            " 2024-07-03 07:58:31,971 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 07:58:44,306 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 07:59:05,173 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 07:59:11,080 - INFO -marigold_trainer.py - train >> iter  1851 (epoch  2): loss=0.09084\n",
            " 2024-07-03 07:59:15,406 - INFO -marigold_trainer.py - train >> iter  1852 (epoch  2): loss=0.06798\n",
            " 2024-07-03 07:59:19,730 - INFO -marigold_trainer.py - train >> iter  1853 (epoch  2): loss=0.06104\n",
            " 2024-07-03 07:59:24,094 - INFO -marigold_trainer.py - train >> iter  1854 (epoch  2): loss=0.06642\n",
            " 2024-07-03 07:59:28,514 - INFO -marigold_trainer.py - train >> iter  1855 (epoch  2): loss=0.07554\n",
            " 2024-07-03 07:59:32,841 - INFO -marigold_trainer.py - train >> iter  1856 (epoch  2): loss=0.07551\n",
            " 2024-07-03 07:59:37,197 - INFO -marigold_trainer.py - train >> iter  1857 (epoch  2): loss=0.16102\n",
            " 2024-07-03 07:59:41,523 - INFO -marigold_trainer.py - train >> iter  1858 (epoch  2): loss=0.08282\n",
            " 2024-07-03 07:59:45,886 - INFO -marigold_trainer.py - train >> iter  1859 (epoch  2): loss=0.07523\n",
            " 2024-07-03 07:59:50,236 - INFO -marigold_trainer.py - train >> iter  1860 (epoch  2): loss=0.06606\n",
            " 2024-07-03 07:59:54,559 - INFO -marigold_trainer.py - train >> iter  1861 (epoch  2): loss=0.08720\n",
            " 2024-07-03 07:59:58,895 - INFO -marigold_trainer.py - train >> iter  1862 (epoch  2): loss=0.08595\n",
            " 2024-07-03 08:00:03,214 - INFO -marigold_trainer.py - train >> iter  1863 (epoch  2): loss=0.09349\n",
            " 2024-07-03 08:00:07,523 - INFO -marigold_trainer.py - train >> iter  1864 (epoch  2): loss=0.07080\n",
            " 2024-07-03 08:00:11,830 - INFO -marigold_trainer.py - train >> iter  1865 (epoch  2): loss=0.13177\n",
            " 2024-07-03 08:00:16,139 - INFO -marigold_trainer.py - train >> iter  1866 (epoch  2): loss=0.04717\n",
            " 2024-07-03 08:00:20,460 - INFO -marigold_trainer.py - train >> iter  1867 (epoch  2): loss=0.08987\n",
            " 2024-07-03 08:00:24,788 - INFO -marigold_trainer.py - train >> iter  1868 (epoch  2): loss=0.10706\n",
            " 2024-07-03 08:00:29,095 - INFO -marigold_trainer.py - train >> iter  1869 (epoch  2): loss=0.08756\n",
            " 2024-07-03 08:00:33,497 - INFO -marigold_trainer.py - train >> iter  1870 (epoch  2): loss=0.12640\n",
            " 2024-07-03 08:00:37,837 - INFO -marigold_trainer.py - train >> iter  1871 (epoch  2): loss=0.08160\n",
            " 2024-07-03 08:00:42,154 - INFO -marigold_trainer.py - train >> iter  1872 (epoch  2): loss=0.06250\n",
            " 2024-07-03 08:00:46,499 - INFO -marigold_trainer.py - train >> iter  1873 (epoch  2): loss=0.14406\n",
            " 2024-07-03 08:00:50,800 - INFO -marigold_trainer.py - train >> iter  1874 (epoch  2): loss=0.07750\n",
            " 2024-07-03 08:00:55,142 - INFO -marigold_trainer.py - train >> iter  1875 (epoch  2): loss=0.09030\n",
            " 2024-07-03 08:00:59,495 - INFO -marigold_trainer.py - train >> iter  1876 (epoch  2): loss=0.09782\n",
            " 2024-07-03 08:01:03,817 - INFO -marigold_trainer.py - train >> iter  1877 (epoch  2): loss=0.08251\n",
            " 2024-07-03 08:01:08,132 - INFO -marigold_trainer.py - train >> iter  1878 (epoch  2): loss=0.11267\n",
            " 2024-07-03 08:01:12,464 - INFO -marigold_trainer.py - train >> iter  1879 (epoch  2): loss=0.12529\n",
            " 2024-07-03 08:01:16,790 - INFO -marigold_trainer.py - train >> iter  1880 (epoch  2): loss=0.13067\n",
            " 2024-07-03 08:01:21,137 - INFO -marigold_trainer.py - train >> iter  1881 (epoch  2): loss=0.07866\n",
            " 2024-07-03 08:01:25,464 - INFO -marigold_trainer.py - train >> iter  1882 (epoch  2): loss=0.11350\n",
            " 2024-07-03 08:01:29,803 - INFO -marigold_trainer.py - train >> iter  1883 (epoch  2): loss=0.08412\n",
            " 2024-07-03 08:01:34,242 - INFO -marigold_trainer.py - train >> iter  1884 (epoch  2): loss=0.09290\n",
            " 2024-07-03 08:01:38,558 - INFO -marigold_trainer.py - train >> iter  1885 (epoch  2): loss=0.07948\n",
            " 2024-07-03 08:01:42,884 - INFO -marigold_trainer.py - train >> iter  1886 (epoch  2): loss=0.11589\n",
            " 2024-07-03 08:01:47,456 - INFO -marigold_trainer.py - train >> iter  1887 (epoch  2): loss=0.08484\n",
            " 2024-07-03 08:01:51,771 - INFO -marigold_trainer.py - train >> iter  1888 (epoch  2): loss=0.09976\n",
            " 2024-07-03 08:01:56,081 - INFO -marigold_trainer.py - train >> iter  1889 (epoch  2): loss=0.04800\n",
            " 2024-07-03 08:02:00,415 - INFO -marigold_trainer.py - train >> iter  1890 (epoch  2): loss=0.11256\n",
            " 2024-07-03 08:02:04,724 - INFO -marigold_trainer.py - train >> iter  1891 (epoch  2): loss=0.05606\n",
            " 2024-07-03 08:02:09,035 - INFO -marigold_trainer.py - train >> iter  1892 (epoch  2): loss=0.08433\n",
            " 2024-07-03 08:02:13,349 - INFO -marigold_trainer.py - train >> iter  1893 (epoch  2): loss=0.09789\n",
            " 2024-07-03 08:02:17,664 - INFO -marigold_trainer.py - train >> iter  1894 (epoch  2): loss=0.09453\n",
            " 2024-07-03 08:02:21,991 - INFO -marigold_trainer.py - train >> iter  1895 (epoch  2): loss=0.07381\n",
            " 2024-07-03 08:02:26,323 - INFO -marigold_trainer.py - train >> iter  1896 (epoch  2): loss=0.08926\n",
            " 2024-07-03 08:02:30,634 - INFO -marigold_trainer.py - train >> iter  1897 (epoch  2): loss=0.09205\n",
            " 2024-07-03 08:02:35,043 - INFO -marigold_trainer.py - train >> iter  1898 (epoch  2): loss=0.07904\n",
            " 2024-07-03 08:02:39,350 - INFO -marigold_trainer.py - train >> iter  1899 (epoch  2): loss=0.08005\n",
            " 2024-07-03 08:02:43,656 - INFO -marigold_trainer.py - train >> iter  1900 (epoch  2): loss=0.05734\n",
            " 2024-07-03 08:02:43,657 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 08:02:56,833 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 08:03:15,257 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 08:03:21,474 - INFO -marigold_trainer.py - train >> iter  1901 (epoch  2): loss=0.06230\n",
            " 2024-07-03 08:03:26,153 - INFO -marigold_trainer.py - train >> iter  1902 (epoch  2): loss=0.05733\n",
            " 2024-07-03 08:03:30,763 - INFO -marigold_trainer.py - train >> iter  1903 (epoch  2): loss=0.09922\n",
            " 2024-07-03 08:03:35,414 - INFO -marigold_trainer.py - train >> iter  1904 (epoch  2): loss=0.08350\n",
            " 2024-07-03 08:03:40,006 - INFO -marigold_trainer.py - train >> iter  1905 (epoch  2): loss=0.10295\n",
            " 2024-07-03 08:03:44,578 - INFO -marigold_trainer.py - train >> iter  1906 (epoch  2): loss=0.13184\n",
            " 2024-07-03 08:03:49,123 - INFO -marigold_trainer.py - train >> iter  1907 (epoch  2): loss=0.09331\n",
            " 2024-07-03 08:03:53,644 - INFO -marigold_trainer.py - train >> iter  1908 (epoch  2): loss=0.06016\n",
            " 2024-07-03 08:03:58,113 - INFO -marigold_trainer.py - train >> iter  1909 (epoch  2): loss=0.08856\n",
            " 2024-07-03 08:04:02,618 - INFO -marigold_trainer.py - train >> iter  1910 (epoch  2): loss=0.06580\n",
            " 2024-07-03 08:04:07,084 - INFO -marigold_trainer.py - train >> iter  1911 (epoch  2): loss=0.10304\n",
            " 2024-07-03 08:04:11,622 - INFO -marigold_trainer.py - train >> iter  1912 (epoch  2): loss=0.07694\n",
            " 2024-07-03 08:04:16,040 - INFO -marigold_trainer.py - train >> iter  1913 (epoch  2): loss=0.09943\n",
            " 2024-07-03 08:04:20,417 - INFO -marigold_trainer.py - train >> iter  1914 (epoch  2): loss=0.07933\n",
            " 2024-07-03 08:04:24,737 - INFO -marigold_trainer.py - train >> iter  1915 (epoch  2): loss=0.05449\n",
            " 2024-07-03 08:04:29,077 - INFO -marigold_trainer.py - train >> iter  1916 (epoch  2): loss=0.09084\n",
            " 2024-07-03 08:04:33,391 - INFO -marigold_trainer.py - train >> iter  1917 (epoch  2): loss=0.07552\n",
            " 2024-07-03 08:04:37,801 - INFO -marigold_trainer.py - train >> iter  1918 (epoch  2): loss=0.08325\n",
            " 2024-07-03 08:04:42,101 - INFO -marigold_trainer.py - train >> iter  1919 (epoch  2): loss=0.07478\n",
            " 2024-07-03 08:04:46,420 - INFO -marigold_trainer.py - train >> iter  1920 (epoch  2): loss=0.14905\n",
            " 2024-07-03 08:04:50,739 - INFO -marigold_trainer.py - train >> iter  1921 (epoch  2): loss=0.11704\n",
            " 2024-07-03 08:04:55,072 - INFO -marigold_trainer.py - train >> iter  1922 (epoch  2): loss=0.07256\n",
            " 2024-07-03 08:04:59,406 - INFO -marigold_trainer.py - train >> iter  1923 (epoch  2): loss=0.09556\n",
            " 2024-07-03 08:05:03,719 - INFO -marigold_trainer.py - train >> iter  1924 (epoch  2): loss=0.07157\n",
            " 2024-07-03 08:05:08,046 - INFO -marigold_trainer.py - train >> iter  1925 (epoch  2): loss=0.07520\n",
            " 2024-07-03 08:05:12,363 - INFO -marigold_trainer.py - train >> iter  1926 (epoch  2): loss=0.08084\n",
            " 2024-07-03 08:05:16,681 - INFO -marigold_trainer.py - train >> iter  1927 (epoch  2): loss=0.07898\n",
            " 2024-07-03 08:05:20,992 - INFO -marigold_trainer.py - train >> iter  1928 (epoch  2): loss=0.06879\n",
            " 2024-07-03 08:05:25,353 - INFO -marigold_trainer.py - train >> iter  1929 (epoch  2): loss=0.09714\n",
            " 2024-07-03 08:05:29,685 - INFO -marigold_trainer.py - train >> iter  1930 (epoch  2): loss=0.10076\n",
            " 2024-07-03 08:05:33,997 - INFO -marigold_trainer.py - train >> iter  1931 (epoch  2): loss=0.11899\n",
            " 2024-07-03 08:05:38,404 - INFO -marigold_trainer.py - train >> iter  1932 (epoch  2): loss=0.07468\n",
            " 2024-07-03 08:05:42,718 - INFO -marigold_trainer.py - train >> iter  1933 (epoch  2): loss=0.09131\n",
            " 2024-07-03 08:05:47,037 - INFO -marigold_trainer.py - train >> iter  1934 (epoch  2): loss=0.07776\n",
            " 2024-07-03 08:05:51,356 - INFO -marigold_trainer.py - train >> iter  1935 (epoch  2): loss=0.08967\n",
            " 2024-07-03 08:05:55,682 - INFO -marigold_trainer.py - train >> iter  1936 (epoch  2): loss=0.08277\n",
            " 2024-07-03 08:06:00,005 - INFO -marigold_trainer.py - train >> iter  1937 (epoch  2): loss=0.13114\n",
            " 2024-07-03 08:06:04,334 - INFO -marigold_trainer.py - train >> iter  1938 (epoch  2): loss=0.08016\n",
            " 2024-07-03 08:06:08,652 - INFO -marigold_trainer.py - train >> iter  1939 (epoch  2): loss=0.07872\n",
            " 2024-07-03 08:06:12,986 - INFO -marigold_trainer.py - train >> iter  1940 (epoch  2): loss=0.05945\n",
            " 2024-07-03 08:06:17,300 - INFO -marigold_trainer.py - train >> iter  1941 (epoch  2): loss=0.09287\n",
            " 2024-07-03 08:06:21,611 - INFO -marigold_trainer.py - train >> iter  1942 (epoch  2): loss=0.05820\n",
            " 2024-07-03 08:06:25,931 - INFO -marigold_trainer.py - train >> iter  1943 (epoch  2): loss=0.06269\n",
            " 2024-07-03 08:06:30,259 - INFO -marigold_trainer.py - train >> iter  1944 (epoch  2): loss=0.08485\n",
            " 2024-07-03 08:06:34,585 - INFO -marigold_trainer.py - train >> iter  1945 (epoch  2): loss=0.09974\n",
            " 2024-07-03 08:06:38,965 - INFO -marigold_trainer.py - train >> iter  1946 (epoch  2): loss=0.07194\n",
            " 2024-07-03 08:06:43,276 - INFO -marigold_trainer.py - train >> iter  1947 (epoch  2): loss=0.07066\n",
            " 2024-07-03 08:06:47,595 - INFO -marigold_trainer.py - train >> iter  1948 (epoch  2): loss=0.08342\n",
            " 2024-07-03 08:06:51,914 - INFO -marigold_trainer.py - train >> iter  1949 (epoch  2): loss=0.07412\n",
            " 2024-07-03 08:06:56,242 - INFO -marigold_trainer.py - train >> iter  1950 (epoch  2): loss=0.12251\n",
            " 2024-07-03 08:06:56,243 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 08:07:09,071 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 08:07:27,754 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            " 2024-07-03 08:07:33,640 - INFO -marigold_trainer.py - train >> iter  1951 (epoch  2): loss=0.10690\n",
            " 2024-07-03 08:07:37,966 - INFO -marigold_trainer.py - train >> iter  1952 (epoch  2): loss=0.08645\n",
            " 2024-07-03 08:07:42,347 - INFO -marigold_trainer.py - train >> iter  1953 (epoch  2): loss=0.11671\n",
            " 2024-07-03 08:07:46,694 - INFO -marigold_trainer.py - train >> iter  1954 (epoch  2): loss=0.07812\n",
            " 2024-07-03 08:07:51,021 - INFO -marigold_trainer.py - train >> iter  1955 (epoch  2): loss=0.12614\n",
            " 2024-07-03 08:07:55,357 - INFO -marigold_trainer.py - train >> iter  1956 (epoch  2): loss=0.07779\n",
            " 2024-07-03 08:07:59,724 - INFO -marigold_trainer.py - train >> iter  1957 (epoch  2): loss=0.08187\n",
            " 2024-07-03 08:08:04,059 - INFO -marigold_trainer.py - train >> iter  1958 (epoch  2): loss=0.10984\n",
            " 2024-07-03 08:08:08,377 - INFO -marigold_trainer.py - train >> iter  1959 (epoch  2): loss=0.08225\n",
            " 2024-07-03 08:08:12,728 - INFO -marigold_trainer.py - train >> iter  1960 (epoch  2): loss=0.07222\n",
            " 2024-07-03 08:08:17,044 - INFO -marigold_trainer.py - train >> iter  1961 (epoch  2): loss=0.09851\n",
            " 2024-07-03 08:08:21,371 - INFO -marigold_trainer.py - train >> iter  1962 (epoch  2): loss=0.07272\n",
            " 2024-07-03 08:08:25,690 - INFO -marigold_trainer.py - train >> iter  1963 (epoch  2): loss=0.07810\n",
            " 2024-07-03 08:08:29,997 - INFO -marigold_trainer.py - train >> iter  1964 (epoch  2): loss=0.06688\n",
            " 2024-07-03 08:08:34,300 - INFO -marigold_trainer.py - train >> iter  1965 (epoch  2): loss=0.08932\n",
            " 2024-07-03 08:08:38,602 - INFO -marigold_trainer.py - train >> iter  1966 (epoch  2): loss=0.08607\n",
            " 2024-07-03 08:08:43,000 - INFO -marigold_trainer.py - train >> iter  1967 (epoch  2): loss=0.08079\n",
            " 2024-07-03 08:08:47,306 - INFO -marigold_trainer.py - train >> iter  1968 (epoch  2): loss=0.11144\n",
            " 2024-07-03 08:08:51,631 - INFO -marigold_trainer.py - train >> iter  1969 (epoch  2): loss=0.09140\n",
            " 2024-07-03 08:08:55,954 - INFO -marigold_trainer.py - train >> iter  1970 (epoch  2): loss=0.10719\n",
            " 2024-07-03 08:09:00,317 - INFO -marigold_trainer.py - train >> iter  1971 (epoch  2): loss=0.09492\n",
            " 2024-07-03 08:09:04,656 - INFO -marigold_trainer.py - train >> iter  1972 (epoch  2): loss=0.08366\n",
            " 2024-07-03 08:09:08,994 - INFO -marigold_trainer.py - train >> iter  1973 (epoch  2): loss=0.06527\n",
            " 2024-07-03 08:09:13,324 - INFO -marigold_trainer.py - train >> iter  1974 (epoch  2): loss=0.11525\n",
            " 2024-07-03 08:09:17,650 - INFO -marigold_trainer.py - train >> iter  1975 (epoch  2): loss=0.06858\n",
            " 2024-07-03 08:09:21,979 - INFO -marigold_trainer.py - train >> iter  1976 (epoch  2): loss=0.09135\n",
            " 2024-07-03 08:09:26,332 - INFO -marigold_trainer.py - train >> iter  1977 (epoch  2): loss=0.10911\n",
            " 2024-07-03 08:09:30,663 - INFO -marigold_trainer.py - train >> iter  1978 (epoch  2): loss=0.07358\n",
            " 2024-07-03 08:09:34,992 - INFO -marigold_trainer.py - train >> iter  1979 (epoch  2): loss=0.14137\n",
            " 2024-07-03 08:09:39,334 - INFO -marigold_trainer.py - train >> iter  1980 (epoch  2): loss=0.06966\n",
            " 2024-07-03 08:09:43,707 - INFO -marigold_trainer.py - train >> iter  1981 (epoch  2): loss=0.10080\n",
            " 2024-07-03 08:09:48,048 - INFO -marigold_trainer.py - train >> iter  1982 (epoch  2): loss=0.10463\n",
            " 2024-07-03 08:09:52,379 - INFO -marigold_trainer.py - train >> iter  1983 (epoch  2): loss=0.10250\n",
            " 2024-07-03 08:09:56,712 - INFO -marigold_trainer.py - train >> iter  1984 (epoch  2): loss=0.10281\n",
            " 2024-07-03 08:10:01,082 - INFO -marigold_trainer.py - train >> iter  1985 (epoch  2): loss=0.09527\n",
            " 2024-07-03 08:10:05,418 - INFO -marigold_trainer.py - train >> iter  1986 (epoch  2): loss=0.06797\n",
            " 2024-07-03 08:10:10,018 - INFO -marigold_trainer.py - train >> iter  1987 (epoch  2): loss=0.09515\n",
            " 2024-07-03 08:10:14,626 - INFO -marigold_trainer.py - train >> iter  1988 (epoch  2): loss=0.10328\n",
            " 2024-07-03 08:10:19,205 - INFO -marigold_trainer.py - train >> iter  1989 (epoch  2): loss=0.07969\n",
            " 2024-07-03 08:10:23,810 - INFO -marigold_trainer.py - train >> iter  1990 (epoch  2): loss=0.11859\n",
            " 2024-07-03 08:10:28,348 - INFO -marigold_trainer.py - train >> iter  1991 (epoch  2): loss=0.07726\n",
            " 2024-07-03 08:10:32,830 - INFO -marigold_trainer.py - train >> iter  1992 (epoch  2): loss=0.07715\n",
            " 2024-07-03 08:10:37,307 - INFO -marigold_trainer.py - train >> iter  1993 (epoch  2): loss=0.08777\n",
            " 2024-07-03 08:10:41,798 - INFO -marigold_trainer.py - train >> iter  1994 (epoch  2): loss=0.08600\n",
            " 2024-07-03 08:10:46,327 - INFO -marigold_trainer.py - train >> iter  1995 (epoch  2): loss=0.06648\n",
            " 2024-07-03 08:10:50,773 - INFO -marigold_trainer.py - train >> iter  1996 (epoch  2): loss=0.05681\n",
            " 2024-07-03 08:10:55,165 - INFO -marigold_trainer.py - train >> iter  1997 (epoch  2): loss=0.12115\n",
            " 2024-07-03 08:10:59,512 - INFO -marigold_trainer.py - train >> iter  1998 (epoch  2): loss=0.08188\n",
            " 2024-07-03 08:11:03,846 - INFO -marigold_trainer.py - train >> iter  1999 (epoch  2): loss=0.07227\n",
            " 2024-07-03 08:11:08,179 - INFO -marigold_trainer.py - train >> iter  2000 (epoch  2): loss=0.04879\n",
            " 2024-07-03 08:11:08,180 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/iter_002000\n",
            " 2024-07-03 08:11:21,398 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/iter_002000/unet\n",
            " 2024-07-03 08:11:21,399 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: ./output/train_marigold/checkpoint/latest\n",
            " 2024-07-03 08:11:29,580 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: ./output/train_marigold/checkpoint/latest/unet\n",
            " 2024-07-03 08:11:49,749 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: ./output/train_marigold/checkpoint/latest/trainer.ckpt\n",
            "evaluating on :   0% 0/10000 [00:00<?, ?it/s]\n",
            " 2024-07-03 08:11:51,434 - ERROR -train.py - <module> >> Wrong input shape torch.Size([3, 32, 32]), expected [1, rgb, H, W]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Marigold/train.py\", line 361, in <module>\n",
            "    trainer.train(t_end=t_end)\n",
            "  File \"/content/Marigold/src/trainer/marigold_trainer.py\", line 365, in train\n",
            "    self._train_step_callback()\n",
            "  File \"/content/Marigold/src/trainer/marigold_trainer.py\", line 417, in _train_step_callback\n",
            "    self.validate()\n",
            "  File \"/content/Marigold/src/trainer/marigold_trainer.py\", line 436, in validate\n",
            "    val_metric_dic = self.validate_single_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/Marigold/src/trainer/marigold_trainer.py\", line 528, in validate_single_dataset\n",
            "    pipe_out: MarigoldDepthOutput = self.model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/Marigold/marigold/marigold_pipeline.py\", line 232, in __call__\n",
            "    4 == rgb.dim() and 3 == input_size[-3]\n",
            "AssertionError: Wrong input shape torch.Size([3, 32, 32]), expected [1, rgb, H, W]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🏇 iv. Initialize pipeline\n",
        "\n",
        "# change model cache directory\n",
        "# !export HF_HOME=/content/Marigold/checkpoint\n",
        "\n",
        "from marigold import MarigoldPipeline\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "cfg = OmegaConf.load(\"config/train_marigold.yaml\")\n",
        "_pipeline_kwargs = cfg.pipeline.kwargs if cfg.pipeline.kwargs is not None else {}\n",
        "pipe = MarigoldPipeline.from_pretrained(stable-diffusion, **_pipeline_kwargs)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "2778478f65af400793e8671c5d510ce2",
            "00398a404dc84d7ba8518d58f7eaaa52",
            "60eb6d6eb5ce4850ae8020e3c57e6db0",
            "f0a1ce8b4af640898da9e3d9f7b5bb94",
            "615804088a3e48ddb9e977d8ac39e27d",
            "71575dba847f483d80b4c3afb31d44d1",
            "b4568cb4de5149b8bd0b7c5eee41947c",
            "4df9ee6ba2114f52b902163b21a6e498",
            "e79393d440a545068a891eb1d554f510",
            "966d636006bc41e4aee68b90d9a32b8c",
            "a2d3bb46a6b24bb8913ada89ca41612c"
          ]
        },
        "id": "mxczTk0lTWRq",
        "outputId": "333fd7da-6ffa-4c09-b9c5-d899762a5656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2778478f65af400793e8671c5d510ce2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4bc0e584c12d>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarigoldPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 )\n\u001b[1;32m    430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Config the Path\n",
        "!export BASE_DATA_DIR=YOUR_DATA_DIR  # directory of training data\n",
        "!export BASE_CKPT_DIR=YOUR_CHECKPOINT_DIR  # directory of pretrained checkpoint"
      ],
      "metadata": {
        "id": "1M02HUuPMSg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Data\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"uoft-cs/cifar10\")\n"
      ],
      "metadata": {
        "id": "ezL93l_kMu_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpwmmmYOWZ5w",
        "outputId": "9dfc6977-76dc-4f4f-f5d2-07b282a0e782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/547.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CIFAR10ColorDataset(Dataset):\n",
        "    def __init__(self, split=\"train\", transform=None):\n",
        "        self.dataset = load_dataset(\"cifar10\", split=split)\n",
        "        self.transform = transform\n",
        "        self.class_colors = [\n",
        "            [255, 0, 0],    # Red\n",
        "            [0, 255, 0],    # Green\n",
        "            [0, 0, 255],    # Blue\n",
        "            [255, 255, 0],  # Yellow\n",
        "            [255, 0, 255],  # Magenta\n",
        "            [0, 255, 255],  # Cyan\n",
        "            [128, 0, 0],    # Maroon\n",
        "            [0, 128, 0],    # Green\n",
        "            [0, 0, 128],    # Navy\n",
        "            [128, 128, 0],  # Olive\n",
        "        ]\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        image = item['img']  # This is a PIL Image\n",
        "\n",
        "        # Convert PIL Image to tensor and normalize\n",
        "        image = self.to_tensor(image)  # This also changes from HWC to CHW format\n",
        "\n",
        "        label = item['label']\n",
        "        color = torch.tensor(self.class_colors[label], dtype=torch.float32) / 255.0\n",
        "\n",
        "        # Create a color tensor with the same size as the image\n",
        "        color_tensor = color.view(3, 1, 1).repeat(1, 32, 32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            color_tensor = self.transform(color_tensor)\n",
        "\n",
        "        return image, color_tensor\n",
        "\n",
        "    def get_class_colors(self):\n",
        "        return self.class_colors"
      ],
      "metadata": {
        "id": "-9-1uYLZWKpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = CIFAR10ColorDataset(split=\"train\")\n",
        "test_dataset = CIFAR10ColorDataset(split=\"test\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "BCFfu1UeWT95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the train_loader\n",
        "images, colors = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(colors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbTXB6FkWVIN",
        "outputId": "a87b2823-8f69-49ca-8746-325f28a738dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([32, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the image\n",
        "i = 3\n",
        "plt.imshow(images[i].permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dFiNNWqLWsP8",
        "outputId": "b23197be-3b06-4f99-dd93-bf4905de5de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(colors[i].permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6D4WREvzXtv6",
        "outputId": "713dd3a2-b90a-4879-fd71-7cb645fe4cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n"
      ],
      "metadata": {
        "id": "KqI01ghhX4Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train = CIFAR10(root='./data', train=True, download=True)\n",
        "cifar10_test = CIFAR10(root='./data', train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTioMvGVhXu3",
        "outputId": "e2b27af8-7cc5-40d9-876e-f5d3bd242208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 73380698.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8WMuDzahbAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}